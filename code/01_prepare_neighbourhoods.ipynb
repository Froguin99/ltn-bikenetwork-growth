{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pre-process neighbourhood data\n",
    "## Project: Growing Urban Bicycle Networks with an LTN twist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the outputs of the ltnDetection (https://github.com/Froguin99/LTN-Detection) and prepares them for later use within the bike network growth project\n",
    "\n",
    "Contact: Chris Larkin (c.larkin@ncl.ac.uk) \n",
    "\n",
    "Created: 2025-03-26  \n",
    "Last modified: 2025-03-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "\n",
    "%load_ext watermark\n",
    "#%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in neighbourhoods and extract \"ltns\" from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- store ltns on a public location to avoid manually having to find the data. Currently hosting Tyne & Wear on Github as geopackages, not very flexible\n",
    "- set up fuzzy matching of place names to growbike's use of placenames (e.g. Newcastle Upon Tyne --> newcastle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LTNs and Normal Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in from Github\n",
    "github_link = \"https://raw.githubusercontent.com/Froguin99/LTN-Detection/main/data/Tyne%26Wear/\"\n",
    "raw_files = [\n",
    "    \"scored_neighbourhoods_Gateshead.gpkg\",\n",
    "    \"scored_neighbourhoods_Newcastle Upon Tyne.gpkg\",\n",
    "    \"scored_neighbourhoods_South Tyneside.gpkg\",\n",
    "    \"scored_neighbourhoods_Sunderland.gpkg\",\n",
    "    \"scored_neighbourhoods_North Tyneside.gpkg\"] # just Tyne & Wear for now...\n",
    "\n",
    "# Manual map: filename place â†’ folder name. Tried a fuzzy matching (lower down adn commented out) but haven't got it quite right yet...\n",
    "folder_map = {\n",
    "    \"Gateshead\": \"gateshead\",\n",
    "    \"Newcastle Upon Tyne\": \"newcastle\",\n",
    "    \"South Tyneside\": \"south_tyneside\",\n",
    "    \"Sunderland\": \"sunderland\",\n",
    "    \"North Tyneside\": \"north_tyneside\"\n",
    "}\n",
    "\n",
    "columns_to_convert = [\n",
    "    \"rat_run_score\", \"mean_distance_diff_score\",\n",
    "    \"filter_road_density_score\", \"overall_score\", \"cluster_label\"\n",
    "]\n",
    "\n",
    "\n",
    "# save just LTN neighbourhoods based on the \n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "\n",
    "    new_fname = f\"scored_neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "\n",
    "    # Download\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Filter by scores\n",
    "    ltns_current = gdf[gdf[\"overall_score\"] > ltn_plausiablity_score]\n",
    "    scenario_path = os.path.join(PATH[\"data\"], folder, \"current_ltn_scenario\")\n",
    "    os.makedirs(scenario_path, exist_ok=True)\n",
    "    output_path = os.path.join(scenario_path, new_fname)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    ltns_current.to_file(output_path, layer=new_fname.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path} (current LTNs scenario)\")\n",
    "\n",
    "    ltns_more = gdf[gdf[\"overall_score\"] > lower_ltn_plausiablity_score]\n",
    "    scenario_path = os.path.join(PATH[\"data\"], folder, \"more_ltn_scenario\")\n",
    "    os.makedirs(scenario_path, exist_ok=True)\n",
    "    output_path = os.path.join(scenario_path, new_fname)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    ltns_more.to_file(output_path, layer=new_fname.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path} (more LTNs scenario)\")\n",
    "\n",
    "\n",
    "\n",
    "# save all neighbourhoods, regardless of how much traffic they have within them\n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "    new_fname = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    out_name = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    output_path = os.path.join(PATH[\"data\"], folder, out_name)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    gdf.to_file(output_path, layer=out_name.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fuzzy matching attempt\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# columns_to_convert = [\"rat_run_score\", \"mean_distance_diff_score\", \"filter_road_density_score\", \"overall_score\", \"cluster_label\"]\n",
    "\n",
    "\n",
    "# def place_from_filename(fname):\n",
    "#     return fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\").strip()\n",
    "\n",
    "# # Function to fuzzy match the place to the folder names\n",
    "# def get_matching_folder(place_name, folder_names):\n",
    "#     match = process.extractOne(place_name, folder_names)\n",
    "#     return match[0] if match[1] >= 80 else None  # threshold of 80% similarity\n",
    "\n",
    "# # Get available folder names in PATH['data']\n",
    "# available_folders = [folder for folder in os.listdir(PATH[\"data\"]) if os.path.isdir(os.path.join(PATH[\"data\"], folder))]\n",
    "\n",
    "# # Process each file\n",
    "# for fname in raw_files:\n",
    "#     place_name = place_from_filename(fname)\n",
    "#     matching_folder = get_matching_folder(place_name, available_folders)\n",
    "    \n",
    "#     if not matching_folder:\n",
    "#         print(f\"No match found for {place_name}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Download the file\n",
    "#     url = github_link + fname\n",
    "#     local_tmp = fname  # Save temporarily with original name\n",
    "#     with open(local_tmp, \"wb\") as f:\n",
    "#         f.write(requests.get(url).content)\n",
    "\n",
    "#     # Read and filter\n",
    "#     gdf = gpd.read_file(local_tmp)\n",
    "#     gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "#     ltns = gdf[gdf[\"overall_score\"] > 50]\n",
    "\n",
    "#     # Define the output path using the matched folder name\n",
    "#     output_path = os.path.join(PATH[\"data\"], matching_folder, fname)\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "#     # Save the file\n",
    "#     ltns.to_file(output_path, driver=\"GPKG\")\n",
    "#     print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
