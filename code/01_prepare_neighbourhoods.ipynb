{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pre-process neighbourhood data\n",
    "## Project: Growing Urban Bicycle Networks with an LTN twist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the outputs of the ltnDetection (https://github.com/Froguin99/LTN-Detection) and prepares them for later use within the bike network growth project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# System\n",
    "import copy\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import watermark\n",
    "import dill as pickle\n",
    "import itertools\n",
    "import random\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Math/Data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Network\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "from networkx.utils import pairwise\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Geo\n",
    "import osmnx as ox\n",
    "ox.settings.log_file = True\n",
    "ox.settings.requests_timeout = 300\n",
    "ox.settings.logs_folder = PATH[\"logs\"]\n",
    "import fiona\n",
    "import shapely\n",
    "from osgeo import gdal, osr\n",
    "from haversine import haversine, haversine_vector\n",
    "import pyproj\n",
    "from shapely.geometry import Point, MultiPoint, LineString, Polygon, MultiLineString, MultiPolygon, shape, GeometryCollection\n",
    "import shapely.ops as ops\n",
    "from shapely.ops import unary_union\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.plotting import plot_line\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "import json\n",
    "from owslib.wms import WebMapService\n",
    "from rasterio.mask import mask as rio_mask  \n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "from rasterio.io import MemoryFile\n",
    "from tesspy import Tessellation\n",
    "import momepy\n",
    "from pyproj import Transformer\n",
    "import geopy\n",
    "from geopy.distance import geodesic\n",
    "#import ukcensusapi.Nomisweb as Api # not needed at the moment\n",
    "import esda\n",
    "from shapely.ops import polygonize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "\n",
    "%load_ext watermark\n",
    "#%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in neighbourhoods and extract \"ltns\" from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- store ltns on a public location to avoid manually having to find the data. Currently hosting Tyne & Wear on Github as geopackages, not very flexible\n",
    "- set up fuzzy matching of place names to growbike's use of placenames (e.g. Newcastle Upon Tyne --> newcastle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LTNs and Normal Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in from Github\n",
    "github_link = \"https://raw.githubusercontent.com/Froguin99/LTN-Detection/main/data/Tyne%26Wear/\"\n",
    "raw_files = [\n",
    "    \"scored_neighbourhoods_Gateshead.gpkg\",\n",
    "    \"scored_neighbourhoods_Newcastle Upon Tyne.gpkg\",\n",
    "    \"scored_neighbourhoods_South Tyneside.gpkg\",\n",
    "    \"scored_neighbourhoods_Sunderland.gpkg\",\n",
    "    \"scored_neighbourhoods_North Tyneside.gpkg\"] # just Tyne & Wear for now...\n",
    "\n",
    "# Manual map: filename place â†’ folder name. Tried a fuzzy matching (lower down adn commented out) but haven't got it quite right yet...\n",
    "folder_map = {\n",
    "    \"Gateshead\": \"gateshead\",\n",
    "    \"Newcastle Upon Tyne\": \"newcastle\",\n",
    "    \"South Tyneside\": \"south_tyneside\",\n",
    "    \"Sunderland\": \"sunderland\",\n",
    "    \"North Tyneside\": \"north_tyneside\"\n",
    "}\n",
    "\n",
    "columns_to_convert = [\n",
    "    \"rat_run_score\", \"mean_distance_diff_score\",\n",
    "    \"filter_road_density_score\", \"overall_score\", \"cluster_label\"\n",
    "]\n",
    "\n",
    "\n",
    "# save just LTN neighbourhoods based on the \n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "\n",
    "    new_fname = f\"scored_neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "\n",
    "    # Download\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Filter by scores\n",
    "    ltns_current = gdf[gdf[\"overall_score\"] > ltn_plausiablity_score]\n",
    "    scenario_path = os.path.join(PATH[\"data\"], folder, \"current_ltn_scenario\")\n",
    "    os.makedirs(scenario_path, exist_ok=True)\n",
    "    output_path = os.path.join(scenario_path, new_fname)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    ltns_current.to_file(output_path, layer=new_fname.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path} (current LTNs scenario)\")\n",
    "\n",
    "    ltns_more = gdf[gdf[\"overall_score\"] > lower_ltn_plausiablity_score]\n",
    "    scenario_path = os.path.join(PATH[\"data\"], folder, \"more_ltn_scenario\")\n",
    "    os.makedirs(scenario_path, exist_ok=True)\n",
    "    output_path = os.path.join(scenario_path, new_fname)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    ltns_more.to_file(output_path, layer=new_fname.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path} (more LTNs scenario)\")\n",
    "\n",
    "\n",
    "\n",
    "# save all neighbourhoods, regardless of how much traffic they have within them\n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "    new_fname = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    out_name = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    output_path = os.path.join(PATH[\"data\"], folder, out_name)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    gdf.to_file(output_path, layer=out_name.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fuzzy matching attempt\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# columns_to_convert = [\"rat_run_score\", \"mean_distance_diff_score\", \"filter_road_density_score\", \"overall_score\", \"cluster_label\"]\n",
    "\n",
    "\n",
    "# def place_from_filename(fname):\n",
    "#     return fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\").strip()\n",
    "\n",
    "# # Function to fuzzy match the place to the folder names\n",
    "# def get_matching_folder(place_name, folder_names):\n",
    "#     match = process.extractOne(place_name, folder_names)\n",
    "#     return match[0] if match[1] >= 80 else None  # threshold of 80% similarity\n",
    "\n",
    "# # Get available folder names in PATH['data']\n",
    "# available_folders = [folder for folder in os.listdir(PATH[\"data\"]) if os.path.isdir(os.path.join(PATH[\"data\"], folder))]\n",
    "\n",
    "# # Process each file\n",
    "# for fname in raw_files:\n",
    "#     place_name = place_from_filename(fname)\n",
    "#     matching_folder = get_matching_folder(place_name, available_folders)\n",
    "    \n",
    "#     if not matching_folder:\n",
    "#         print(f\"No match found for {place_name}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Download the file\n",
    "#     url = github_link + fname\n",
    "#     local_tmp = fname  # Save temporarily with original name\n",
    "#     with open(local_tmp, \"wb\") as f:\n",
    "#         f.write(requests.get(url).content)\n",
    "\n",
    "#     # Read and filter\n",
    "#     gdf = gpd.read_file(local_tmp)\n",
    "#     gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "#     ltns = gdf[gdf[\"overall_score\"] > 50]\n",
    "\n",
    "#     # Define the output path using the matched folder name\n",
    "#     output_path = os.path.join(PATH[\"data\"], matching_folder, fname)\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "#     # Save the file\n",
    "#     ltns.to_file(output_path, driver=\"GPKG\")\n",
    "#     print(f\"Saved: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growbikenet_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
