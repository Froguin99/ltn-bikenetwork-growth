{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Analysis of bicycle network results\n",
    "## Project: Growing Urban Bicycle Networks with LTNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the existing infrastructure, the results from 03_poi_based_generation and calculates/analyzes a number of measures:\n",
    "* cost (length)\n",
    "* coverage  \n",
    "* directness  \n",
    "* efficiency\n",
    "* overlap with existing networks\n",
    "* average node degree\n",
    "* cyclable trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Speeding up\n",
    "    - The `get_composite_lcc_length` funciton is pretty slow currently!\n",
    "    - Producing buffers for coverage analysis is very slow\n",
    "    - Coverage very slow - commented out for the moment\n",
    "    - average node degree very slow\n",
    "- bikeable trips metric\n",
    "- find neighbourhoods where large amounts of residiental streets are used to potentially convert to LTNs?\n",
    "- only runs for one place at at time currently (my bad coding skills + getting stuck down rabbitholes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from src import utils\n",
    "PATH = utils.PATH # shortening the var name so that we don't have to change it below\n",
    "\n",
    "# System\n",
    "import csv\n",
    "import os\n",
    "import dill as pickle\n",
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from copy import deepcopy\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "# Math/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Network\n",
    "import networkx as nx\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Geo\n",
    "import osmnx as ox\n",
    "ox.settings.log_file = True\n",
    "ox.settings.requests_timeout = 300\n",
    "ox.settings.logs_folder = PATH[\"logs\"]\n",
    "import geopandas as gpd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "# if not debug: # Only do this if sure the code is bug-free!\n",
    "#     warnings.filterwarnings('ignore')\n",
    "rerun_existing = True # If True, will re-run the costly analysis of existing infra even if files already exist.\n",
    "rerun = True # If True, recompute the analysis. If false, just re-make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.load(\n",
    "    open(\"../parameters/parameters.yml\"), \n",
    "    Loader=yaml.FullLoader)\n",
    "osmnxparameters = json.load(open(\"../parameters/osmnxparameters.json\", \"r\"))\n",
    "plotparam = json.load(open(\"../parameters/plotparam.json\", \"r\"))\n",
    "plotparam_analysis = json.load(open(\"../parameters/plotparam_analysis.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network weighting by tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_lts = json.load(open(\"../parameters/tag_lts.json\", \"r\"))\n",
    "distance_cost = json.load(open(\"../parameters/distance_cost.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cities\n",
    "cities = utils.load_cities(PATH, debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness \n",
    "betweenness_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    betweenness_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_betweenness_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                betweenness_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the betweenness analysis first.\")\n",
    "            print(f\"No betweenness files found for {placeid} in scenario {scenario}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random (many runs to get a distribution)\n",
    "random_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    random_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        pattern = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" +\n",
    "                   f\"{placeid}_poi_{params['poi_source']}_random_weighted_{scenario}_run*.pickle\")\n",
    "        random_files = sorted(glob.glob(os.path.abspath(pattern)))#[:3]  # only take the first 3 whilst we debug :D\n",
    "        if random_files:\n",
    "            random_results[scenario][placeid] = []\n",
    "            for fn in random_files:\n",
    "                abs_path = os.path.abspath(fn)\n",
    "                with open(abs_path, \"rb\") as f:\n",
    "                    res = pickle.load(f)\n",
    "                random_results[scenario][placeid].append(res)\n",
    "        else:\n",
    "            print(f\"No random files found for {placeid} in scenario {scenario}.\")\n",
    "            print(\"Please run the random growth analysis first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand\n",
    "demand_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    demand_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_demand_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                demand_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the demand analysis first.\")\n",
    "            print(f\"No demand files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand LTN priority\n",
    "demand_ltn_priority_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    demand_ltn_priority_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_demand_ltn_priority_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                demand_ltn_priority_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the demand LTN priority analysis first.\")\n",
    "            print(f\"No demand LTN priority files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness LTN priority\n",
    "betweenness_ltn_priority_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    betweenness_ltn_priority_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_betweenness_ltn_priority_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                betweenness_ltn_priority_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the betweenness LTN priority analysis first.\")\n",
    "            print(f\"No betweenness LTN priority files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find investment level, split results into GTs, GT_abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario_name in params[\"scenarios\"]:\n",
    "    for placeid in cities:\n",
    "\n",
    "        # Demand \n",
    "        if placeid in demand_results.get(scenario_name, {}):\n",
    "            demand_dict = demand_results[scenario_name][placeid]\n",
    "            investment_levels_demand = demand_dict[\"prune_quantiles\"]\n",
    "            GTs_demand               = demand_dict[\"GTs\"]\n",
    "            GT_abstracts_demand      = demand_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            print(f\"No demand results for {placeid} in scenario '{scenario_name}'\")\n",
    "            investment_levels_demand = []\n",
    "            GTs_demand               = []\n",
    "            GT_abstracts_demand      = []\n",
    "\n",
    "\n",
    "        # Betweenness‐LTN‐priority \n",
    "        if placeid in betweenness_ltn_priority_results.get(scenario_name, {}):\n",
    "            betweenness_ltn_dict = betweenness_ltn_priority_results[scenario_name][placeid]\n",
    "            investment_levels_betw = betweenness_ltn_dict[\"prune_quantiles\"]\n",
    "            GTs_betw               = betweenness_ltn_dict[\"GTs\"]\n",
    "            GT_abstracts_betw      = betweenness_ltn_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            # e.g. scenario == \"no_ltn_scenario\" has no betweenness‐LTN‐priority data\n",
    "            investment_levels_betw = []\n",
    "            GTs_betw               = []\n",
    "            GT_abstracts_betw      = []\n",
    "\n",
    "        # Betweenness\n",
    "        if placeid in betweenness_results.get(scenario_name, {}):\n",
    "            betweenness_dict = betweenness_results[scenario_name][placeid]\n",
    "            investment_levels_betweenness = betweenness_dict[\"prune_quantiles\"]\n",
    "            GTs_betweenness               = betweenness_dict[\"GTs\"]\n",
    "            GT_abstracts_betweenness      = betweenness_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            investment_levels_betweenness = []\n",
    "            GTs_betweenness               = []\n",
    "            GT_abstracts_betweenness      = []\n",
    "\n",
    "        # Demand‐LTN‐priority \n",
    "        if placeid in demand_ltn_priority_results.get(scenario_name, {}):\n",
    "            dem_ltn_dict = demand_ltn_priority_results[scenario_name][placeid]\n",
    "            investment_levels_dem_ltn = dem_ltn_dict[\"prune_quantiles\"]\n",
    "            GTs_dem_ltn               = dem_ltn_dict[\"GTs\"]\n",
    "            GT_abstracts_dem_ltn      = dem_ltn_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            investment_levels_dem_ltn = []\n",
    "            GTs_dem_ltn               = []\n",
    "            GT_abstracts_dem_ltn      = []\n",
    "\n",
    "        # Random‐runs (loads all run*.pickle files)\n",
    "        random_runs_list = random_results.get(scenario_name, {}).get(placeid, [])\n",
    "        if random_runs_list:\n",
    "            all_GTs_random       = [run_dict[\"GTs\"]          for run_dict in random_runs_list]\n",
    "            all_GTabs_random      = [run_dict[\"GT_abstracts\"]  for run_dict in random_runs_list]\n",
    "            investment_levels_random = random_runs_list[0][\"prune_quantiles\"]\n",
    "        else:\n",
    "            all_GTs_random          = []\n",
    "            all_GTabs_random         = []\n",
    "            investment_levels_random = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing networks, nodes, GeoDataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_biketracks_dict               = {}  # (placeid, scenario) → biketrack graph\n",
    "G_biketrack_no_ltns_dict       = {}  # (placeid, scenario) → biketrack_no_ltn graph\n",
    "G_biketrackcaralls_dict        = {}  # (placeid, scenario) → biketrackcarall graph\n",
    "G_biketrackcarall_edges_dict    = {}  # (placeid, scenario) → GeoDataFrame of biketrackcarall edges\n",
    "boundary_gdfs               = {}  # placeid → boundary GeoDataFrame (same for all scenarios)\n",
    "tess_points_dict            = {}  # (placeid, scenario) → tessellation points GeoDataFrame\n",
    "ltn_points_dict             = {}  # (placeid, scenario) → LTN points GeoDataFrame\n",
    "combined_points_dict        = {}  # (placeid, scenario) → combined points GeoDataFrame\n",
    "\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    for placeid, placeinfo in cities.items():\n",
    "        base_folder = os.path.join(PATH[\"data\"], placeid, scenario)\n",
    "\n",
    "        # Load biketrack graph\n",
    "        biketrack_gpkg = os.path.join(base_folder, f\"{placeid}_biketrack.gpkg\")\n",
    "        if os.path.exists(biketrack_gpkg):\n",
    "            G_biketrack = utils.ox_gpkg_to_graph(biketrack_gpkg)\n",
    "            G_biketrack.remove_nodes_from(list(nx.isolates(G_biketrack)))\n",
    "            G_biketracks_dict[(placeid, scenario)] = G_biketrack\n",
    "        else:\n",
    "            print(f\"Missing: {biketrack_gpkg}\")\n",
    "            G_biketracks_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # Load biketrack_no_ltn graph\n",
    "        biketrack_no_ltn_gpkg = os.path.join(base_folder, f\"{placeid}_biketrack_no_ltn.gpkg\")\n",
    "        if os.path.exists(biketrack_no_ltn_gpkg):\n",
    "            G_no_ltn = utils.ox_gpkg_to_graph(biketrack_no_ltn_gpkg)\n",
    "            G_no_ltn.remove_nodes_from(list(nx.isolates(G_no_ltn)))\n",
    "            G_biketrack_no_ltns_dict[(placeid, scenario)] = G_no_ltn\n",
    "        else:\n",
    "            print(f\"Missing: {biketrack_no_ltn_gpkg}\")\n",
    "            G_biketrack_no_ltns_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # Load biketrackcarall graph\n",
    "        biketrackcarall_gpkg = os.path.join(base_folder, f\"{placeid}_biketrackcarall.gpkg\")\n",
    "        if os.path.exists(biketrackcarall_gpkg):\n",
    "            G_carall = utils.ox_gpkg_to_graph(biketrackcarall_gpkg)\n",
    "            G_carall.remove_nodes_from(list(nx.isolates(G_carall)))\n",
    "            G_biketrackcaralls_dict[(placeid, scenario)] = G_carall\n",
    "\n",
    "            # also store edges GeoDataFrame\n",
    "            edges_gdf = ox.graph_to_gdfs(G_carall, nodes=False)\n",
    "            G_biketrackcarall_edges_dict[(placeid, scenario)] = edges_gdf\n",
    "        else:\n",
    "            print(f\"Missing: {biketrackcarall_gpkg}\")\n",
    "            G_biketrackcaralls_dict[(placeid, scenario)] = None\n",
    "            G_biketrackcarall_edges_dict[(placeid, scenario)] = None\n",
    "\n",
    "        #  Load boundary once per placeid (it won’t change by scenario)\n",
    "        if placeid not in boundary_gdfs:\n",
    "            boundary_gdf = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "            boundary_gdfs[placeid] = boundary_gdf\n",
    "\n",
    "        # get nodes\n",
    "        tess_points_gpkg = os.path.join(base_folder, f\"{placeid}_tessellation_points.gpkg\")\n",
    "        if os.path.exists(tess_points_gpkg):\n",
    "            tess_points = gpd.read_file(tess_points_gpkg)\n",
    "            tess_points_dict[(placeid, scenario)] = tess_points\n",
    "        else:\n",
    "            print(f\"Missing: {tess_points_gpkg}\")\n",
    "            tess_points_dict[(placeid, scenario)] = None\n",
    "        \n",
    "        # get ltn points\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            ltn_points_gpkg = os.path.join(base_folder, f\"{placeid}_ltn_points.gpkg\")\n",
    "            if os.path.exists(ltn_points_gpkg):\n",
    "                ltn_points = gpd.read_file(ltn_points_gpkg)\n",
    "                ltn_points_dict[(placeid, scenario)] = ltn_points\n",
    "            else:\n",
    "                print(f\"Missing: {ltn_points_gpkg}\")\n",
    "                ltn_points_dict[(placeid, scenario)] = None\n",
    "        \n",
    "        # get combined points\n",
    "        combined_points_gpkg = os.path.join(base_folder, f\"{placeid}_combined_points.gpkg\")\n",
    "        if os.path.exists(combined_points_gpkg):\n",
    "            combined_points = gpd.read_file(combined_points_gpkg)\n",
    "            combined_points_dict[(placeid, scenario)] = combined_points\n",
    "        else:\n",
    "            print(f\"Missing: {combined_points_gpkg}\")\n",
    "            combined_points_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # get all neighbourhoods (ragardless of their low traffic status. This doesn't change by scenario)\n",
    "        all_neighbourhoods = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + 'neighbourhoods_'+  placeid + '.gpkg')\n",
    "        all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n",
    "        all_neighbourhoods_centroids = gpd.GeoDataFrame(geometry= all_neighbourhoods_centroids, crs=all_neighbourhoods.crs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "def csv_to_ox(p, placeid, parameterid):\n",
    "    '''\n",
    "    Load graph from csv files (nodes and edge)\n",
    "    Include OSMID, length, highway, x, y attributes\n",
    "    '''\n",
    "\n",
    "    prefix = placeid + '_' + parameterid\n",
    "    compress = utils.check_extract_zip(p, prefix)\n",
    "    \n",
    "    with open(p + prefix + '_edges.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        lines = []\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = str(eval(line_list[header.index(\"osmid\")])[0]) if isinstance(eval(line_list[header.index(\"osmid\")]), list) else line_list[header.index(\"osmid\")]\n",
    "            length = str(eval(line_list[header.index(\"length\")])[0]) if isinstance(eval(line_list[header.index(\"length\")]), list) else line_list[header.index(\"length\")]\n",
    "            highway = line_list[header.index(\"highway\")]\n",
    "            if highway.startswith(\"[\") and highway.endswith(\"]\"):\n",
    "                highway = highway.strip(\"[]\").split(\",\")[0].strip(\" '\")\n",
    "            line_string = f\"{line_list[header.index('u')]} {line_list[header.index('v')]} {osmid} {length} {highway}\"\n",
    "            lines.append(line_string)\n",
    "        G = nx.parse_edgelist(lines, nodetype=int, data=((\"osmid\", int), (\"length\", float), (\"highway\", str)), create_using=nx.MultiDiGraph)\n",
    "    \n",
    "    with open(p + prefix + '_nodes.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        values_x = {}\n",
    "        values_y = {}\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = int(line_list[header.index(\"osmid\")])\n",
    "            values_x[osmid] = float(line_list[header.index(\"x\")])\n",
    "            values_y[osmid] = float(line_list[header.index(\"y\")])\n",
    "        nx.set_node_attributes(G, values_x, \"x\")\n",
    "        nx.set_node_attributes(G, values_y, \"y\")\n",
    "    \n",
    "    if compress:\n",
    "        os.remove(p + prefix + '_nodes.csv')\n",
    "        os.remove(p + prefix + '_edges.csv')\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis saving setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res_pickle_paths = {}  \n",
    "analysis_res_json_paths    = {}  \n",
    "analysis_results          = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle_paths[scenario] = os.path.join(PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_{scenario}_analysis_results.pickle\")\n",
    "    analysis_res_json_paths[scenario] = os.path.join(PATH[\"results\"], placeid + \"/\" + scenario + \"/\" + f\"{placeid}_{scenario}_analysis_results.json\")\n",
    "    analysis_results[scenario] = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelimiary Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length - finding the distance of the connected network, along with the investment distance (length - existing infrastructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    G_biketrack = G_biketracks_dict.get((placeid, scenario))\n",
    "    G_biketrack_no_ltn = G_biketrack_no_ltns_dict.get((placeid, scenario))\n",
    "    GTs = demand_results.get(scenario, {}).get(placeid, {}).get(\"GTs\", [])\n",
    "\n",
    "    if not (G_biketrack and G_biketrack_no_ltn and GTs):\n",
    "        print(f\"Missing data for {placeid} - {scenario}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # File paths\n",
    "    analysis_res_pickle = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.pickle\")\n",
    "    analysis_res_csv    = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.csv\")\n",
    "    output_path         = os.path.join(PATH[\"plots\"], placeid, scenario, \"allLengths.png\")\n",
    "\n",
    "    # Load existing results\n",
    "    if os.path.exists(analysis_res_pickle):\n",
    "        with open(analysis_res_pickle, 'rb') as f:\n",
    "            analysis_results[scenario] = pickle.load(f)\n",
    "    else:\n",
    "        analysis_results[scenario] = {}\n",
    "\n",
    "    # Calculations\n",
    "    total_biketrack        = sum(nx.get_edge_attributes(G_biketrack, 'length').values())\n",
    "    total_biketrack_no_ltn = sum(nx.get_edge_attributes(G_biketrack_no_ltn, 'length').values())\n",
    "    total_network          = sum(nx.get_edge_attributes(GTs[-1], 'length').values())\n",
    "    investment_length      = sum(\n",
    "        data.get('length', 0) * distance_cost.get(data.get('highway', 'unclassified'), 1)\n",
    "        for _, _, data in GTs[-1].edges(data=True))\n",
    "\n",
    "    length_stats = {'length_comparison_labels': [ \"Existing Cycle Infrastructure (Including LTNs)\", \"Existing Cycle Infrastructure (Excluding LTNs)\", \"LTNs\", \"Fully Connected Cycle Network\", \"Investment Distance\"],\n",
    "        'length_comparison_values': [total_biketrack, total_biketrack_no_ltn, abs(total_biketrack - total_biketrack_no_ltn), total_network, investment_length],\n",
    "        'length_comparison_colors': ['deepskyblue'] * 5,\n",
    "        'total_network_length': total_network,\n",
    "        'total_biketrack_length': total_biketrack,\n",
    "        'total_biketrack_no_ltn_length': total_biketrack_no_ltn,\n",
    "        'length_difference': abs(total_biketrack - total_biketrack_no_ltn),\n",
    "        'total_investment_length': investment_length}\n",
    "\n",
    "    # Save to pickle & CSV\n",
    "    analysis_results[scenario].update(length_stats)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results[scenario], f)\n",
    "    analysis_res_json = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.json\")\n",
    "    with open(analysis_res_json, 'w') as f:\n",
    "        json.dump(analysis_results[scenario], f, indent=2)\n",
    "    # removed csv - can't take columns with different lengths\n",
    "    #pd.DataFrame({k: [v] for k, v in analysis_results[scenario].items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(\n",
    "        analysis_results[scenario]['length_comparison_labels'],\n",
    "        analysis_results[scenario]['length_comparison_values'],\n",
    "        color=analysis_results[scenario]['length_comparison_colors']\n",
    "    )\n",
    "    plt.xlabel('Network Type')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'{placeid} - {scenario} - Lengths of Cycle Networks')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ltn_difference = abs(total_biketrack - total_biketrack_no_ltn)\n",
    "    labels = [\"Total Cycle Infrastructure\", \"Protected Cycle Infrastructure\",\"LTNs\"]\n",
    "    values = [total_biketrack, total_biketrack_no_ltn, ltn_difference]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, values, color=['deepskyblue'] * 3)\n",
    "    plt.xlabel('Network Type')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'{placeid} - {scenario} - Total Lengths of Cycle Infrastructure')\n",
    "    plt.tight_layout()\n",
    "    output_path_total = os.path.join(PATH[\"plots\"], placeid, scenario, \"TotalLengthsCycleNet.png\")\n",
    "    plt.savefig(output_path_total, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Completed {placeid} - {scenario}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pure length - how is the budget used per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'total_lengths' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        total_lengths_betweenness = utils.compute_total_lengths(GTs_betweenness)\n",
    "        total_lengths_demand = utils.compute_total_lengths(GTs_demand)\n",
    "        total_lengths_random_runs = [utils.compute_total_lengths(run[\"GTs\"]) for run in random_runs]\n",
    "        total_lengths_random_mean = np.mean(total_lengths_random_runs, axis=0).tolist()\n",
    "\n",
    "        # save results\n",
    "        results_list.append((\"Betweenness Growth - Total Length\", total_lengths_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Length\", total_lengths_demand))\n",
    "        for i, run_lengths in enumerate(total_lengths_random_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length\", run_lengths))\n",
    "        results_list.append((\"Random Growth (mean) - Total Length\", total_lengths_random_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            total_lengths_demand_ltn_priority = utils.compute_total_lengths(GTs_demand_ltn_priority)\n",
    "            total_lengths_betweenness_ltn_priority = utils.compute_total_lengths(GTs_betweenness_ltn_priority)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length\", total_lengths_demand_ltn_priority))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length\", total_lengths_betweenness_ltn_priority))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Total Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario]['Random Growth (mean) - Total Length'], linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario]['Betweenness Growth - Total Length'], '-', label='Betweenness Growth', color='orange')\n",
    "    plt.plot(analysis_results[scenario]['Demand Growth - Total Length'], '-.', label='Demand Growth', color='red')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario]['Demand LTN Priority Growth - Total Length'], ':', label='Demand LTN Priority Growth', color='green')\n",
    "        plt.plot(analysis_results[scenario]['Betweenness LTN Priority Growth - Total Length'], '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'Length of Invested Cycle Network for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"L_of_Investment.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviation from random - pure length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or not any(k.endswith(\"Deviation from Random\") for k in analysis_results[scenario]):\n",
    "        baseline = analysis_results[scenario]['Random Growth (mean) - Total Length']\n",
    "        results_list = []\n",
    "        # Calculate deviation from random baseline\n",
    "        results_list.append((\n",
    "            \"Betweenness Growth - Total Length Deviation from Random\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness Growth - Total Length\"], baseline)))\n",
    "        results_list.append((\n",
    "            \"Demand Growth - Total Length Deviation from Random\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Demand Growth - Total Length\"], baseline)))\n",
    "\n",
    "        # Calculate mean deviation for random runs\n",
    "        random_runs_keys = [key for key in analysis_results[scenario] if key.startswith(\"Random Run\") and \"Total Length\" in key]\n",
    "        random_runs = [analysis_results[scenario][key] for key in random_runs_keys]\n",
    "        random_runs_deviations = [utils.compute_abs_deviation(run, baseline) for run in random_runs]\n",
    "        random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Total Length Deviation from Random\", random_deviations_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length Deviation from Random\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Demand LTN Priority Growth - Total Length\"], baseline)))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length Deviation from Random\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Length\"], baseline)))\n",
    "\n",
    "        # Add random runs deviations\n",
    "        for i, dev in enumerate(random_runs_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length Deviation from Random\", dev))\n",
    "\n",
    "        # Save all results as list of (label, data)\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved absolute deviation results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in analysis_results[scenario]:\n",
    "        if key.startswith(\"Random Run\") and \"Deviation from Random\" in key:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plot_lines = [\n",
    "        (\"Betweenness Growth - Total Length Deviation from Random\", '-', 'orange', 'Betweenness Growth'),\n",
    "        (\"Demand Growth - Total Length Deviation from Random\", '-.', 'red', 'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\": plot_lines += [ (\"Demand LTN Priority Growth - Total Length Deviation from Random\", ':', 'green', 'Demand LTN Priority Growth'), (\"Betweenness LTN Priority Growth - Total Length Deviation from Random\", '-', 'purple', 'Betweenness LTN Priority Growth'),]\n",
    "    for key, ls, color, label in plot_lines:\n",
    "        plt.plot(analysis_results[scenario][key], linestyle=ls, color=color, label=label)\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Deviation from Random Growth Baseline (meters)')\n",
    "    plt.title(f'Deviation from Random Growth Baseline for {scenario} - {placeid}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"abs_dev_from_random_length.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Actual\" investment length - how much do we actually need to use to close gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate length, minus the existing infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find how much we actually need to invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Total Investment Length\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        total_investment_betweenness = utils.compute_total_investment_lengths(GTs_betweenness, distance_cost)\n",
    "        total_investment_demand = utils.compute_total_investment_lengths(GTs_demand, distance_cost)\n",
    "        random_runs_investments = [utils.compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs]\n",
    "        random_investment_mean = np.mean(random_runs_investments, axis=0).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Total Investment Length\", total_investment_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Investment Length\", total_investment_demand))\n",
    "        for i, run_lengths in enumerate(random_runs_investments):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Investment Length\", run_lengths))\n",
    "        results_list.append((\"Random Growth (mean) - Total Investment Length\", random_investment_mean))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            total_investment_demand_ltn_priority = utils.compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost)\n",
    "            total_investment_betweenness_ltn_priority = utils.compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Investment Length\", total_investment_demand_ltn_priority))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Investment Length\", total_investment_betweenness_ltn_priority))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated investment cost results for {scenario} in {placeid}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Total Investment Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Total Investment Length\"], linestyle='--', linewidth=2, color='blue', label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Total Investment Length\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Total Investment Length\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Total Investment Length\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Investment Length\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Total Investment Cost (Meters)')\n",
    "    plt.title(f'Total Investment Cost per Growth Strategy for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"total_investment_cost.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or not any(k.endswith(\"Deviation from Random - Total Investment Length\") for k in analysis_results[scenario]):\n",
    "        baseline = analysis_results[scenario][\"Random Growth (mean) - Total Investment Length\"]\n",
    "        results_list = []\n",
    "\n",
    "        # Compute deviations from random baseline\n",
    "        results_list.append((\"Betweenness Growth - Deviation from Random - Total Investment Length\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness Growth - Total Investment Length\"], baseline)))\n",
    "        results_list.append((\"Demand Growth - Deviation from Random - Total Investment Length\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Demand Growth - Total Investment Length\"], baseline)))\n",
    "        random_keys = [key for key in analysis_results[scenario] if key.startswith(\"Random Run\") and \"Total Investment Length\" in key]\n",
    "        random_runs = [analysis_results[scenario][key] for key in random_keys]\n",
    "        random_deviations = [utils.compute_abs_deviation(run, baseline) for run in random_runs]\n",
    "        mean_random_dev = np.mean(random_deviations, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Deviation from Random - Total Investment Length\", mean_random_dev))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\n",
    "                \"Demand LTN Priority Growth - Deviation from Random - Total Investment Length\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Demand LTN Priority Growth - Total Investment Length\"], baseline)))\n",
    "            results_list.append((\n",
    "                \"Betweenness LTN Priority Growth - Deviation from Random - Total Investment Length\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Investment Length\"], baseline)))\n",
    "        for i, dev in enumerate(random_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - Deviation from Random - Total Investment Length\", dev))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario].update({label: data for label, data in results_list})\n",
    "        print(f\"Saved deviation-from-random investment cost results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in analysis_results[scenario]:\n",
    "        if key.startswith(\"Random Run\") and \"Deviation from Random - Total Investment Length\" in key:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "    plot_lines = [(\"Betweenness Growth - Deviation from Random - Total Investment Length\", '-', 'orange', 'Betweenness Growth'),\n",
    "        (\"Demand Growth - Deviation from Random - Total Investment Length\", '-.', 'red', 'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plot_lines += [ (\"Demand LTN Priority Growth - Deviation from Random - Total Investment Length\", ':', 'green', 'Demand LTN Priority Growth'),\n",
    "                       (\"Betweenness LTN Priority Growth - Deviation from Random - Total Investment Length\", '-', 'purple', 'Betweenness LTN Priority Growth')]\n",
    "\n",
    "    for key, linestyle, color, label in plot_lines:\n",
    "        plt.plot(analysis_results[scenario][key], linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Deviation from Random Growth Baseline (meters × weight)')\n",
    "    plt.title(f'Deviation from Random Growth Baseline (Total Investment Cost) for {scenario} - {placeid}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"abs_dev_from_random_investment_cost.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find comparison between how much we need against full route lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find differance between network size and required investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Length Difference\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        length_diff_betweenness = utils.compute_length_difference(GTs_betweenness)\n",
    "        length_diff_demand = utils.compute_length_difference(GTs_demand)\n",
    "        random_run_differences = [utils.compute_length_difference(run[\"GTs\"]) for run in random_runs]\n",
    "        random_diff_mean = np.mean(random_run_differences, axis=0).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Length Difference\", length_diff_betweenness))\n",
    "        results_list.append((\"Demand Growth - Length Difference\", length_diff_demand))\n",
    "        for i, run_diff in enumerate(random_run_differences):\n",
    "            results_list.append((f\"Random Run {i+1} - Length Difference\", run_diff))\n",
    "        results_list.append((\"Random Growth (mean) - Length Difference\", random_diff_mean))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            length_diff_demand_ltn = utils.compute_length_difference(GTs_demand_ltn_priority)\n",
    "            length_diff_betweenness_ltn = utils.compute_length_difference(GTs_betweenness_ltn_priority)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Length Difference\", length_diff_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Length Difference\", length_diff_betweenness_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved length difference results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Length Difference\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"], linestyle='--', linewidth=2, color='blue', label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Length Difference\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Length Difference\"], '-.', color='red', label='Demand Growth')\n",
    "\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Length Difference\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Length Difference\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Length Difference (meters)\")\n",
    "    plt.title(f\"Difference Between Total Network Size and Investment Size for {scenario} - {placeid}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"length_difference.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Deviation from Random Length Difference\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        baseline = np.array(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"])\n",
    "        deviation_betweenness = (np.array(analysis_results[scenario][\"Betweenness Growth - Length Difference\"]) - baseline).tolist()\n",
    "        deviation_demand = (np.array(analysis_results[scenario][\"Demand Growth - Length Difference\"]) - baseline).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Deviation from Random Length Difference\", deviation_betweenness))\n",
    "        results_list.append((\"Demand Growth - Deviation from Random Length Difference\", deviation_demand))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            deviation_demand_ltn = (np.array(analysis_results[scenario][\"Demand LTN Priority Growth - Length Difference\"]) - baseline).tolist()\n",
    "            deviation_betweenness_ltn = (np.array(analysis_results[scenario][\"Betweenness LTN Priority Growth - Length Difference\"]) - baseline).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - Deviation from Random Length Difference\", deviation_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Deviation from Random Length Difference\", deviation_betweenness_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario].update({k: v for k, v in results_list})\n",
    "        print(f\"Saved deviation-from-random length difference results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Length Difference\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            run_dev = np.array(analysis_results[scenario][key]) - np.array(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"])\n",
    "            plt.plot(run_dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Deviation from Random Length Difference\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Deviation from Random Length Difference\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Deviation from Random Length Difference\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Deviation from Random Length Difference\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random (meters)\")\n",
    "    plt.title(f\"Deviation from Random Growth Strategy for {scenario} - {placeid}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"length_difference_deviation_from_random.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load paths and results for this scenario\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    # Load GTs data per growth strategy\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'total_lengths_vs_investment' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        # Compute total lengths and investment lengths for each growth type\n",
    "        lengths_betweenness = utils.compute_total_lengths(GTs_betweenness)\n",
    "        investment_betweenness = utils.compute_total_investment_lengths(GTs_betweenness, distance_cost)\n",
    "        lengths_demand = utils.compute_total_lengths(GTs_demand)\n",
    "        investment_demand = utils.compute_total_investment_lengths(GTs_demand, distance_cost)\n",
    "        random_lengths_runs = [utils.compute_total_lengths(run[\"GTs\"]) for run in random_runs]\n",
    "        random_investment_runs = [utils.compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs]\n",
    "        random_lengths_mean = np.mean(random_lengths_runs, axis=0).tolist()\n",
    "        random_investment_mean = np.mean(random_investment_runs, axis=0).tolist()\n",
    "        # Append results \n",
    "        results_list.append((\"Betweenness Growth - Total Length\", lengths_betweenness))\n",
    "        results_list.append((\"Betweenness Growth - Total Investment Length\", investment_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Length\", lengths_demand))\n",
    "        results_list.append((\"Demand Growth - Total Investment Length\", investment_demand))\n",
    "        for i, (run_lengths, run_investment) in enumerate(zip(random_lengths_runs, random_investment_runs)):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length\", run_lengths))\n",
    "            results_list.append((f\"Random Run {i+1} - Total Investment Length\", run_investment))\n",
    "        results_list.append((\"Random Growth (mean) - Total Length\", random_lengths_mean))\n",
    "        results_list.append((\"Random Growth (mean) - Total Investment Length\", random_investment_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            lengths_demand_ltn = utils.compute_total_lengths(GTs_demand_ltn_priority)\n",
    "            investment_demand_ltn = utils.compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost)\n",
    "            lengths_betweenness_ltn = utils.compute_total_lengths(GTs_betweenness_ltn_priority)\n",
    "            investment_betweenness_ltn = utils.compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length\", lengths_demand_ltn))\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Investment Length\", investment_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length\", lengths_betweenness_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Investment Length\", investment_betweenness_ltn))\n",
    "        # Save all results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "    # Plotting: investment length vs total length\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        len_key = f\"Random Run {i} - Total Length\"\n",
    "        invest_key = f\"Random Run {i} - Total Investment Length\"\n",
    "        if len_key in analysis_results[scenario] and invest_key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][len_key], analysis_results[scenario][invest_key], \n",
    "                     color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario]['Random Growth (mean) - Total Length'],\n",
    "             analysis_results[scenario]['Random Growth (mean) - Total Investment Length'],\n",
    "             linestyle='--', linewidth=2, label='Random Growth (mean)', color='blue')\n",
    "    plt.plot(analysis_results[scenario]['Betweenness Growth - Total Length'],\n",
    "             analysis_results[scenario]['Betweenness Growth - Total Investment Length'],\n",
    "             '-', label='Betweenness Growth', color='orange')\n",
    "    plt.plot(analysis_results[scenario]['Demand Growth - Total Length'],\n",
    "             analysis_results[scenario]['Demand Growth - Total Investment Length'],\n",
    "             '-.', label='Demand Growth', color='red')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        # Plot LTN priority demand growth\n",
    "        plt.plot(analysis_results[scenario]['Demand LTN Priority Growth - Total Length'],\n",
    "                 analysis_results[scenario]['Demand LTN Priority Growth - Total Investment Length'],\n",
    "                 ':', label='Demand LTN Priority Growth', color='green')\n",
    "\n",
    "        # Plot LTN priority betweenness growth\n",
    "        plt.plot(analysis_results[scenario]['Betweenness LTN Priority Growth - Total Length'],\n",
    "                 analysis_results[scenario]['Betweenness LTN Priority Growth - Total Investment Length'],\n",
    "                 '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "\n",
    "    plt.xlabel('Total Length (meters)')\n",
    "    plt.ylabel('Total Investment Length (meters)')\n",
    "    plt.title(f'Investment Length vs Total Length for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"Investment_vs_Length.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    # Use mean random runs as baseline\n",
    "    random_lengths_mean = np.array(analysis_results[\"Random Growth (mean) - Total Length\"])\n",
    "    random_investments_mean = np.array(analysis_results[\"Random Growth (mean) - Total Investment Length\"])\n",
    "\n",
    "    strategies = {\n",
    "        'Betweenness Growth': {\n",
    "            'lengths': np.array(analysis_results[\"Betweenness Growth - Total Length\"]),\n",
    "            'investments': np.array(analysis_results[\"Betweenness Growth - Total Investment Length\"]),\n",
    "            'color': 'orange', 'marker': 'o'},\n",
    "        'Demand Growth': {\n",
    "            'lengths': np.array(analysis_results[\"Demand Growth - Total Length\"]),\n",
    "            'investments': np.array(analysis_results[\"Demand Growth - Total Investment Length\"]),\n",
    "            'color': 'red', 'marker': 's' },\n",
    "        'Demand LTN Growth': {\n",
    "            'lengths': np.array(analysis_results.get(\"Demand LTN Priority Growth - Total Length\", [])),\n",
    "            'investments': np.array(analysis_results.get(\"Demand LTN Priority Growth - Total Investment Length\", [])),\n",
    "            'color': 'green', 'marker': '^'},\n",
    "        'Betweenness LTN Growth': {\n",
    "            'lengths': np.array(analysis_results.get(\"Betweenness LTN Priority Growth - Total Length\", [])),\n",
    "            'investments': np.array(analysis_results.get(\"Betweenness LTN Priority Growth - Total Investment Length\", [])),\n",
    "            'color': 'purple', 'marker': 'D'}}\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "    random_runs_lengths = analysis_results.get('random_runs_lengths_list', [])\n",
    "    random_runs_investments = analysis_results.get('random_runs_investment_lengths_list', [])\n",
    "    for i in range(len(random_runs_lengths)):\n",
    "        run_lengths = np.array(random_runs_lengths[i])\n",
    "        run_investments = np.array(random_runs_investments[i])\n",
    "        plt.scatter(run_lengths - random_lengths_mean,\n",
    "                    run_investments - random_investments_mean,\n",
    "                    color='lightgray', alpha=0.3, s=10, label='_nolegend_')\n",
    "    for label, data in strategies.items():\n",
    "        if data['lengths'].size == 0 or data['investments'].size == 0:\n",
    "            continue  # skip missing\n",
    "        x_dev = data['lengths'] - random_lengths_mean\n",
    "        y_dev = data['investments'] - random_investments_mean\n",
    "        plt.scatter(x_dev, y_dev, label=label, color=data['color'], marker=data['marker'], alpha=0.8, s=50)\n",
    "\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.xlabel('Deviation in Total Length (m) from Random Growth (mean)')\n",
    "    plt.ylabel('Deviation in Investment Length (m) from Random Growth (mean)')\n",
    "    plt.title(f'Investment Cost vs Length: Deviation from Random ({scenario})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"investment_vs_length_deviation_scatter.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for {scenario} - {placeid}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance gained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to find how much of the existing network is connected per iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total bike network - G_bikeall\n",
    "\n",
    "G'investment_length' - investment size\n",
    "\n",
    "G'length' - length of created network, not including netowrk size\n",
    "\n",
    "need to do a compose of G_bikeall and G in GTs\n",
    "\n",
    "but only compose where infrastucutre is connected to our generated network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of infrastructure connected to generated network, along with the combined length. Thus we now know how much extra cycle network is connected per level of investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand_ltn = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", []) if scenario != \"no_ltn_scenario\" else []\n",
    "    GTs_betweenness_ltn = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", []) if scenario != \"no_ltn_scenario\" else []\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "\n",
    "    if rerun or \"Biketrack Connected Lengths\" not in analysis_results:\n",
    "        results_list = []\n",
    "        gt, bike, combined = utils.compute_biketrack_connected_lengths(GTs_betweenness, G_biketrack)\n",
    "        results_list += [(\"GT Connected Lengths\", gt),\n",
    "            (\"Biketrack Connected Lengths\", bike),\n",
    "            (\"Combined Connected Lengths\", combined),]\n",
    "\n",
    "        random_GT_lengths = []\n",
    "        random_bike_lengths = []\n",
    "        random_comb_lengths = []\n",
    "        for run in random_runs:\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)\n",
    "            random_GT_lengths.append(gt)\n",
    "            random_bike_lengths.append(bike)\n",
    "            random_comb_lengths.append(comb)\n",
    "\n",
    "        for i, run in enumerate(random_bike_lengths):\n",
    "            results_list.append((f\"Random Run {i+1} - Biketrack Connected Lengths\", run))\n",
    "        results_list.append((\"random_runs_biketrack_lengths\", random_bike_lengths))\n",
    "\n",
    "        results_list += [(\"GT Random Mean - Connected Lengths\", np.mean(random_GT_lengths, axis=0).tolist()),\n",
    "            (\"Biketrack Random Mean - Connected Lengths\", np.mean(random_bike_lengths, axis=0).tolist()),\n",
    "            (\"Combined Random Mean - Connected Lengths\", np.mean(random_comb_lengths, axis=0).tolist()),]\n",
    "        gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_demand, G_biketrack)\n",
    "        results_list += [(\"GT Demand Connected Lengths\", gt),\n",
    "            (\"Biketrack Demand Connected Lengths\", bike),\n",
    "            (\"Combined Demand Connected Lengths\", comb),]\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_demand_ltn, G_biketrack)\n",
    "            results_list += [(\"GT Demand LTN Priority Connected Lengths\", gt),\n",
    "                (\"Biketrack Demand LTN Priority Connected Lengths\", bike),\n",
    "                (\"Combined Demand LTN Priority Connected Lengths\", comb),]\n",
    "\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_betweenness_ltn, G_biketrack)\n",
    "            results_list += [(\"GT Betweenness LTN Priority Connected Lengths\", gt),\n",
    "                (\"Biketrack Betweenness LTN Priority Connected Lengths\", bike),\n",
    "                (\"Combined Betweenness LTN Priority Connected Lengths\", comb),]\n",
    "            \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results = {label: data for label, data in results_list}\n",
    "        print(f\"Updated biketrack connected length analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot random runs\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Biketrack Connected Lengths\"\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[\"Biketrack Random Mean - Connected Lengths\"], '--', color='blue', linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[\"Biketrack Connected Lengths\"], '-', color='orange', label=\"Betweenness\")\n",
    "    plt.plot(analysis_results[\"Biketrack Demand Connected Lengths\"], '-.', color='red', label=\"Demand\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[\"Biketrack Demand LTN Priority Connected Lengths\"], ':', color='green', label=\"Demand LTN Priority\")\n",
    "        plt.plot(analysis_results[\"Biketrack Betweenness LTN Priority Connected Lengths\"], '-', color='purple', label=\"Betweenness LTN Priority\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Additional Cycle Infrastructure Connected Length (meters)\")\n",
    "    plt.title(f\"Additional Cycle Infrastructure Connected per Iteration ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"additional_cyclenet_connected.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load paths and results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or \"Connected Biketrack - Deviation from Random\" not in analysis_results:\n",
    "        random_runs = analysis_results.get(\"random_runs_biketrack_lengths\", [])\n",
    "        random_mean = np.mean(random_runs, axis=0)\n",
    "        random_runs_deviations = [np.array(run) - random_mean for run in random_runs]\n",
    "        random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "        deviation_results = {\"Betweenness Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(analysis_results[\"Biketrack Connected Lengths\"], random_mean),\n",
    "            \"Demand Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(analysis_results[\"Biketrack Demand Connected Lengths\"], random_mean),}\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            deviation_results.update({\"Demand LTN Priority Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(\n",
    "                    analysis_results[\"Biketrack Demand LTN Priority Connected Lengths\"], random_mean),\n",
    "                \"Betweenness LTN Priority Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(\n",
    "                    analysis_results[\"Biketrack Betweenness LTN Priority Connected Lengths\"], random_mean),})\n",
    "        results_list = [(k, v) for k, v in deviation_results.items()]\n",
    "        results_list.append((\"Connected Biketrack - Random Deviations (All Runs)\", [d.tolist() for d in random_runs_deviations]))\n",
    "        results_list.append((\"Connected Biketrack - Mean Deviation from Random\", random_deviations_mean))\n",
    "        results_list.append((\"Connected Biketrack - Deviation from Random\", deviation_results))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results.update({k: v for k, v in results_list})\n",
    "        print(f\"Saved biketrack deviation-from-random results for {scenario} in {placeid}\")\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for dev in analysis_results[\"Connected Biketrack - Random Deviations (All Runs)\"]:\n",
    "        plt.plot(dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label=\"Random Growth (mean)\")\n",
    "    strategy_styles = {\"Betweenness Growth - Connected Biketrack Deviation from Random\": ('-', 'orange', \"Betweenness Growth\"),\n",
    "        \"Demand Growth - Connected Biketrack Deviation from Random\": ('-.', 'red', \"Demand Growth\"),\n",
    "        \"Demand LTN Priority Growth - Connected Biketrack Deviation from Random\": (':', 'green', \"Demand LTN Priority Growth\"),\n",
    "        \"Betweenness LTN Priority Growth - Connected Biketrack Deviation from Random\": ('-', 'purple', \"Betweenness LTN Priority Growth\"),}\n",
    "    for key, (style, color, label) in strategy_styles.items():\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], linestyle=style, color=color, label=label)\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Biketrack Connected Length: Deviation from Random Baseline ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"biketrack_connected__deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved biketrack connected deviation plot for {scenario} - {placeid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected Components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of the largest connected component, first a just our investment, then combined with existing network, then by combined but only where its connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'LCC Growth - LCC Length' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        lcc_lengths_betweenness = [utils.get_longest_connected_components(G) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - LCC Length\", lcc_lengths_betweenness))\n",
    "\n",
    "        random_runs_lcc_lengths = [[utils.get_longest_connected_components(G) for G in run[\"GTs\"]] for run in random_runs]\n",
    "        for i, run_lengths in enumerate(random_runs_lcc_lengths):\n",
    "            results_list.append((f\"Random Run {i+1} - LCC Length\", run_lengths))\n",
    "        results_list.append((\"random_runs_lcc_lengths\", random_runs_lcc_lengths))\n",
    "        random_lcc_mean = np.mean(random_runs_lcc_lengths, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - LCC Length\", random_lcc_mean))\n",
    "\n",
    "        lcc_lengths_demand = [utils.get_longest_connected_components(G) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - LCC Length\", lcc_lengths_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            lcc_lengths_demand_ltn_priority = [utils.get_longest_connected_components(G) for G in GTs_demand_ltn_priority]\n",
    "            results_list.append((\"Demand LTN Priority Growth - LCC Length\", lcc_lengths_demand_ltn_priority))\n",
    "            lcc_lengths_betweenness_ltn_priority = [utils.get_longest_connected_components(G) for G in GTs_betweenness_ltn_priority]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - LCC Length\", lcc_lengths_betweenness_ltn_priority))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated LCC analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - LCC Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - LCC Length\"], '--', color='blue', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - LCC Length\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - LCC Length\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - LCC Length\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - LCC Length\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('LCC Length (meters)')\n",
    "    plt.title(f'Largest Connected Component Length per Iteration ({scenario})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"size_of_lcc.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - LCC Length Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_lcc_lengths = analysis_results[scenario].get(\"random_runs_lcc_lengths\", [])\n",
    "        random_lcc_mean = np.array(analysis_results[scenario].get(\"Random Growth (mean) - LCC Length\", []))\n",
    "        random_runs_deviations = [(np.array(run) - random_lcc_mean).tolist() for run in random_runs_lcc_lengths]\n",
    "        random_deviations_mean = np.mean([np.array(dev) for dev in random_runs_deviations], axis=0).tolist()\n",
    "\n",
    "        betw_lcc = np.array(analysis_results[scenario].get(\"Betweenness Growth - LCC Length\", []))\n",
    "        dev_betw = (betw_lcc - random_lcc_mean).tolist()\n",
    "        results_list.append((\"Betweenness Growth - LCC Length Deviation from Random\", dev_betw))\n",
    "        demand_lcc = np.array(analysis_results[scenario].get(\"Demand Growth - LCC Length\", []))\n",
    "        dev_demand = (demand_lcc - random_lcc_mean).tolist()\n",
    "        results_list.append((\"Demand Growth - LCC Length Deviation from Random\", dev_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            demand_ltn_lcc = np.array(analysis_results[scenario].get(\"Demand LTN Priority Growth - LCC Length\", []))\n",
    "            dev_demand_ltn = (demand_ltn_lcc - random_lcc_mean).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - LCC Length Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            betw_ltn_lcc = np.array(analysis_results[scenario].get(\"Betweenness LTN Priority Growth - LCC Length\", []))\n",
    "            dev_betw_ltn = (betw_ltn_lcc - random_lcc_mean).tolist()\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - LCC Length Deviation from Random\", dev_betw_ltn))\n",
    "\n",
    "        for i, dev_series in enumerate(random_runs_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - LCC Length Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - LCC Length Deviation from Random\", random_deviations_mean))\n",
    "\n",
    "        # Save \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved LCC deviation-from-random results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - LCC Length Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "    strategy_lines = [(\"Betweenness Growth - LCC Length Deviation from Random\",    '-',  'orange',  'Betweenness Growth'),\n",
    "        (\"Demand Growth - LCC Length Deviation from Random\",         '-.', 'red',     'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        strategy_lines += [(\"Demand LTN Priority Growth - LCC Length Deviation from Random\",    ':',  'green',  'Demand LTN Priority Growth'),\n",
    "            (\"Betweenness LTN Priority Growth - LCC Length Deviation from Random\", '-', 'purple', 'Betweenness LTN Priority Growth'),]\n",
    "    for key, ls, color, label in strategy_lines:\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], linestyle=ls, color=color, label=label)\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Deviation in LCC Length from Random Baseline ({scenario})\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"lcc_length_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved LCC deviation plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCC including any addtionally connected cycle track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_composite_lcc_length` funciton is pretty slow currently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    G_biketrack = G_biketracks_dict.get((placeid, scenario))\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Composite LCC Length\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        comp_lcc_betw = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Composite LCC Length\", comp_lcc_betw))\n",
    "        random_comp_lcc_runs = [[utils.get_composite_lcc_length(G, G_biketrack) for G in run[\"GTs\"]] for run in random_runs]\n",
    "        for i, run_lengths in enumerate(random_comp_lcc_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Composite LCC Length\", run_lengths))\n",
    "        results_list.append((\"random_runs_composite_lcc_lengths\", random_comp_lcc_runs))\n",
    "        random_comp_lcc_mean = np.mean(random_comp_lcc_runs, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Composite LCC Length\", random_comp_lcc_mean))\n",
    "        comp_lcc_demand = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Composite LCC Length\", comp_lcc_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            comp_lcc_demand_ltn = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_demand_ltn_priority]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Composite LCC Length\", comp_lcc_demand_ltn))\n",
    "            comp_lcc_betw_ltn = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_betweenness_ltn_priority]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Composite LCC Length\", comp_lcc_betw_ltn))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated composite LCC analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Composite LCC Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Composite LCC Length\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Composite LCC Length\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Composite LCC Length\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Demand LTN Priority Growth - Composite LCC Length\"],\n",
    "            \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Betweenness LTN Priority Growth - Composite LCC Length\"],\n",
    "            \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Composite LCC Length (meters)\")\n",
    "    plt.title(f\"Composite LCC Length per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"size_of_composite_lcc.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load \n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - Composite LCC Length Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_composite = analysis_results[scenario].get(\"random_runs_composite_lcc_lengths\", [])\n",
    "        random_composite_mean = np.array(analysis_results[scenario].get(\"Random Growth (mean) - Composite LCC Length\", []))\n",
    "        random_runs_dev = [\n",
    "            (np.array(run) - random_composite_mean).tolist()\n",
    "            for run in random_runs_composite\n",
    "        ]\n",
    "        random_dev_mean = np.mean([np.array(dev) for dev in random_runs_dev], axis=0).tolist()\n",
    "\n",
    "        comp_betw = np.array(analysis_results[scenario].get(\"Betweenness Growth - Composite LCC Length\", []))\n",
    "        dev_betw = (comp_betw - random_composite_mean).tolist()\n",
    "        results_list.append((\"Betweenness Growth - Composite LCC Length Deviation from Random\", dev_betw))\n",
    "\n",
    "    \n",
    "        comp_demand = np.array(analysis_results[scenario].get(\"Demand Growth - Composite LCC Length\", []))\n",
    "        dev_demand = (comp_demand - random_composite_mean).tolist()\n",
    "        results_list.append((\"Demand Growth - Composite LCC Length Deviation from Random\", dev_demand))\n",
    "\n",
    "        \n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            comp_demand_ltn = np.array(analysis_results[scenario].get(\"Demand LTN Priority Growth - Composite LCC Length\", []))\n",
    "            dev_demand_ltn = (comp_demand_ltn - random_composite_mean).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - Composite LCC Length Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            comp_betw_ltn = np.array(analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Composite LCC Length\", []))\n",
    "            dev_betw_ltn = (comp_betw_ltn - random_composite_mean).tolist()\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Composite LCC Length Deviation from Random\", dev_betw_ltn))\n",
    "\n",
    "        \n",
    "        for i, dev_series in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Composite LCC Length Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - Composite LCC Length Deviation from Random\", random_dev_mean))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved composite LCC deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Composite LCC Length Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Composite LCC Length Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Composite LCC Length Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Composite LCC Length Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Composite LCC Length Deviation from Random\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Composite LCC Length Deviation from Random ({scenario})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"composite_lcc_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnected Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many seperate disconnected components we have per iteration - this is currently very slow! any speeding up would be useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    G_biketrack = G_biketracks_dict.get((placeid, scenario))\n",
    "    if G_biketrack and G_biketrack.is_directed():\n",
    "        G_biketrack = G_biketrack.to_undirected()\n",
    "\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand      = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn        = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn   = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Num Components\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        comp_betw_series = utils.count_disconnected_components(GTs_betweenness, G_biketrack).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Num Components\", comp_betw_series))\n",
    "        random_comp_runs = []\n",
    "        for run in random_runs:\n",
    "            run_series = utils.count_disconnected_components(run[\"GTs\"], G_biketrack).tolist()\n",
    "            random_comp_runs.append(run_series)\n",
    "        for i, run_series in enumerate(random_comp_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Num Components\", run_series))\n",
    "        results_list.append((\"random_runs_num_components\", random_comp_runs))\n",
    "        if random_comp_runs:\n",
    "            random_array = np.array(random_comp_runs)\n",
    "            random_mean = np.nanmean(random_array, axis=0).tolist()\n",
    "        else:\n",
    "            random_mean = []\n",
    "        results_list.append((\"Random Growth (mean) - Num Components\", random_mean))\n",
    "\n",
    "        comp_demand_series = utils.count_disconnected_components(GTs_demand, G_biketrack).tolist()\n",
    "        results_list.append((\"Demand Growth - Num Components\", comp_demand_series))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            comp_demand_ltn = utils.count_disconnected_components(GTs_demand_ltn, G_biketrack).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - Num Components\", comp_demand_ltn))\n",
    "            comp_betw_ltn = utils.count_disconnected_components(GTs_betweenness_ltn, G_biketrack).tolist()\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Num Components\", comp_betw_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated component-count analysis for {scenario} in {placeid}\")\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Num Components\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Num Components\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Num Components\"],\"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Num Components\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Num Components\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Num Components\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Number of Disconnected Components\")\n",
    "    plt.title(f\"Disconnected Component Count per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"num_components.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved component-count plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation from random growth \n",
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    random_keys = [k for k in analysis_results[scenario] if k.startswith(\"Random Run\") and \"Num Components\" in k]\n",
    "    if not random_keys:\n",
    "        print(f\"No random runs for {placeid} in {scenario}, skipping component-count deviation.\")\n",
    "        continue\n",
    "\n",
    "    baseline = analysis_results[scenario].get(\"Random Growth (mean) - Num Components\", [])\n",
    "    if rerun or \"Betweenness Growth - Num Components Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        series_betw = analysis_results[scenario].get(\"Betweenness Growth - Num Components\", [])\n",
    "        dev_betw = utils.compute_abs_deviation(series_betw, baseline)\n",
    "        results_list.append((\"Betweenness Growth - Num Components Deviation from Random\", dev_betw))\n",
    "        series_demand = analysis_results[scenario].get(\"Demand Growth - Num Components\", [])\n",
    "        dev_demand = utils.compute_abs_deviation(series_demand, baseline)\n",
    "        results_list.append((\"Demand Growth - Num Components Deviation from Random\", dev_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            series_demand_ltn = analysis_results[scenario].get(\"Demand LTN Priority Growth - Num Components\", [])\n",
    "            dev_demand_ltn = utils.compute_abs_deviation(series_demand_ltn, baseline)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Num Components Deviation from Random\", dev_demand_ltn))\n",
    "            series_betw_ltn = analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Num Components\", [])\n",
    "            dev_betw_ltn = utils.compute_abs_deviation(series_betw_ltn, baseline)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Num Components Deviation from Random\", dev_betw_ltn))\n",
    "        random_runs_series = [analysis_results[scenario][k] for k in random_keys]\n",
    "        random_runs_dev = [utils.compute_abs_deviation(run, baseline) for run in random_runs_series]\n",
    "        for i, dev in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Num Components Deviation from Random\", dev))\n",
    "        random_dev_mean = np.mean(random_runs_dev, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Num Components Deviation from Random\", random_dev_mean))\n",
    "\n",
    "        # Save \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved component-count deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "    # plot \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i+1} - Num Components Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Num Components Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Num Components Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Num Components Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Num Components Deviation from Random\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random (Num Components)\")\n",
    "    plt.title(f\"Component-Count Deviation from Random ({scenario} - {placeid})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"num_components_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved component-count deviation plot for {placeid} - {scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to running any coverage analysis, we create buffers of each graph to avoid re-calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    base_path = os.path.abspath(os.path.join(PATH[\"results\"], placeid, scenario))\n",
    "    GTs_buffers = utils.process_and_save_buffers_parallel(GTs, \"GTs_buffers\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_demand = utils.process_and_save_buffers_parallel(GTs_demand, \"GTs_buffers_demand\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_demand_ltn_priority = utils.process_and_save_buffers_parallel(GTs_demand_ltn_priority, \"GTs_buffers_demand_ltn_priority\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_betweenness_ltn_priority = utils.process_and_save_buffers_parallel(GTs_betweenness_ltn_priority, \"GTs_buffers_betweenness_ltn_priority\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    # For multiple random runs\n",
    "    GTs_buffers_random_all = []\n",
    "    for run_id, run_res in enumerate(random_runs, start=1):\n",
    "        name = f\"GTs_buffers_random_run{run_id:02d}\"\n",
    "        buffers = utils.process_and_save_buffers_parallel(run_res[\"GTs\"], name, rerun, base_path, params[\"buffer_walk\"])\n",
    "        GTs_buffers_random_all.append(buffers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Area analysis cell\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'buffer_areas' not in analysis_results:\n",
    "#     target_crs = \"EPSG:3857\"\n",
    "#     boundary_proj = boundary.to_crs(target_crs)\n",
    "#     total_area = boundary_proj.unary_union.area\n",
    "\n",
    "#     def compute_metrics(buffer_list):\n",
    "#         areas = []\n",
    "#         percentages = []\n",
    "#         for gdf in buffer_list:\n",
    "#             gdf_proj = gdf.to_crs(target_crs)\n",
    "#             inter = gpd.overlay(gdf_proj, boundary_proj, how='intersection')\n",
    "#             inter_area = inter.unary_union.area if not inter.empty else 0\n",
    "#             areas.append(inter_area / 1e6)  # Convert m² to km²\n",
    "#             percentages.append((inter_area / total_area * 100) if total_area else 0)\n",
    "#         return areas, percentages\n",
    "\n",
    "#     buffer_metrics = {\n",
    "#         'buffer_areas': compute_metrics(GTs_buffers)[0],\n",
    "#         'buffer_percentages': compute_metrics(GTs_buffers)[1],\n",
    "#         'random_buffer_areas': compute_metrics(GTs_buffers_random)[0],\n",
    "#         'random_buffer_percentages': compute_metrics(GTs_buffers_random)[1],\n",
    "#         'demand_buffer_areas': compute_metrics(GTs_buffers_demand)[0],\n",
    "#         'demand_buffer_percentages': compute_metrics(GTs_buffers_demand)[1],\n",
    "#         'demand_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[0],\n",
    "#         'demand_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[1],\n",
    "#         'betweenness_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "#         'betweenness_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(buffer_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting - Area (km²)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['buffer_areas'], \n",
    "#     color='orange', \n",
    "#     linestyle='-', \n",
    "#     label='Betweenness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['random_buffer_areas'], \n",
    "#     color='blue', \n",
    "#     linestyle='--', \n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_areas'], \n",
    "#     color='red', \n",
    "#     linestyle='-.', \n",
    "#     label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_areas_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['betweenness_buffer_areas_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Area (km²)')\n",
    "# plt.title('Total Area Coverage')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/area_coverage_km2.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Plotting - Percentage Coverage\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['buffer_percentages'], \n",
    "#     color='orange', \n",
    "#     linestyle='-', \n",
    "#     label='Betweeness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['random_buffer_percentages'], \n",
    "#     color='blue', \n",
    "#     linestyle='--', \n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_percentages'], \n",
    "#     color='red', \n",
    "#     linestyle='-.', \n",
    "#     label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_percentages_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['betweenness_buffer_percentages_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Boundary Coverage')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/boundary_cov_percentage.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streets coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Street Coverage %\" not in analysis_results:\n",
    "        results_list = []\n",
    "        edges = G_biketrackcarall_edges_dict.get((placeid, scenario))\n",
    "        if edges is None or edges.empty:\n",
    "            print(f\"Skipping {placeid} ({scenario}): No street network available.\")\n",
    "            continue\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Street Coverage m\", utils.compute_street_coverage(GTs_buffers, edges)[0]))\n",
    "        results_list.append((\"Betweenness Growth - Street Coverage %\", utils.compute_street_coverage(GTs_buffers, edges)[1]))\n",
    "        results_list.append((\"Demand Growth - Street Coverage m\", utils.compute_street_coverage(GTs_buffers_demand, edges)[0]))\n",
    "        results_list.append((\"Demand Growth - Street Coverage %\", utils.compute_street_coverage(GTs_buffers_demand, edges)[1]))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\"Demand LTN Priority Growth - Street Coverage m\", utils.compute_street_coverage(GTs_buffers_demand_ltn_priority, edges)[0]))\n",
    "            results_list.append((\"Demand LTN Priority Growth - Street Coverage %\", utils.compute_street_coverage(GTs_buffers_demand_ltn_priority, edges)[1]))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Street Coverage m\", utils.compute_street_coverage(GTs_buffers_betweenness_ltn_priority, edges)[0]))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Street Coverage %\", utils.compute_street_coverage(GTs_buffers_betweenness_ltn_priority, edges)[1]))\n",
    "        for i, random_buffers in enumerate(GTs_buffers_random_all):\n",
    "            m_list, pct_list = utils.compute_street_coverage(random_buffers, edges)\n",
    "            results_list.append((f\"Random Run {i+1} - Street Coverage m\", m_list))\n",
    "            results_list.append((f\"Random Run {i+1} - Street Coverage %\", pct_list))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results = {label: data for label, data in results_list}\n",
    "        print(f\"Updated street coverage results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Street Coverage m\"\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], color=\"lightgray\", alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[\"Betweenness Growth - Street Coverage m\"], \"-\", label=\"Betweenness\")\n",
    "    plt.plot(analysis_results[\"Demand Growth - Street Coverage m\"], \"-.\", label=\"Demand\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[\"Demand LTN Priority Growth - Street Coverage m\"], \":\", label=\"Demand LTN Priority\")\n",
    "        plt.plot(analysis_results[\"Betweenness LTN Priority Growth - Street Coverage m\"], \"--\", label=\"Betweenness LTN Priority\")\n",
    "    plt.title(f\"Street Network Length within Buffers ({scenario})\")\n",
    "    plt.xlabel(\"Growth Iteration\")\n",
    "    plt.ylabel(\"Street Coverage (meters)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    outpath = os.path.join(PATH[\"plots\"], placeid, scenario, \"street_coverage_m.png\")\n",
    "    os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # plot percentage coverage\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Street Coverage %\"\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], color=\"lightgray\", alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[\"Betweenness Growth - Street Coverage %\"], \"-\", label=\"Betweenness\")\n",
    "    plt.plot(analysis_results[\"Demand Growth - Street Coverage %\"], \"-.\", label=\"Demand\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[\"Demand LTN Priority Growth - Street Coverage %\"], \":\", label=\"Demand LTN Priority\")\n",
    "        plt.plot(analysis_results[\"Betweenness LTN Priority Growth - Street Coverage %\"], \"--\", label=\"Betweenness LTN Priority\")\n",
    "    plt.title(f\"Street Network Coverage Percentage ({scenario})\")\n",
    "    plt.xlabel(\"Growth Iteration\")\n",
    "    plt.ylabel(\"Street Coverage (%)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    outpath = os.path.join(PATH[\"plots\"], placeid, scenario, \"street_coverage_pct.png\")\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "\n",
    "\n",
    "# if rerun or 'street_lengths' not in analysis_results:\n",
    "#     network_crs = G_biketrackcarall_edges.crs\n",
    "#     total_network_length = G_biketrackcarall_edges[\"length\"].sum()\n",
    "\n",
    "#     # simplfy to reduce computation time\n",
    "#     proj_crs = network_crs if network_crs.is_projected else \"EPSG:3857\"\n",
    "#     edges_proj = G_biketrackcarall_edges.to_crs(proj_crs)\n",
    "#     edges_simpl = edges_proj.copy()\n",
    "#     edges_simpl.geometry = edges_proj.geometry.simplify(tolerance=10,\n",
    "#                                                          preserve_topology=True)\n",
    "#     edges_simpl = edges_simpl.to_crs(network_crs)\n",
    "\n",
    "#     def compute_street_coverage(buffer_list):\n",
    "#         lengths = []\n",
    "#         percentages = []\n",
    "#         for gdf in buffer_list:\n",
    "#             gdf_proj = gdf.to_crs(network_crs)\n",
    "#             # simplfy to reduce computation time\n",
    "#             gdf_proj = gdf.to_crs(proj_crs).copy()\n",
    "#             gdf_proj.geometry = gdf_proj.geometry.simplify(tolerance=10,\n",
    "#                                                            preserve_topology=True)\n",
    "#             gdf_proj = gdf_proj.to_crs(network_crs)\n",
    "            \n",
    "#             inter = gpd.overlay(G_biketrackcarall_edges, gdf_proj, how='intersection')\n",
    "#             seg_length = inter[\"length\"].sum() if not inter.empty else 0\n",
    "#             lengths.append(seg_length)\n",
    "#             percentages.append((seg_length / total_network_length * 100) if total_network_length else 0)\n",
    "#         return lengths, percentages\n",
    "\n",
    "#     street_metrics = {\n",
    "#         'street_cov_lengths': compute_street_coverage(GTs_buffers)[0],\n",
    "#         'street_cov_percentages': compute_street_coverage(GTs_buffers)[1],\n",
    "#         'random_street_cov_lengths': compute_street_coverage(GTs_buffers_random)[0],\n",
    "#         'random_street_cov_percentages': compute_street_coverage(GTs_buffers_random)[1],\n",
    "#         'demand_street_cov_lengths': compute_street_coverage(GTs_buffers_demand)[0],\n",
    "#         'demand_street_cov_percentages': compute_street_coverage(GTs_buffers_demand)[1],\n",
    "#         'demand_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[0],\n",
    "#         'demand_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[1],\n",
    "#         'betweenness_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "#         'betweenness_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(street_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot: Network Length within Buffers\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(analysis_results['street_cov_lengths'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "# plt.plot(analysis_results['random_street_cov_lengths'], color='blue', linestyle='--', label='Random Growth')\n",
    "# plt.plot(analysis_results['demand_street_cov_lengths'], color='red', linestyle='-.', label='Demand Growth')\n",
    "# plt.plot(analysis_results['demand_street_cov_lengths_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "# plt.plot(analysis_results['betweenness_street_cov_lengths_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Street Network Length (m)')\n",
    "# plt.title('Street Network Length within Buffers')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/streets_within_cyclenet.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Plot: Percentage of Network within Buffers\n",
    "# plt.figure(10, 6)\n",
    "# plt.plot(analysis_results['street_cov_percentages'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "# plt.plot(analysis_results['random_street_cov_percentages'], color='blue', linestyle='--', label='Random Growth')\n",
    "# plt.plot(analysis_results['demand_street_cov_percentages'], color='red', linestyle='-.', label='Demand Growth')\n",
    "# plt.plot(analysis_results['demand_street_cov_percentages_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "# plt.plot(analysis_results['betweenness_street_cov_percentages_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Percentage of Total Network within Buffers')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/percentage_within_cyclenet.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get population data from census, asign census data to buildings, find population within cycle route buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get lsoas and population\n",
    "# lsoa_bound = gpd.read_file(PATH[\"data\"] + \"/\" + placeid + \"/lsoa_bound.gpkg\")\n",
    "# boundary = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "# lsoa_bound = gpd.clip(lsoa_bound, boundary)\n",
    "# lsoa_bound = add_lsoa_population(lsoa_bound) # using 2011 census data\n",
    "\n",
    "# # get buildings\n",
    "# buildings = get_building_populations(lsoa_bound, boundary) ## add more detail??\n",
    "# buildings = buildings.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # pop_counts_GT = []\n",
    "# # pop_counts_random_GT = []\n",
    "\n",
    "\n",
    "# # # Function to calculate total pop_count within each buffer\n",
    "# # def calculate_pop_count(buffers_list, buildings):\n",
    "# #     pop_counts = []\n",
    "# #     for buffer in buffers_list:\n",
    "# #         intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "# #         total_pop = intersecting_buildings[\"pop_assigned\"].sum()\n",
    "# #         pop_counts.append(total_pop)\n",
    "# #     return pop_counts\n",
    "\n",
    "# # # Calculate for both sets of buffers\n",
    "# # pop_counts_GT = calculate_pop_count(GTs_buffers, buildings)\n",
    "# # pop_counts_random_GT = calculate_pop_count(GTs_buffers_random, buildings)\n",
    "\n",
    "# # plt.figure(figsize=(10, 5))\n",
    "# # buffer_indices = np.arange(len(GTs_buffers))  # Common x-axis indices for both datasets\n",
    "\n",
    "# # plt.plot(buffer_indices, pop_counts_GT, label=\"GTs Buffers\", linestyle='-', color='blue')\n",
    "# # plt.plot(buffer_indices, pop_counts_random_GT, label=\"Random GTs Buffers\", linestyle='--', color='orange')\n",
    "\n",
    "# # plt.xlabel(\"Buffer Index\")\n",
    "# # plt.ylabel(\"Total Population Count\")\n",
    "# # plt.title(\"Comparison of Population Within Buffers\")\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# # plt.show()\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'pop_counts_GT' not in analysis_results:\n",
    "#     def calculate_pop_count(buffers_list, buildings):\n",
    "#         pop_counts = []\n",
    "#         for buffer in buffers_list:\n",
    "#             intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "#             pop_counts.append(intersecting_buildings[\"pop_assigned\"].sum())\n",
    "#         return pop_counts\n",
    "\n",
    "#     pop_metrics = {\n",
    "#         'pop_counts_GT': calculate_pop_count(GTs_buffers, buildings),\n",
    "#         'pop_counts_random_GT': calculate_pop_count(GTs_buffers_random, buildings),\n",
    "#         'pop_counts_demand_GT': calculate_pop_count(GTs_buffers_demand, buildings)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(pop_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# buffer_indices = np.arange(len(GTs_buffers))\n",
    "\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_GT'],\n",
    "#     label=\"Betweenness Growth\",\n",
    "#     linestyle='-',\n",
    "#     color='orange'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_random_GT'],\n",
    "#     label=\"Random Growth\",\n",
    "#     linestyle='--',\n",
    "#     color='blue'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_demand_GT'],\n",
    "#     label=\"Demand-based Growth\",\n",
    "#     linestyle='-.',\n",
    "#     color='red'\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Buffer Index\")\n",
    "# plt.ylabel(\"Total Population Count\")\n",
    "# plt.title(\"Population Within Buffers Over Investment Iterations\")\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "    combined_points = combined_points_dict.get((placeid, scenario))\n",
    "\n",
    "    if rerun or not any(k.endswith(\"Seed Coverage\") for k in analysis_results):\n",
    "        base_path = os.path.abspath(os.path.join(PATH[\"results\"], placeid, scenario))\n",
    "        \n",
    "        GTs_buffers = utils.load_results(f\"{base_path}_GTs_buffers.pickle\")\n",
    "        GTs_buffers_demand = utils.load_results(f\"{base_path}_GTs_buffers_demand.pickle\")\n",
    "        GTs_buffers_demand_ltn_priority = utils.load_results(f\"{base_path}_GTs_buffers_demand_ltn_priority.pickle\")\n",
    "        GTs_buffers_betweenness_ltn_priority = utils.load_results(f\"{base_path}_GTs_buffers_betweenness_ltn_priority.pickle\")\n",
    "        GTs_buffers_random_all = []\n",
    "        for i in range(1, 100):  # Adjust if fewer runs\n",
    "            path = f\"{base_path}_GTs_buffers_random_run{i:02d}.pickle\"\n",
    "            if os.path.exists(path):\n",
    "                GTs_buffers_random_all.append(utils.load_results(path))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        results_list = []\n",
    "        results_list.append((\"Betweenness Growth - Seed Coverage\", utils.seed_point_coverage(GTs_buffers, combined_points )))\n",
    "        results_list.append((\"Demand Growth - Seed Coverage\", utils.seed_point_coverage(GTs_buffers_demand, combined_points )))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\"Demand LTN Priority Growth - Seed Coverage\", utils.seed_point_coverage(GTs_buffers_demand_ltn_priority, combined_points )))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Seed Coverage\", utils.seed_point_coverage(GTs_buffers_betweenness_ltn_priority, combined_points )))\n",
    "        random_coverages = [utils.seed_point_coverage(bufs, combined_points ) for bufs in GTs_buffers_random_all]\n",
    "        random_mean = np.mean(random_coverages, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Seed Coverage\", random_mean))\n",
    "        for i, coverage in enumerate(random_coverages):\n",
    "            results_list.append((f\"Random Run {i+1} - Seed Coverage\", coverage))\n",
    "\n",
    "        # Save\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results.update({k: v for k, v in results_list})\n",
    "        print(f\"Saved seed coverage results for {scenario} in {placeid}\")\n",
    "\n",
    "        \n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in analysis_results:\n",
    "        if key.startswith(\"Random Run\") and \"Seed Coverage\" in key:\n",
    "            plt.plot(analysis_results[key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plot_lines = [(\"Betweenness Growth - Seed Coverage\", '-', 'orange', 'Betweenness Growth'),\n",
    "        (\"Demand Growth - Seed Coverage\", '-.', 'red', 'Demand Growth'), ]\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plot_lines += [(\"Demand LTN Priority Growth - Seed Coverage\", ':', 'green', 'Demand LTN Priority Growth'),\n",
    "            (\"Betweenness LTN Priority Growth - Seed Coverage\", '-', 'purple', 'Betweenness LTN Priority Growth'), ]\n",
    "    if \"Random Growth (mean) - Seed Coverage\" in analysis_results:\n",
    "        plt.plot(analysis_results[\"Random Growth (mean) - Seed Coverage\"], '--', color='blue', linewidth=2, label=\"Random Growth (mean)\")\n",
    "    for key, ls, color, label in plot_lines:\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], linestyle=ls, color=color, label=label)\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Number of Covered Seed Points\")\n",
    "    plt.title(f\"Seed Point Coverage by Growth Strategy ({scenario} - {placeid})\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"seed_coverage_analysis.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LTN Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # counts_buffers = []\n",
    "# # counts_random = []\n",
    "\n",
    "# # # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# # for gdf in GTs_buffers:\n",
    "# #     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "# #     buffer_union = gdf.unary_union\n",
    "# #     # Count the points that fall within this union\n",
    "# #     count = ltn_points.within(buffer_union).sum()\n",
    "# #     counts_buffers.append(count)\n",
    "\n",
    "# # # Do the same for GTs_buffers_random\n",
    "# # for gdf in GTs_buffers_random:\n",
    "# #     buffer_union = gdf.unary_union\n",
    "# #     count = ltn_points.within(buffer_union).sum()\n",
    "# #     counts_random.append(count)\n",
    "\n",
    "# # # Plotting the results on a line graph\n",
    "# # plt.figure(figsize=(10, 6))\n",
    "# # x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# # plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# # plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# # plt.xlabel('Buffer Index')\n",
    "# # plt.ylabel('Number of Points Covered')\n",
    "# # plt.title('Points Covered by Each Buffer')\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# # plt.show()\n",
    "\n",
    "# # LTN point coverage analysis cell\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {} \n",
    "\n",
    "# if rerun or 'ltn_points_covered_GT' not in analysis_results:\n",
    "#     def compute_ltn_coverage(buffers_list):\n",
    "#         return [\n",
    "#             ltn_points.within(gdf.unary_union).sum()\n",
    "#             for gdf in buffers_list\n",
    "#         ]\n",
    "    \n",
    "#     analysis_results.update({\n",
    "#         'ltn_points_covered_GT': compute_ltn_coverage(GTs_buffers),\n",
    "#         'ltn_points_covered_random': compute_ltn_coverage(GTs_buffers_random),\n",
    "#         'ltn_points_covered_demand': compute_ltn_coverage(GTs_buffers_demand),\n",
    "#         'ltn_points_covered_demand_ltn_priority': compute_ltn_coverage(GTs_buffers_demand_ltn_priority),\n",
    "#         'ltn_points_covered_betweenness_ltn_priority': compute_ltn_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "#     })\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(analysis_results['ltn_points_covered_GT']) + 1)\n",
    "\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['ltn_points_covered_GT'],\n",
    "#     color='orange',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['ltn_points_covered_random'],\n",
    "#     color='blue',\n",
    "#     linestyle='--',\n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['ltn_points_covered_demand'],\n",
    "#     color='red',\n",
    "#     linestyle='-.',\n",
    "#     label='Demand-based Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['ltn_points_covered_demand_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['ltn_points_covered_betweenness_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Number of LTN Points Covered')\n",
    "# plt.title('LTNs Covered by Cycle Network')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/ltns_coverage.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about how if we were to create future LTNs, where could these go based purely on making more cycling safe?\n",
    "\n",
    "# should these be where the most cycling is on? or which area has the longest bit of cycle network added? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # counts_buffers = []\n",
    "# # counts_random = []\n",
    "\n",
    "# # # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# # for gdf in GTs_buffers:\n",
    "# #     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "# #     buffer_union = gdf.unary_union\n",
    "# #     # Count the points in combined_points that fall within this union\n",
    "# #     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "# #     counts_buffers.append(count)\n",
    "\n",
    "# # # Do the same for GTs_buffers_random\n",
    "# # for gdf in GTs_buffers_random:\n",
    "# #     buffer_union = gdf.unary_union\n",
    "# #     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "# #     counts_random.append(count)\n",
    "\n",
    "# # # Plotting the results on a line graph\n",
    "# # plt.figure(figsize=(10, 6))\n",
    "# # x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# # plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# # plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# # plt.xlabel('Buffer Index')\n",
    "# # plt.ylabel('Number of Points Covered')\n",
    "# # plt.title('Points Covered by Each Buffer')\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# # plt.show()\n",
    "# # Neighborhood centroids analysis cell\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {} \n",
    "\n",
    "# if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "#     def count_neighborhood_coverage(buffers_list):\n",
    "#         return [\n",
    "#             all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "#             for gdf in buffers_list\n",
    "#         ]\n",
    "\n",
    "#     neighborhood_metrics = {\n",
    "#         'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "#         'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "#         'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "#         'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "#         'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(neighborhood_metrics)\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(analysis_results['neighborhood_points_covered_GT']) + 1)\n",
    "\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['neighborhood_points_covered_GT'],\n",
    "#     color='orange',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['neighborhood_points_covered_random'],\n",
    "#     color='blue',\n",
    "#     linestyle='--',\n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['neighborhood_points_covered_demand'],\n",
    "#     color='red',\n",
    "#     linestyle='-.',\n",
    "#     label='Demand-based Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['neighborhood_points_covered_demand_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     x_vals,\n",
    "#     analysis_results['neighborhood_points_covered_betweenness_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Neighbourhoods Covered')\n",
    "# plt.title('Neighbourhoods Covered by Cycle Network')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/neighbourhoods_coverage.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## against random baseline\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {} \n",
    "\n",
    "# if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "#     def count_neighborhood_coverage(buffers_list):\n",
    "#         return [\n",
    "#             all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "#             for gdf in buffers_list\n",
    "#         ]\n",
    "\n",
    "#     neighborhood_metrics = {\n",
    "#         'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "#         'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "#         'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "#         'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "#         'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(neighborhood_metrics)\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "\n",
    "#     pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}) \\\n",
    "#         .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Calculate deviation from random\n",
    "# random_coverage = np.array(analysis_results['neighborhood_points_covered_random'])\n",
    "\n",
    "# coverage_deviations = {\n",
    "#     'Betweenness': {\n",
    "#         'values': np.array(analysis_results['neighborhood_points_covered_GT']) - random_coverage,\n",
    "#         'color': 'orange',\n",
    "#         'linestyle': '-'\n",
    "#     },\n",
    "#     'Demand': {\n",
    "#         'values': np.array(analysis_results['neighborhood_points_covered_demand']) - random_coverage,\n",
    "#         'color': 'red',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Demand LTN': {\n",
    "#         'values': np.array(analysis_results['neighborhood_points_covered_demand_ltn_priority']) - random_coverage,\n",
    "#         'color': 'green',\n",
    "#         'linestyle': ':'\n",
    "#     },\n",
    "#     'Betweenness LTN': {\n",
    "#         'values': np.array(analysis_results['neighborhood_points_covered_betweenness_ltn_priority']) - random_coverage,\n",
    "#         'color': 'purple',\n",
    "#         'linestyle': '-'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Plot deviation from random\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(random_coverage) + 1)\n",
    "\n",
    "# for label, data in coverage_deviations.items():\n",
    "#     plt.plot(\n",
    "#         x_vals,\n",
    "#         data['values'],\n",
    "#         linestyle=data['linestyle'],\n",
    "#         color=data['color'],\n",
    "#         label=label\n",
    "#     )\n",
    "\n",
    "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Deviation in Neighbourhoods Covered (vs Random)')\n",
    "# plt.title('Neighbourhood Coverage — Deviation from Random Growth (Baseline)')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save plot\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/neighbourhoods_coverage__deviation_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap with existing infrastructure. Finding how much of the existing network we overlap, in terms of % of total network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness     = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand          = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn        = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn   = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs         = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Overlap Size Percent\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        size_percent_betw = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Overlap Size Percent\", size_percent_betw))\n",
    "        random_runs_size = [\n",
    "            [utils.overlap_size_percent(G_biketrack, G) for G in run[\"GTs\"]]\n",
    "            for run in random_runs\n",
    "        ]\n",
    "        for i, run_sizes in enumerate(random_runs_size):\n",
    "            results_list.append((f\"Random Run {i+1} - Overlap Size Percent\", run_sizes))\n",
    "        results_list.append((\"random_runs_overlap_size_percent\", random_runs_size))\n",
    "        random_size_mean = np.mean(random_runs_size, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Overlap Size Percent\", random_size_mean))\n",
    "        size_percent_demand = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Overlap Size Percent\", size_percent_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            size_percent_demand_ltn = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_demand_ltn]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Overlap Size Percent\", size_percent_demand_ltn))\n",
    "\n",
    "            size_percent_betw_ltn = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_betweenness_ltn]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Overlap Size Percent\", size_percent_betw_ltn))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated overlap-size analysis for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Overlap Size Percent\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Overlap Size Percent\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Overlap Size Percent\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Overlap Size Percent\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Overlap Size Percent\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\" )\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Overlap Size Percent\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Overlap Size (%)\")\n",
    "    plt.title(f\"Overlap with Bike Network per Iteration ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"overlap_size_percent.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved overlap-size plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation from random\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    # load \n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - Overlap Size Percent Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_size = analysis_results[scenario].get(\"random_runs_overlap_size_percent\", [])\n",
    "        random_size_mean = analysis_results[scenario].get(\"Random Growth (mean) - Overlap Size Percent\", [])\n",
    "        random_runs_dev = [utils.compute_abs_deviation(run, random_size_mean) for run in random_runs_size]\n",
    "        random_dev_mean = np.mean([np.array(dev) for dev in random_runs_dev], axis=0).tolist()\n",
    "\n",
    "        betw_series = analysis_results[scenario].get(\"Betweenness Growth - Overlap Size Percent\", [])\n",
    "        dev_betw = utils.compute_abs_deviation(betw_series, random_size_mean)\n",
    "        results_list.append((\"Betweenness Growth - Overlap Size Percent Deviation from Random\", dev_betw))\n",
    "\n",
    "        demand_series = analysis_results[scenario].get(\"Demand Growth - Overlap Size Percent\", [])\n",
    "        dev_demand = utils.compute_abs_deviation(demand_series, random_size_mean)\n",
    "        results_list.append((\"Demand Growth - Overlap Size Percent Deviation from Random\", dev_demand))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            demand_ltn_series = analysis_results[scenario].get(\"Demand LTN Priority Growth - Overlap Size Percent\", [])\n",
    "            dev_demand_ltn = utils.compute_abs_deviation(demand_ltn_series, random_size_mean)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Overlap Size Percent Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            betw_ltn_series = analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Overlap Size Percent\", [])\n",
    "            dev_betw_ltn = utils.compute_abs_deviation(betw_ltn_series, random_size_mean)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Overlap Size Percent Deviation from Random\", dev_betw_ltn))\n",
    "        for i, dev_series in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Overlap Size Percent Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - Overlap Size Percent Deviation from Random\", random_dev_mean))\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved overlap-size deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Overlap Size Percent Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Overlap Size Percent Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Overlap Size Percent Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Overlap Size Percent Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Overlap Size Percent Deviation from Random\"],\"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Overlap (%)\")\n",
    "    plt.title(f\"Overlap Size Percent Deviation from Random ({scenario})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"overlap_size_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved overlap-size deviation plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directness (Directness=Total Sum of Network Distances/Total Sum of Euclidean Distances​)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    # load \n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    GTs_demand      = demand_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority      = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    random_runs = [run[\"GT_abstracts\"] for run in random_results[scenario].get(placeid, [])]\n",
    "    if rerun or \"Betweenness Growth - Directness\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        direct_betw = utils.calc_directness(GTs_betweenness)\n",
    "        results_list.append((\"Betweenness Growth - Directness\", direct_betw))\n",
    "        for i, run_graphs in enumerate(random_runs):\n",
    "            direct_rand = utils.calc_directness(run_graphs)\n",
    "            results_list.append((f\"Random Run {i+1} - Directness\", direct_rand))\n",
    "        random_array = np.array([[val if val is not None else 0 for val in utils.calc_directness(run_graphs)] for run_graphs in random_runs])\n",
    "        if random_array.size > 0:\n",
    "            random_direct_mean = np.nanmean(random_array, axis=0).tolist()\n",
    "        else:\n",
    "            random_direct_mean = []\n",
    "        results_list.append((\"Random Growth (mean) - Directness\", random_direct_mean))\n",
    "        direct_demand = utils.calc_directness(GTs_demand)\n",
    "        results_list.append((\"Demand Growth - Directness\", direct_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            direct_demand_ltn = utils.calc_directness(GTs_demand_ltn_priority)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Directness\", direct_demand_ltn))\n",
    "\n",
    "            direct_betw_ltn = utils.calc_directness(GTs_betweenness_ltn_priority)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Directness\", direct_betw_ltn))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated directness analysis for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Directness\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Directness\"], \"--\", color=\"blue\", linewidth=2, label=\"Random\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Directness\"], \"-\", color=\"orange\", label=\"Betweenness\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Directness\"], \"-.\", color=\"red\", label=\"Demand\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Directness\"], \":\", color=\"green\", label=\"Demand LTN\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Directness\"], \"-\", color=\"purple\", label=\"Betweenness LTN\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Directness (Euclidean / Network)\")\n",
    "    plt.title(f\"Network Directness Comparison ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"directness.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved directness plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcaulate directness of existing network to compare against..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn        = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "        GTs_betweenness_ltn   = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    random_runs = [run[\"GT_abstracts\"] for run in random_results[scenario].get(placeid, [])]\n",
    "    if rerun or \"Betweenness Growth - Global Efficiency\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        eff_betw = [utils.calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight=\"length\") for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Global Efficiency\", eff_betw))\n",
    "        for i, run_graphs in enumerate(random_runs):\n",
    "            eff_rand = [utils.calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight=\"length\") for G in run_graphs]\n",
    "            results_list.append((f\"Random Run {i+1} - Global Efficiency\", eff_rand))\n",
    "        random_array = np.array([run_series for (_, run_series) in results_list if isinstance(run_series, list) and run_series and _ .startswith(\"Random Run\")])\n",
    "        if random_array.size > 0:\n",
    "            random_eff_mean = np.nanmean(random_array, axis=0).tolist()\n",
    "        else:\n",
    "            random_eff_mean = []\n",
    "        results_list.append((\"Random Growth (mean) - Global Efficiency\", random_eff_mean))\n",
    "        eff_demand = [utils.calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight=\"length\") for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Global Efficiency\", eff_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            eff_demand_ltn = [utils.calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight=\"length\") for G in GTs_demand_ltn ]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Global Efficiency\", eff_demand_ltn))\n",
    "            eff_betw_ltn = [utils.calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight=\"length\") for G in GTs_betweenness_ltn]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Global Efficiency\", eff_betw_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated efficiency analysis for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Global Efficiency\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Global Efficiency\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Global Efficiency\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Global Efficiency\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Global Efficiency\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Global Efficiency\"],\"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    " \n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Global Efficiency\")\n",
    "    plt.title(f\"Global Network Efficiency per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"global_eff.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved efficiency plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "        GTs_betweenness_ltn = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "\n",
    "    random_runs = [run[\"GT_abstracts\"] for run in random_results[scenario].get(placeid, [])]\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Local Efficiency\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        # Betweenness\n",
    "        eff_betw = [utils.calculate_local_efficiency(G, numnodepairs=1000, weight=\"length\") for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Local Efficiency\", eff_betw))\n",
    "\n",
    "        # Random runs\n",
    "        for i, run_graphs in enumerate(random_runs):\n",
    "            eff_rand = [utils.calculate_local_efficiency(G, numnodepairs=1000,  weight=\"length\") for G in run_graphs]\n",
    "            results_list.append((f\"Random Run {i+1} - Local Efficiency\", eff_rand))\n",
    "\n",
    "        # Mean random baseline\n",
    "        random_array = np.array([\n",
    "            series for (label, series) in results_list\n",
    "            if isinstance(series, list) and series and label.startswith(\"Random Run\")\n",
    "        ])\n",
    "        random_eff_mean = np.nanmean(random_array, axis=0).tolist() if random_array.size > 0 else []\n",
    "        results_list.append((\"Random Growth (mean) - Local Efficiency\", random_eff_mean))\n",
    "\n",
    "        # Demand\n",
    "        eff_demand = [utils.calculate_local_efficiency(G, numnodepairs=1000, weight=\"length\") for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Local Efficiency\", eff_demand))\n",
    "\n",
    "        # LTN variants\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            eff_demand_ltn = [utils.calculate_local_efficiency(G, numnodepairs=1000, weight=\"length\") for G in GTs_demand_ltn]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Local Efficiency\", eff_demand_ltn))\n",
    "            eff_betw_ltn = [utils.calculate_local_efficiency(G, numnodepairs=1000,  weight=\"length\") for G in GTs_betweenness_ltn]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Local Efficiency\", eff_betw_ltn))\n",
    "\n",
    "        # Save and store\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated local efficiency analysis for {scenario} in {placeid}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Local Efficiency\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Local Efficiency\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Local Efficiency\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Local Efficiency\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Local Efficiency\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Local Efficiency\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Local Efficiency (Normalized)\")\n",
    "    plt.title(f\"Normalized Local Network Efficiency per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"local_eff.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved local efficiency plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclable trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we should calcualte the number of cycleable trips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average node degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average number of connections per node - shows choice of direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific data\n",
    "    G_biketrack = G_biketracks_dict.get((placeid, scenario))\n",
    "    if G_biketrack and G_biketrack.is_directed():\n",
    "        G_biketrack = G_biketrack.to_undirected()\n",
    "\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand      = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn      = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "  \n",
    "    if rerun or \"Betweenness Growth - Avg Node Degree\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        avg_deg_betw = utils.average_node_degree_composed(GTs_betweenness, G_biketrack)\n",
    "        results_list.append((\"Betweenness Growth - Avg Node Degree\", avg_deg_betw))\n",
    "        random_deg_runs = []\n",
    "        for run in random_runs:\n",
    "            run_series = utils.average_node_degree_composed(run[\"GTs\"], G_biketrack)\n",
    "            random_deg_runs.append(run_series)\n",
    "        for i, run_series in enumerate(random_deg_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Avg Node Degree\", run_series))\n",
    "        results_list.append((\"random_runs_avg_node_degree\", random_deg_runs))\n",
    "        if random_deg_runs:\n",
    "            random_array = np.array(random_deg_runs)\n",
    "            random_mean = np.nanmean(random_array, axis=0)\n",
    "        else:\n",
    "            random_mean = []\n",
    "        results_list.append((\"Random Growth (mean) - Avg Node Degree\", random_mean.tolist()))\n",
    "        avg_deg_demand = utils.average_node_degree_composed(GTs_demand, G_biketrack)\n",
    "        results_list.append((\"Demand Growth - Avg Node Degree\", avg_deg_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            avg_deg_demand_ltn = utils.average_node_degree_composed(GTs_demand_ltn, G_biketrack)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Avg Node Degree\", avg_deg_demand_ltn))\n",
    "\n",
    "            avg_deg_betw_ltn = utils.average_node_degree_composed(GTs_betweenness_ltn, G_biketrack)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Avg Node Degree\", avg_deg_betw_ltn))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated avg-node-degree analysis for {scenario} in {placeid}\")\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Avg Node Degree\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    plt.plot( analysis_results[scenario][\"Random Growth (mean) - Avg Node Degree\"],  \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Avg Node Degree\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Avg Node Degree\"],\"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Avg Node Degree\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Avg Node Degree\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Average Node Degree\")\n",
    "    plt.title(f\"Average Node Degree per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"avg_node_degree.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved avg-node-degree plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation from random\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    random_keys = [k for k in analysis_results[scenario] if k.startswith(\"Random Run\") and \"Avg Node Degree\" in k]\n",
    "    if not random_keys:\n",
    "        print(f\"No random runs for {placeid} in {scenario}, skipping avg-node-degree deviation.\")\n",
    "        continue\n",
    "\n",
    "    baseline = analysis_results[scenario].get(\"Random Growth (mean) - Avg Node Degree\", [])\n",
    "    if rerun or \"Betweenness Growth - Avg Node Degree Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        series_betw = analysis_results[scenario].get(\"Betweenness Growth - Avg Node Degree\", [])\n",
    "        dev_betw = utils.compute_abs_deviation(series_betw, baseline)\n",
    "        results_list.append((\"Betweenness Growth - Avg Node Degree Deviation from Random\", dev_betw))\n",
    "        series_demand = analysis_results[scenario].get(\"Demand Growth - Avg Node Degree\", [])\n",
    "        dev_demand = utils.compute_abs_deviation(series_demand, baseline)\n",
    "        results_list.append((\"Demand Growth - Avg Node Degree Deviation from Random\", dev_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            series_demand_ltn = analysis_results[scenario].get(\"Demand LTN Priority Growth - Avg Node Degree\", [])\n",
    "            dev_demand_ltn = utils.compute_abs_deviation(series_demand_ltn, baseline)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Avg Node Degree Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            series_betw_ltn = analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Avg Node Degree\", [])\n",
    "            dev_betw_ltn = utils.compute_abs_deviation(series_betw_ltn, baseline)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Avg Node Degree Deviation from Random\", dev_betw_ltn))\n",
    "        random_runs_series = [analysis_results[scenario][k] for k in random_keys]\n",
    "        random_runs_dev = [utils.compute_abs_deviation(run, baseline) for run in random_runs_series]\n",
    "        for i, dev in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Avg Node Degree Deviation from Random\", dev))\n",
    "        random_dev_mean = np.mean(random_runs_dev, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Avg Node Degree Deviation from Random\", random_dev_mean))\n",
    "\n",
    "        # save \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved avg-node-degree deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i+1} - Avg Node Degree Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot( analysis_results[scenario][\"Betweenness Growth - Avg Node Degree Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Avg Node Degree Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Avg Node Degree Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Avg Node Degree Deviation from Random\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random (Avg Node Degree)\")\n",
    "    plt.title(f\"Avg Node Degree Deviation from Random ({scenario} - {placeid})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"avg_node_degree_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved avg-node-degree deviation plot for {placeid} - {scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Pretty plots of networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed plots of specific networks should go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfinshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack_no_ltn) # no differance?\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
