{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Analysis of bicycle network results\n",
    "## Project: Growing Urban Bicycle Networks with LTNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the existing infrastructure, the results from 03_poi_based_generation and calculates/analyzes a number of measures:\n",
    "* cost (length)\n",
    "* coverage  \n",
    "* directness  \n",
    "* efficiency\n",
    "* overlap with existing networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Speeding up\n",
    "    - The `get_composite_lcc_length` funciton is pretty slow currently!\n",
    "    - Producing buffers for coverage analysis is very slow\n",
    "    - Coverage very slow\n",
    "- find neighbourhoods where large amounts of residiental streets are used to potentially convert to LTNs?\n",
    "- only runs for one place at at time currently (my bad coding skills + getting stuck down rabbitholes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from src import utils\n",
    "PATH = utils.PATH # shortening the var name so that we don't have to change it below\n",
    "\n",
    "# System\n",
    "import csv\n",
    "import os\n",
    "import dill as pickle\n",
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from copy import deepcopy\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "# Math/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Network\n",
    "import networkx as nx\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Geo\n",
    "import osmnx as ox\n",
    "ox.settings.log_file = True\n",
    "ox.settings.requests_timeout = 300\n",
    "ox.settings.logs_folder = PATH[\"logs\"]\n",
    "import geopandas as gpd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "# if not debug: # Only do this if sure the code is bug-free!\n",
    "#     warnings.filterwarnings('ignore')\n",
    "rerun_existing = True # If True, will re-run the costly analysis of existing infra even if files already exist.\n",
    "rerun = True # If True, recompute the analysis. If false, just re-make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.load(\n",
    "    open(\"../parameters/parameters.yml\"), \n",
    "    Loader=yaml.FullLoader)\n",
    "osmnxparameters = json.load(open(\"../parameters/osmnxparameters.json\", \"r\"))\n",
    "plotparam = json.load(open(\"../parameters/plotparam.json\", \"r\"))\n",
    "plotparam_analysis = json.load(open(\"../parameters/plotparam_analysis.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network weighting by tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_lts = json.load(open(\"../parameters/tag_lts.json\", \"r\"))\n",
    "distance_cost = json.load(open(\"../parameters/distance_cost.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cities\n",
    "cities = utils.load_cities(PATH, debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness \n",
    "betweenness_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    betweenness_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_betweenness_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                betweenness_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the betweenness analysis first.\")\n",
    "            print(f\"No betweenness files found for {placeid} in scenario {scenario}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random (many runs to get a distribution)\n",
    "random_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    random_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        pattern = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" +\n",
    "                   f\"{placeid}_poi_{params['poi_source']}_random_weighted_{scenario}_run*.pickle\")\n",
    "        random_files = sorted(glob.glob(os.path.abspath(pattern)))[:3]  # only take the first 3 whilst we debug :D\n",
    "        if random_files:\n",
    "            random_results[scenario][placeid] = []\n",
    "            for fn in random_files:\n",
    "                abs_path = os.path.abspath(fn)\n",
    "                with open(abs_path, \"rb\") as f:\n",
    "                    res = pickle.load(f)\n",
    "                random_results[scenario][placeid].append(res)\n",
    "        else:\n",
    "            print(f\"No random files found for {placeid} in scenario {scenario}.\")\n",
    "            print(\"Please run the random growth analysis first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand\n",
    "demand_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    demand_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_demand_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                demand_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the demand analysis first.\")\n",
    "            print(f\"No demand files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand LTN priority\n",
    "demand_ltn_priority_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    demand_ltn_priority_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_demand_ltn_priority_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                demand_ltn_priority_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the demand LTN priority analysis first.\")\n",
    "            print(f\"No demand LTN priority files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness LTN priority\n",
    "betweenness_ltn_priority_results = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    betweenness_ltn_priority_results[scenario] = {}\n",
    "    for placeid in cities:\n",
    "        filename = (PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_poi_{params['poi_source']}_betweenness_ltn_priority_weighted_\" + scenario + \".pickle\")\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        if os.path.exists(abs_path):\n",
    "            with open(abs_path, \"rb\") as f:\n",
    "                betweenness_ltn_priority_results[scenario][placeid] = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {abs_path} does not exist.\")\n",
    "            print(\"Please run the betweenness LTN priority analysis first.\")\n",
    "            print(f\"No betweenness LTN priority files found for {placeid} in scenario {scenario}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find investment level, split results into GTs, GT_abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario_name in params[\"scenarios\"]:\n",
    "    for placeid in cities:\n",
    "\n",
    "        # Demand \n",
    "        if placeid in demand_results.get(scenario_name, {}):\n",
    "            demand_dict = demand_results[scenario_name][placeid]\n",
    "            investment_levels_demand = demand_dict[\"prune_quantiles\"]\n",
    "            GTs_demand               = demand_dict[\"GTs\"]\n",
    "            GT_abstracts_demand      = demand_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            print(f\"No demand results for {placeid} in scenario '{scenario_name}'\")\n",
    "            investment_levels_demand = []\n",
    "            GTs_demand               = []\n",
    "            GT_abstracts_demand      = []\n",
    "\n",
    "\n",
    "        # Betweenness‐LTN‐priority \n",
    "        if placeid in betweenness_ltn_priority_results.get(scenario_name, {}):\n",
    "            betweenness_ltn_dict = betweenness_ltn_priority_results[scenario_name][placeid]\n",
    "            investment_levels_betw = betweenness_ltn_dict[\"prune_quantiles\"]\n",
    "            GTs_betw               = betweenness_ltn_dict[\"GTs\"]\n",
    "            GT_abstracts_betw      = betweenness_ltn_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            # e.g. scenario == \"no_ltn_scenario\" has no betweenness‐LTN‐priority data\n",
    "            investment_levels_betw = []\n",
    "            GTs_betw               = []\n",
    "            GT_abstracts_betw      = []\n",
    "\n",
    "        # Betweenness\n",
    "        if placeid in betweenness_results.get(scenario_name, {}):\n",
    "            betweenness_dict = betweenness_results[scenario_name][placeid]\n",
    "            investment_levels_betweenness = betweenness_dict[\"prune_quantiles\"]\n",
    "            GTs_betweenness               = betweenness_dict[\"GTs\"]\n",
    "            GT_abstracts_betweenness      = betweenness_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            investment_levels_betweenness = []\n",
    "            GTs_betweenness               = []\n",
    "            GT_abstracts_betweenness      = []\n",
    "\n",
    "        # Demand‐LTN‐priority \n",
    "        if placeid in demand_ltn_priority_results.get(scenario_name, {}):\n",
    "            dem_ltn_dict = demand_ltn_priority_results[scenario_name][placeid]\n",
    "            investment_levels_dem_ltn = dem_ltn_dict[\"prune_quantiles\"]\n",
    "            GTs_dem_ltn               = dem_ltn_dict[\"GTs\"]\n",
    "            GT_abstracts_dem_ltn      = dem_ltn_dict[\"GT_abstracts\"]\n",
    "        else:\n",
    "            investment_levels_dem_ltn = []\n",
    "            GTs_dem_ltn               = []\n",
    "            GT_abstracts_dem_ltn      = []\n",
    "\n",
    "        # Random‐runs (loads all run*.pickle files)\n",
    "        random_runs_list = random_results.get(scenario_name, {}).get(placeid, [])\n",
    "        if random_runs_list:\n",
    "            all_GTs_random       = [run_dict[\"GTs\"]          for run_dict in random_runs_list]\n",
    "            all_GTabs_random      = [run_dict[\"GT_abstracts\"]  for run_dict in random_runs_list]\n",
    "            investment_levels_random = random_runs_list[0][\"prune_quantiles\"]\n",
    "        else:\n",
    "            all_GTs_random          = []\n",
    "            all_GTabs_random         = []\n",
    "            investment_levels_random = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing networks, nodes, GeoDataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: ../../bikenwgrowth_external/data/newcastle\\no_ltn_scenario\\newcastle_tessellation_points.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b8008458\\AppData\\Local\\Temp\\ipykernel_22976\\1656686378.py:84: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: ../../bikenwgrowth_external/data/newcastle\\current_ltn_scenario\\newcastle_tessellation_points.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b8008458\\AppData\\Local\\Temp\\ipykernel_22976\\1656686378.py:84: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: ../../bikenwgrowth_external/data/newcastle\\more_ltn_scenario\\newcastle_tessellation_points.gpkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b8008458\\AppData\\Local\\Temp\\ipykernel_22976\\1656686378.py:84: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n"
     ]
    }
   ],
   "source": [
    "G_biketracks_dict               = {}  # (placeid, scenario) → biketrack graph\n",
    "G_biketrack_no_ltns_dict       = {}  # (placeid, scenario) → biketrack_no_ltn graph\n",
    "G_biketrackcaralls_dict        = {}  # (placeid, scenario) → biketrackcarall graph\n",
    "G_biketrackcarall_edges_dict    = {}  # (placeid, scenario) → GeoDataFrame of biketrackcarall edges\n",
    "boundary_gdfs               = {}  # placeid → boundary GeoDataFrame (same for all scenarios)\n",
    "tess_points_dict            = {}  # (placeid, scenario) → tessellation points GeoDataFrame\n",
    "ltn_points_dict             = {}  # (placeid, scenario) → LTN points GeoDataFrame\n",
    "combined_points_dict        = {}  # (placeid, scenario) → combined points GeoDataFrame\n",
    "\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    for placeid, placeinfo in cities.items():\n",
    "        base_folder = os.path.join(PATH[\"data\"], placeid, scenario)\n",
    "\n",
    "        # Load biketrack graph\n",
    "        biketrack_gpkg = os.path.join(base_folder, f\"{placeid}_biketrack.gpkg\")\n",
    "        if os.path.exists(biketrack_gpkg):\n",
    "            G_biketrack = utils.ox_gpkg_to_graph(biketrack_gpkg)\n",
    "            G_biketrack.remove_nodes_from(list(nx.isolates(G_biketrack)))\n",
    "            G_biketracks_dict[(placeid, scenario)] = G_biketrack\n",
    "        else:\n",
    "            print(f\"Missing: {biketrack_gpkg}\")\n",
    "            G_biketracks_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # Load biketrack_no_ltn graph\n",
    "        biketrack_no_ltn_gpkg = os.path.join(base_folder, f\"{placeid}_biketrack_no_ltn.gpkg\")\n",
    "        if os.path.exists(biketrack_no_ltn_gpkg):\n",
    "            G_no_ltn = utils.ox_gpkg_to_graph(biketrack_no_ltn_gpkg)\n",
    "            G_no_ltn.remove_nodes_from(list(nx.isolates(G_no_ltn)))\n",
    "            G_biketrack_no_ltns_dict[(placeid, scenario)] = G_no_ltn\n",
    "        else:\n",
    "            print(f\"Missing: {biketrack_no_ltn_gpkg}\")\n",
    "            G_biketrack_no_ltns_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # Load biketrackcarall graph\n",
    "        biketrackcarall_gpkg = os.path.join(base_folder, f\"{placeid}_biketrackcarall.gpkg\")\n",
    "        if os.path.exists(biketrackcarall_gpkg):\n",
    "            G_carall = utils.ox_gpkg_to_graph(biketrackcarall_gpkg)\n",
    "            G_carall.remove_nodes_from(list(nx.isolates(G_carall)))\n",
    "            G_biketrackcaralls_dict[(placeid, scenario)] = G_carall\n",
    "\n",
    "            # also store edges GeoDataFrame\n",
    "            edges_gdf = ox.graph_to_gdfs(G_carall, nodes=False)\n",
    "            G_biketrackcarall_edges_dict[(placeid, scenario)] = edges_gdf\n",
    "        else:\n",
    "            print(f\"Missing: {biketrackcarall_gpkg}\")\n",
    "            G_biketrackcaralls_dict[(placeid, scenario)] = None\n",
    "            G_biketrackcarall_edges_dict[(placeid, scenario)] = None\n",
    "\n",
    "        #  Load boundary once per placeid (it won’t change by scenario)\n",
    "        if placeid not in boundary_gdfs:\n",
    "            boundary_gdf = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "            boundary_gdfs[placeid] = boundary_gdf\n",
    "\n",
    "        # get nodes\n",
    "        tess_points_gpkg = os.path.join(base_folder, f\"{placeid}_tessellation_points.gpkg\")\n",
    "        if os.path.exists(tess_points_gpkg):\n",
    "            tess_points = gpd.read_file(tess_points_gpkg)\n",
    "            tess_points_dict[(placeid, scenario)] = tess_points\n",
    "        else:\n",
    "            print(f\"Missing: {tess_points_gpkg}\")\n",
    "            tess_points_dict[(placeid, scenario)] = None\n",
    "        \n",
    "        # get ltn points\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            ltn_points_gpkg = os.path.join(base_folder, f\"{placeid}_ltn_points.gpkg\")\n",
    "            if os.path.exists(ltn_points_gpkg):\n",
    "                ltn_points = gpd.read_file(ltn_points_gpkg)\n",
    "                ltn_points_dict[(placeid, scenario)] = ltn_points\n",
    "            else:\n",
    "                print(f\"Missing: {ltn_points_gpkg}\")\n",
    "                ltn_points_dict[(placeid, scenario)] = None\n",
    "        \n",
    "        # get combined points\n",
    "        combined_points_gpkg = os.path.join(base_folder, f\"{placeid}_combined_points.gpkg\")\n",
    "        if os.path.exists(combined_points_gpkg):\n",
    "            combined_points = gpd.read_file(combined_points_gpkg)\n",
    "            combined_points_dict[(placeid, scenario)] = combined_points\n",
    "        else:\n",
    "            print(f\"Missing: {combined_points_gpkg}\")\n",
    "            combined_points_dict[(placeid, scenario)] = None\n",
    "\n",
    "        # get all neighbourhoods (ragardless of their low traffic status. This doesn't change by scenario)\n",
    "        all_neighbourhoods = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + 'neighbourhoods_'+  placeid + '.gpkg')\n",
    "        all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n",
    "        all_neighbourhoods_centroids = gpd.GeoDataFrame(geometry= all_neighbourhoods_centroids, crs=all_neighbourhoods.crs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "def csv_to_ox(p, placeid, parameterid):\n",
    "    '''\n",
    "    Load graph from csv files (nodes and edge)\n",
    "    Include OSMID, length, highway, x, y attributes\n",
    "    '''\n",
    "\n",
    "    prefix = placeid + '_' + parameterid\n",
    "    compress = utils.check_extract_zip(p, prefix)\n",
    "    \n",
    "    with open(p + prefix + '_edges.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        lines = []\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = str(eval(line_list[header.index(\"osmid\")])[0]) if isinstance(eval(line_list[header.index(\"osmid\")]), list) else line_list[header.index(\"osmid\")]\n",
    "            length = str(eval(line_list[header.index(\"length\")])[0]) if isinstance(eval(line_list[header.index(\"length\")]), list) else line_list[header.index(\"length\")]\n",
    "            highway = line_list[header.index(\"highway\")]\n",
    "            if highway.startswith(\"[\") and highway.endswith(\"]\"):\n",
    "                highway = highway.strip(\"[]\").split(\",\")[0].strip(\" '\")\n",
    "            line_string = f\"{line_list[header.index('u')]} {line_list[header.index('v')]} {osmid} {length} {highway}\"\n",
    "            lines.append(line_string)\n",
    "        G = nx.parse_edgelist(lines, nodetype=int, data=((\"osmid\", int), (\"length\", float), (\"highway\", str)), create_using=nx.MultiDiGraph)\n",
    "    \n",
    "    with open(p + prefix + '_nodes.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        values_x = {}\n",
    "        values_y = {}\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = int(line_list[header.index(\"osmid\")])\n",
    "            values_x[osmid] = float(line_list[header.index(\"x\")])\n",
    "            values_y[osmid] = float(line_list[header.index(\"y\")])\n",
    "        nx.set_node_attributes(G, values_x, \"x\")\n",
    "        nx.set_node_attributes(G, values_y, \"y\")\n",
    "    \n",
    "    if compress:\n",
    "        os.remove(p + prefix + '_nodes.csv')\n",
    "        os.remove(p + prefix + '_edges.csv')\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis saving setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res_pickle_paths = {}  \n",
    "analysis_res_json_paths    = {}  \n",
    "analysis_results          = {}\n",
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle_paths[scenario] = os.path.join(PATH[\"results\"] + placeid + \"/\" + scenario + \"/\" + f\"{placeid}_{scenario}_analysis_results.pickle\")\n",
    "    analysis_res_json_paths[scenario] = os.path.join(PATH[\"results\"], placeid + \"/\" + scenario + \"/\" + f\"{placeid}_{scenario}_analysis_results.json\")\n",
    "    analysis_results[scenario] = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelimiary Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length - finding the distance of the connected network, along with the investment distance (length - existing infrastructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed newcastle - no_ltn_scenario\n",
      "Completed newcastle - current_ltn_scenario\n",
      "Completed newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    G_biketrack        = G_biketracks_dict.get((placeid, scenario))\n",
    "    G_biketrack_no_ltn = G_biketrack_no_ltns_dict.get((placeid, scenario))\n",
    "    GTs                = demand_results.get(scenario, {}).get(placeid, {}).get(\"GTs\", [])\n",
    "\n",
    "    if not (G_biketrack and G_biketrack_no_ltn and GTs):\n",
    "        print(f\"Missing data for {placeid} - {scenario}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # File paths\n",
    "    analysis_res_pickle = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.pickle\")\n",
    "    analysis_res_csv    = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.csv\")\n",
    "    output_path         = os.path.join(PATH[\"plots\"], placeid, scenario, \"allLengths.png\")\n",
    "\n",
    "    # Load existing results\n",
    "    if os.path.exists(analysis_res_pickle):\n",
    "        with open(analysis_res_pickle, 'rb') as f:\n",
    "            analysis_results[scenario] = pickle.load(f)\n",
    "    else:\n",
    "        analysis_results[scenario] = {}\n",
    "\n",
    "    # Calculations\n",
    "    total_biketrack        = sum(nx.get_edge_attributes(G_biketrack, 'length').values())\n",
    "    total_biketrack_no_ltn = sum(nx.get_edge_attributes(G_biketrack_no_ltn, 'length').values())\n",
    "    total_network          = sum(nx.get_edge_attributes(GTs[-1], 'length').values())\n",
    "    investment_length      = sum(\n",
    "        data.get('length', 0) * distance_cost.get(data.get('highway', 'unclassified'), 1)\n",
    "        for _, _, data in GTs[-1].edges(data=True))\n",
    "\n",
    "    length_stats = {'length_comparison_labels': [ \"Existing Cycle Infrastructure (Including LTNs)\", \"Existing Cycle Infrastructure (Excluding LTNs)\", \"LTNs\", \"Fully Connected Cycle Network\", \"Investment Distance\"],\n",
    "        'length_comparison_values': [total_biketrack, total_biketrack_no_ltn, abs(total_biketrack - total_biketrack_no_ltn), total_network, investment_length],\n",
    "        'length_comparison_colors': ['deepskyblue'] * 5,\n",
    "        'total_network_length': total_network,\n",
    "        'total_biketrack_length': total_biketrack,\n",
    "        'total_biketrack_no_ltn_length': total_biketrack_no_ltn,\n",
    "        'length_difference': abs(total_biketrack - total_biketrack_no_ltn),\n",
    "        'total_investment_length': investment_length}\n",
    "\n",
    "    # Save to pickle & CSV\n",
    "    analysis_results[scenario].update(length_stats)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results[scenario], f)\n",
    "    analysis_res_json = os.path.join(PATH[\"results\"], placeid, scenario, f\"{placeid}_{scenario}_analysis_results.json\")\n",
    "    with open(analysis_res_json, 'w') as f:\n",
    "        json.dump(analysis_results[scenario], f, indent=2)\n",
    "    # removed csv - can't take columns with different lengths\n",
    "    #pd.DataFrame({k: [v] for k, v in analysis_results[scenario].items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(\n",
    "        analysis_results[scenario]['length_comparison_labels'],\n",
    "        analysis_results[scenario]['length_comparison_values'],\n",
    "        color=analysis_results[scenario]['length_comparison_colors']\n",
    "    )\n",
    "    plt.xlabel('Network Type')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'{placeid} - {scenario} - Lengths of Cycle Networks')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ltn_difference = abs(total_biketrack - total_biketrack_no_ltn)\n",
    "    labels = [\"Total Cycle Infrastructure\", \"Protected Cycle Infrastructure\",\"LTNs\"]\n",
    "    values = [total_biketrack, total_biketrack_no_ltn, ltn_difference]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, values, color=['deepskyblue'] * 3)\n",
    "    plt.xlabel('Network Type')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'{placeid} - {scenario} - Total Lengths of Cycle Infrastructure')\n",
    "    plt.tight_layout()\n",
    "    output_path_total = os.path.join(PATH[\"plots\"], placeid, scenario, \"TotalLengthsCycleNet.png\")\n",
    "    plt.savefig(output_path_total, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Completed {placeid} - {scenario}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pure length - how is the budget used per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated analysis results for no_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - no_ltn_scenario\n",
      "Updated analysis results for current_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - current_ltn_scenario\n",
      "Updated analysis results for more_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'total_lengths' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        total_lengths_betweenness = utils.compute_total_lengths(GTs_betweenness)\n",
    "        total_lengths_demand = utils.compute_total_lengths(GTs_demand)\n",
    "        total_lengths_random_runs = [utils.compute_total_lengths(run[\"GTs\"]) for run in random_runs]\n",
    "        total_lengths_random_mean = np.mean(total_lengths_random_runs, axis=0).tolist()\n",
    "\n",
    "        # save results\n",
    "        results_list.append((\"Betweenness Growth - Total Length\", total_lengths_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Length\", total_lengths_demand))\n",
    "        for i, run_lengths in enumerate(total_lengths_random_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length\", run_lengths))\n",
    "        results_list.append((\"Random Growth (mean) - Total Length\", total_lengths_random_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            total_lengths_demand_ltn_priority = utils.compute_total_lengths(GTs_demand_ltn_priority)\n",
    "            total_lengths_betweenness_ltn_priority = utils.compute_total_lengths(GTs_betweenness_ltn_priority)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length\", total_lengths_demand_ltn_priority))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length\", total_lengths_betweenness_ltn_priority))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Total Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario]['Random Growth (mean) - Total Length'], linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario]['Betweenness Growth - Total Length'], '-', label='Betweenness Growth', color='orange')\n",
    "    plt.plot(analysis_results[scenario]['Demand Growth - Total Length'], '-.', label='Demand Growth', color='red')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario]['Demand LTN Priority Growth - Total Length'], ':', label='Demand LTN Priority Growth', color='green')\n",
    "        plt.plot(analysis_results[scenario]['Betweenness LTN Priority Growth - Total Length'], '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Total Length (meters)')\n",
    "    plt.title(f'Length of Invested Cycle Network for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"L_of_Investment.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviation from random - pure length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved absolute deviation results for no_ltn_scenario in newcastle\n",
      "Saved absolute deviation results for current_ltn_scenario in newcastle\n",
      "Saved absolute deviation results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or not any(k.endswith(\"Deviation from Random\") for k in analysis_results[scenario]):\n",
    "        baseline = analysis_results[scenario]['Random Growth (mean) - Total Length']\n",
    "        results_list = []\n",
    "        # Calculate deviation from random baseline\n",
    "        results_list.append((\n",
    "            \"Betweenness Growth - Total Length Deviation from Random\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness Growth - Total Length\"], baseline)))\n",
    "        results_list.append((\n",
    "            \"Demand Growth - Total Length Deviation from Random\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Demand Growth - Total Length\"], baseline)))\n",
    "\n",
    "        # Calculate mean deviation for random runs\n",
    "        random_runs_keys = [key for key in analysis_results[scenario] if key.startswith(\"Random Run\") and \"Total Length\" in key]\n",
    "        random_runs = [analysis_results[scenario][key] for key in random_runs_keys]\n",
    "        random_runs_deviations = [utils.compute_abs_deviation(run, baseline) for run in random_runs]\n",
    "        random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Total Length Deviation from Random\", random_deviations_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length Deviation from Random\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Demand LTN Priority Growth - Total Length\"], baseline)))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length Deviation from Random\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Length\"], baseline)))\n",
    "\n",
    "        # Add random runs deviations\n",
    "        for i, dev in enumerate(random_runs_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length Deviation from Random\", dev))\n",
    "\n",
    "        # Save all results as list of (label, data)\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved absolute deviation results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in analysis_results[scenario]:\n",
    "        if key.startswith(\"Random Run\") and \"Deviation from Random\" in key:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plot_lines = [\n",
    "        (\"Betweenness Growth - Total Length Deviation from Random\", '-', 'orange', 'Betweenness Growth'),\n",
    "        (\"Demand Growth - Total Length Deviation from Random\", '-.', 'red', 'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\": plot_lines += [ (\"Demand LTN Priority Growth - Total Length Deviation from Random\", ':', 'green', 'Demand LTN Priority Growth'), (\"Betweenness LTN Priority Growth - Total Length Deviation from Random\", '-', 'purple', 'Betweenness LTN Priority Growth'),]\n",
    "    for key, ls, color, label in plot_lines:\n",
    "        plt.plot(analysis_results[scenario][key], linestyle=ls, color=color, label=label)\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Deviation from Random Growth Baseline (meters)')\n",
    "    plt.title(f'Deviation from Random Growth Baseline for {scenario} - {placeid}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"abs_dev_from_random_length.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Actual\" investment length - how much do we actually need to use to close gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate length, minus the existing infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find how much we actually need to invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated investment cost results for no_ltn_scenario in newcastle\n",
      "Updated investment cost results for current_ltn_scenario in newcastle\n",
      "Updated investment cost results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Total Investment Length\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        total_investment_betweenness = utils.compute_total_investment_lengths(GTs_betweenness, distance_cost)\n",
    "        total_investment_demand = utils.compute_total_investment_lengths(GTs_demand, distance_cost)\n",
    "        random_runs_investments = [utils.compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs]\n",
    "        random_investment_mean = np.mean(random_runs_investments, axis=0).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Total Investment Length\", total_investment_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Investment Length\", total_investment_demand))\n",
    "        for i, run_lengths in enumerate(random_runs_investments):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Investment Length\", run_lengths))\n",
    "        results_list.append((\"Random Growth (mean) - Total Investment Length\", random_investment_mean))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            total_investment_demand_ltn_priority = utils.compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost)\n",
    "            total_investment_betweenness_ltn_priority = utils.compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Investment Length\", total_investment_demand_ltn_priority))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Investment Length\", total_investment_betweenness_ltn_priority))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated investment cost results for {scenario} in {placeid}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Total Investment Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Total Investment Length\"], linestyle='--', linewidth=2, color='blue', label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Total Investment Length\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Total Investment Length\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Total Investment Length\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Investment Length\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Total Investment Cost (Meters)')\n",
    "    plt.title(f'Total Investment Cost per Growth Strategy for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"total_investment_cost.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved deviation-from-random investment cost results for no_ltn_scenario in newcastle\n",
      "Saved deviation-from-random investment cost results for current_ltn_scenario in newcastle\n",
      "Saved deviation-from-random investment cost results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or not any(k.endswith(\"Deviation from Random - Total Investment Length\") for k in analysis_results[scenario]):\n",
    "        baseline = analysis_results[scenario][\"Random Growth (mean) - Total Investment Length\"]\n",
    "        results_list = []\n",
    "\n",
    "        # Compute deviations from random baseline\n",
    "        results_list.append((\"Betweenness Growth - Deviation from Random - Total Investment Length\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness Growth - Total Investment Length\"], baseline)))\n",
    "        results_list.append((\"Demand Growth - Deviation from Random - Total Investment Length\",\n",
    "            utils.compute_abs_deviation(analysis_results[scenario][\"Demand Growth - Total Investment Length\"], baseline)))\n",
    "        random_keys = [key for key in analysis_results[scenario] if key.startswith(\"Random Run\") and \"Total Investment Length\" in key]\n",
    "        random_runs = [analysis_results[scenario][key] for key in random_keys]\n",
    "        random_deviations = [utils.compute_abs_deviation(run, baseline) for run in random_runs]\n",
    "        mean_random_dev = np.mean(random_deviations, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Deviation from Random - Total Investment Length\", mean_random_dev))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            results_list.append((\n",
    "                \"Demand LTN Priority Growth - Deviation from Random - Total Investment Length\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Demand LTN Priority Growth - Total Investment Length\"], baseline)))\n",
    "            results_list.append((\n",
    "                \"Betweenness LTN Priority Growth - Deviation from Random - Total Investment Length\",\n",
    "                utils.compute_abs_deviation(analysis_results[scenario][\"Betweenness LTN Priority Growth - Total Investment Length\"], baseline)))\n",
    "        for i, dev in enumerate(random_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - Deviation from Random - Total Investment Length\", dev))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario].update({label: data for label, data in results_list})\n",
    "        print(f\"Saved deviation-from-random investment cost results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for key in analysis_results[scenario]:\n",
    "        if key.startswith(\"Random Run\") and \"Deviation from Random - Total Investment Length\" in key:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "    plot_lines = [(\"Betweenness Growth - Deviation from Random - Total Investment Length\", '-', 'orange', 'Betweenness Growth'),\n",
    "        (\"Demand Growth - Deviation from Random - Total Investment Length\", '-.', 'red', 'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plot_lines += [ (\"Demand LTN Priority Growth - Deviation from Random - Total Investment Length\", ':', 'green', 'Demand LTN Priority Growth'),\n",
    "                       (\"Betweenness LTN Priority Growth - Deviation from Random - Total Investment Length\", '-', 'purple', 'Betweenness LTN Priority Growth')]\n",
    "\n",
    "    for key, linestyle, color, label in plot_lines:\n",
    "        plt.plot(analysis_results[scenario][key], linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('Deviation from Random Growth Baseline (meters × weight)')\n",
    "    plt.title(f'Deviation from Random Growth Baseline (Total Investment Cost) for {scenario} - {placeid}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"abs_dev_from_random_investment_cost.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find comparison between how much we need against full route lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find differance between network size and required investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved length difference results for no_ltn_scenario in newcastle\n",
      "Saved length difference results for current_ltn_scenario in newcastle\n",
      "Saved length difference results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Length Difference\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        length_diff_betweenness = utils.compute_length_difference(GTs_betweenness)\n",
    "        length_diff_demand = utils.compute_length_difference(GTs_demand)\n",
    "        random_run_differences = [utils.compute_length_difference(run[\"GTs\"]) for run in random_runs]\n",
    "        random_diff_mean = np.mean(random_run_differences, axis=0).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Length Difference\", length_diff_betweenness))\n",
    "        results_list.append((\"Demand Growth - Length Difference\", length_diff_demand))\n",
    "        for i, run_diff in enumerate(random_run_differences):\n",
    "            results_list.append((f\"Random Run {i+1} - Length Difference\", run_diff))\n",
    "        results_list.append((\"Random Growth (mean) - Length Difference\", random_diff_mean))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            length_diff_demand_ltn = utils.compute_length_difference(GTs_demand_ltn_priority)\n",
    "            length_diff_betweenness_ltn = utils.compute_length_difference(GTs_betweenness_ltn_priority)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Length Difference\", length_diff_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Length Difference\", length_diff_betweenness_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved length difference results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Length Difference\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"], linestyle='--', linewidth=2, color='blue', label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Length Difference\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Length Difference\"], '-.', color='red', label='Demand Growth')\n",
    "\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Length Difference\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Length Difference\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Length Difference (meters)\")\n",
    "    plt.title(f\"Difference Between Total Network Size and Investment Size for {scenario} - {placeid}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"length_difference.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved deviation-from-random length difference results for no_ltn_scenario in newcastle\n",
      "Saved deviation-from-random length difference results for current_ltn_scenario in newcastle\n",
      "Saved deviation-from-random length difference results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Deviation from Random Length Difference\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        baseline = np.array(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"])\n",
    "        deviation_betweenness = (np.array(analysis_results[scenario][\"Betweenness Growth - Length Difference\"]) - baseline).tolist()\n",
    "        deviation_demand = (np.array(analysis_results[scenario][\"Demand Growth - Length Difference\"]) - baseline).tolist()\n",
    "\n",
    "        results_list.append((\"Betweenness Growth - Deviation from Random Length Difference\", deviation_betweenness))\n",
    "        results_list.append((\"Demand Growth - Deviation from Random Length Difference\", deviation_demand))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            deviation_demand_ltn = (np.array(analysis_results[scenario][\"Demand LTN Priority Growth - Length Difference\"]) - baseline).tolist()\n",
    "            deviation_betweenness_ltn = (np.array(analysis_results[scenario][\"Betweenness LTN Priority Growth - Length Difference\"]) - baseline).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - Deviation from Random Length Difference\", deviation_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Deviation from Random Length Difference\", deviation_betweenness_ltn))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario].update({k: v for k, v in results_list})\n",
    "        print(f\"Saved deviation-from-random length difference results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Length Difference\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            run_dev = np.array(analysis_results[scenario][key]) - np.array(analysis_results[scenario][\"Random Growth (mean) - Length Difference\"])\n",
    "            plt.plot(run_dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Deviation from Random Length Difference\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Deviation from Random Length Difference\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Deviation from Random Length Difference\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Deviation from Random Length Difference\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random (meters)\")\n",
    "    plt.title(f\"Deviation from Random Growth Strategy for {scenario} - {placeid}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"length_difference_deviation_from_random.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated analysis results for no_ltn_scenario in newcastle\n",
      "Updated analysis results for current_ltn_scenario in newcastle\n",
      "Updated analysis results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load paths and results for this scenario\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    # Load GTs data per growth strategy\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'total_lengths_vs_investment' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        # Compute total lengths and investment lengths for each growth type\n",
    "        lengths_betweenness = utils.compute_total_lengths(GTs_betweenness)\n",
    "        investment_betweenness = utils.compute_total_investment_lengths(GTs_betweenness, distance_cost)\n",
    "        lengths_demand = utils.compute_total_lengths(GTs_demand)\n",
    "        investment_demand = utils.compute_total_investment_lengths(GTs_demand, distance_cost)\n",
    "        random_lengths_runs = [utils.compute_total_lengths(run[\"GTs\"]) for run in random_runs]\n",
    "        random_investment_runs = [utils.compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs]\n",
    "        random_lengths_mean = np.mean(random_lengths_runs, axis=0).tolist()\n",
    "        random_investment_mean = np.mean(random_investment_runs, axis=0).tolist()\n",
    "        # Append results \n",
    "        results_list.append((\"Betweenness Growth - Total Length\", lengths_betweenness))\n",
    "        results_list.append((\"Betweenness Growth - Total Investment Length\", investment_betweenness))\n",
    "        results_list.append((\"Demand Growth - Total Length\", lengths_demand))\n",
    "        results_list.append((\"Demand Growth - Total Investment Length\", investment_demand))\n",
    "        for i, (run_lengths, run_investment) in enumerate(zip(random_lengths_runs, random_investment_runs)):\n",
    "            results_list.append((f\"Random Run {i+1} - Total Length\", run_lengths))\n",
    "            results_list.append((f\"Random Run {i+1} - Total Investment Length\", run_investment))\n",
    "        results_list.append((\"Random Growth (mean) - Total Length\", random_lengths_mean))\n",
    "        results_list.append((\"Random Growth (mean) - Total Investment Length\", random_investment_mean))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            lengths_demand_ltn = utils.compute_total_lengths(GTs_demand_ltn_priority)\n",
    "            investment_demand_ltn = utils.compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost)\n",
    "            lengths_betweenness_ltn = utils.compute_total_lengths(GTs_betweenness_ltn_priority)\n",
    "            investment_betweenness_ltn = utils.compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Length\", lengths_demand_ltn))\n",
    "            results_list.append((\"Demand LTN Priority Growth - Total Investment Length\", investment_demand_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Length\", lengths_betweenness_ltn))\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Total Investment Length\", investment_betweenness_ltn))\n",
    "        # Save all results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "    # Plotting: investment length vs total length\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        len_key = f\"Random Run {i} - Total Length\"\n",
    "        invest_key = f\"Random Run {i} - Total Investment Length\"\n",
    "        if len_key in analysis_results[scenario] and invest_key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][len_key], analysis_results[scenario][invest_key], \n",
    "                     color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario]['Random Growth (mean) - Total Length'],\n",
    "             analysis_results[scenario]['Random Growth (mean) - Total Investment Length'],\n",
    "             linestyle='--', linewidth=2, label='Random Growth (mean)', color='blue')\n",
    "    plt.plot(analysis_results[scenario]['Betweenness Growth - Total Length'],\n",
    "             analysis_results[scenario]['Betweenness Growth - Total Investment Length'],\n",
    "             '-', label='Betweenness Growth', color='orange')\n",
    "    plt.plot(analysis_results[scenario]['Demand Growth - Total Length'],\n",
    "             analysis_results[scenario]['Demand Growth - Total Investment Length'],\n",
    "             '-.', label='Demand Growth', color='red')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        # Plot LTN priority demand growth\n",
    "        plt.plot(analysis_results[scenario]['Demand LTN Priority Growth - Total Length'],\n",
    "                 analysis_results[scenario]['Demand LTN Priority Growth - Total Investment Length'],\n",
    "                 ':', label='Demand LTN Priority Growth', color='green')\n",
    "\n",
    "        # Plot LTN priority betweenness growth\n",
    "        plt.plot(analysis_results[scenario]['Betweenness LTN Priority Growth - Total Length'],\n",
    "                 analysis_results[scenario]['Betweenness LTN Priority Growth - Total Investment Length'],\n",
    "                 '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "\n",
    "    plt.xlabel('Total Length (meters)')\n",
    "    plt.ylabel('Total Investment Length (meters)')\n",
    "    plt.title(f'Investment Length vs Total Length for {scenario} - {placeid}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"Investment_vs_Length.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot for no_ltn_scenario - newcastle\n",
      "Saved plot for current_ltn_scenario - newcastle\n",
      "Saved plot for more_ltn_scenario - newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    # Use mean random runs as baseline\n",
    "    random_lengths_mean = np.array(analysis_results[\"Random Growth (mean) - Total Length\"])\n",
    "    random_investments_mean = np.array(analysis_results[\"Random Growth (mean) - Total Investment Length\"])\n",
    "\n",
    "    strategies = {\n",
    "        'Betweenness Growth': {\n",
    "            'lengths': np.array(analysis_results[\"Betweenness Growth - Total Length\"]),\n",
    "            'investments': np.array(analysis_results[\"Betweenness Growth - Total Investment Length\"]),\n",
    "            'color': 'orange', 'marker': 'o'},\n",
    "        'Demand Growth': {\n",
    "            'lengths': np.array(analysis_results[\"Demand Growth - Total Length\"]),\n",
    "            'investments': np.array(analysis_results[\"Demand Growth - Total Investment Length\"]),\n",
    "            'color': 'red', 'marker': 's' },\n",
    "        'Demand LTN Growth': {\n",
    "            'lengths': np.array(analysis_results.get(\"Demand LTN Priority Growth - Total Length\", [])),\n",
    "            'investments': np.array(analysis_results.get(\"Demand LTN Priority Growth - Total Investment Length\", [])),\n",
    "            'color': 'green', 'marker': '^'},\n",
    "        'Betweenness LTN Growth': {\n",
    "            'lengths': np.array(analysis_results.get(\"Betweenness LTN Priority Growth - Total Length\", [])),\n",
    "            'investments': np.array(analysis_results.get(\"Betweenness LTN Priority Growth - Total Investment Length\", [])),\n",
    "            'color': 'purple', 'marker': 'D'}}\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot individual random runs\n",
    "    random_runs_lengths = analysis_results.get('random_runs_lengths_list', [])\n",
    "    random_runs_investments = analysis_results.get('random_runs_investment_lengths_list', [])\n",
    "    for i in range(len(random_runs_lengths)):\n",
    "        run_lengths = np.array(random_runs_lengths[i])\n",
    "        run_investments = np.array(random_runs_investments[i])\n",
    "        plt.scatter(run_lengths - random_lengths_mean,\n",
    "                    run_investments - random_investments_mean,\n",
    "                    color='lightgray', alpha=0.3, s=10, label='_nolegend_')\n",
    "\n",
    "    # Plot strategy deviations\n",
    "    for label, data in strategies.items():\n",
    "        if data['lengths'].size == 0 or data['investments'].size == 0:\n",
    "            continue  # skip missing\n",
    "        x_dev = data['lengths'] - random_lengths_mean\n",
    "        y_dev = data['investments'] - random_investments_mean\n",
    "        plt.scatter(x_dev, y_dev, label=label, color=data['color'], marker=data['marker'], alpha=0.8, s=50)\n",
    "\n",
    "    # Reference lines\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    plt.xlabel('Deviation in Total Length (m) from Random Growth (mean)')\n",
    "    plt.ylabel('Deviation in Investment Length (m) from Random Growth (mean)')\n",
    "    plt.title(f'Investment Cost vs Length: Deviation from Random ({scenario})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"investment_vs_length_deviation_scatter.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for {scenario} - {placeid}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance gained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to find how much of the existing network is connected per iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total bike network - G_bikeall\n",
    "\n",
    "G'investment_length' - investment size\n",
    "\n",
    "G'length' - length of created network, not including netowrk size\n",
    "\n",
    "need to do a compose of G_bikeall and G in GTs\n",
    "\n",
    "but only compose where infrastucutre is connected to our generated network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of infrastructure connected to generated network, along with the combined length. Thus we now know how much extra cycle network is connected per level of investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated biketrack connected length analysis results for no_ltn_scenario in newcastle\n",
      "Updated biketrack connected length analysis results for current_ltn_scenario in newcastle\n",
      "Updated biketrack connected length analysis results for more_ltn_scenario in newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand_ltn = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", []) if scenario != \"no_ltn_scenario\" else []\n",
    "    GTs_betweenness_ltn = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", []) if scenario != \"no_ltn_scenario\" else []\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "\n",
    "    if rerun or \"Biketrack Connected Lengths\" not in analysis_results:\n",
    "        results_list = []\n",
    "\n",
    "    \n",
    "        gt, bike, combined = utils.compute_biketrack_connected_lengths(GTs_betweenness, G_biketrack)\n",
    "        results_list += [(\"GT Connected Lengths\", gt),\n",
    "            (\"Biketrack Connected Lengths\", bike),\n",
    "            (\"Combined Connected Lengths\", combined),]\n",
    "\n",
    "   \n",
    "        random_GT_lengths = []\n",
    "        random_bike_lengths = []\n",
    "        random_comb_lengths = []\n",
    "\n",
    "        for run in random_runs:\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)\n",
    "            random_GT_lengths.append(gt)\n",
    "            random_bike_lengths.append(bike)\n",
    "            random_comb_lengths.append(comb)\n",
    "\n",
    "        for i, run in enumerate(random_bike_lengths):\n",
    "            results_list.append((f\"Random Run {i+1} - Biketrack Connected Lengths\", run))\n",
    "        results_list.append((\"random_runs_biketrack_lengths\", random_bike_lengths))\n",
    "\n",
    "        results_list += [(\"GT Random Mean - Connected Lengths\", np.mean(random_GT_lengths, axis=0).tolist()),\n",
    "            (\"Biketrack Random Mean - Connected Lengths\", np.mean(random_bike_lengths, axis=0).tolist()),\n",
    "            (\"Combined Random Mean - Connected Lengths\", np.mean(random_comb_lengths, axis=0).tolist()),]\n",
    "\n",
    "        # --- Demand-based strategy ---\n",
    "        gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_demand, G_biketrack)\n",
    "        results_list += [(\"GT Demand Connected Lengths\", gt),\n",
    "            (\"Biketrack Demand Connected Lengths\", bike),\n",
    "            (\"Combined Demand Connected Lengths\", comb),]\n",
    "\n",
    "        # --- LTN-priority variants ---\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_demand_ltn, G_biketrack)\n",
    "            results_list += [(\"GT Demand LTN Priority Connected Lengths\", gt),\n",
    "                (\"Biketrack Demand LTN Priority Connected Lengths\", bike),\n",
    "                (\"Combined Demand LTN Priority Connected Lengths\", comb),]\n",
    "\n",
    "            gt, bike, comb = utils.compute_biketrack_connected_lengths(GTs_betweenness_ltn, G_biketrack)\n",
    "            results_list += [(\"GT Betweenness LTN Priority Connected Lengths\", gt),\n",
    "                (\"Biketrack Betweenness LTN Priority Connected Lengths\", bike),\n",
    "                (\"Combined Betweenness LTN Priority Connected Lengths\", comb),]\n",
    "            \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results = {label: data for label, data in results_list}\n",
    "        print(f\"Updated biketrack connected length analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot random runs\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Biketrack Connected Lengths\"\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Plot strategy means\n",
    "    plt.plot(analysis_results[\"Biketrack Random Mean - Connected Lengths\"], '--', color='blue', linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[\"Biketrack Connected Lengths\"], '-', color='orange', label=\"Betweenness\")\n",
    "    plt.plot(analysis_results[\"Biketrack Demand Connected Lengths\"], '-.', color='red', label=\"Demand\")\n",
    "\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[\"Biketrack Demand LTN Priority Connected Lengths\"], ':', color='green', label=\"Demand LTN Priority\")\n",
    "        plt.plot(analysis_results[\"Biketrack Betweenness LTN Priority Connected Lengths\"], '-', color='purple', label=\"Betweenness LTN Priority\")\n",
    "\n",
    "    # Finalize plot\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Additional Cycle Infrastructure Connected Length (meters)\")\n",
    "    plt.title(f\"Additional Cycle Infrastructure Connected per Iteration ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"additional_cyclenet_connected.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved biketrack deviation-from-random results for no_ltn_scenario in newcastle\n",
      "Saved biketrack connected deviation plot for no_ltn_scenario - newcastle\n",
      "Saved biketrack deviation-from-random results for current_ltn_scenario in newcastle\n",
      "Saved biketrack connected deviation plot for current_ltn_scenario - newcastle\n",
      "Saved biketrack deviation-from-random results for more_ltn_scenario in newcastle\n",
      "Saved biketrack connected deviation plot for more_ltn_scenario - newcastle\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # Load paths and results\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    if rerun or \"Connected Biketrack - Deviation from Random\" not in analysis_results:\n",
    "        # Load random data\n",
    "        random_runs = analysis_results.get(\"random_runs_biketrack_lengths\", [])\n",
    "        random_mean = np.mean(random_runs, axis=0)\n",
    "\n",
    "        # Compute deviation per run\n",
    "        random_runs_deviations = [np.array(run) - random_mean for run in random_runs]\n",
    "        random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "\n",
    "        # Compute strategy deviations from random mean\n",
    "        deviation_results = {\"Betweenness Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(analysis_results[\"Biketrack Connected Lengths\"], random_mean),\n",
    "            \"Demand Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(analysis_results[\"Biketrack Demand Connected Lengths\"], random_mean),}\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            deviation_results.update({\"Demand LTN Priority Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(\n",
    "                    analysis_results[\"Biketrack Demand LTN Priority Connected Lengths\"], random_mean),\n",
    "                \"Betweenness LTN Priority Growth - Connected Biketrack Deviation from Random\": utils.compute_abs_deviation(\n",
    "                    analysis_results[\"Biketrack Betweenness LTN Priority Connected Lengths\"], random_mean),})\n",
    "\n",
    "        # Save all deviation results\n",
    "        results_list = [(k, v) for k, v in deviation_results.items()]\n",
    "        results_list.append((\"Connected Biketrack - Random Deviations (All Runs)\", [d.tolist() for d in random_runs_deviations]))\n",
    "        results_list.append((\"Connected Biketrack - Mean Deviation from Random\", random_deviations_mean))\n",
    "        results_list.append((\"Connected Biketrack - Deviation from Random\", deviation_results))\n",
    "\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results.update({k: v for k, v in results_list})\n",
    "        print(f\"Saved biketrack deviation-from-random results for {scenario} in {placeid}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot random deviations\n",
    "    for dev in analysis_results[\"Connected Biketrack - Random Deviations (All Runs)\"]:\n",
    "        plt.plot(dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "\n",
    "    # Plot strategies\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label=\"Random Growth (mean)\")\n",
    "\n",
    "    strategy_styles = {\"Betweenness Growth - Connected Biketrack Deviation from Random\": ('-', 'orange', \"Betweenness Growth\"),\n",
    "        \"Demand Growth - Connected Biketrack Deviation from Random\": ('-.', 'red', \"Demand Growth\"),\n",
    "        \"Demand LTN Priority Growth - Connected Biketrack Deviation from Random\": (':', 'green', \"Demand LTN Priority Growth\"),\n",
    "        \"Betweenness LTN Priority Growth - Connected Biketrack Deviation from Random\": ('-', 'purple', \"Betweenness LTN Priority Growth\"),}\n",
    "\n",
    "    for key, (style, color, label) in strategy_styles.items():\n",
    "        if key in analysis_results:\n",
    "            plt.plot(analysis_results[key], linestyle=style, color=color, label=label)\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Biketrack Connected Length: Deviation from Random Baseline ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"biketrack_connected__deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved biketrack connected deviation plot for {scenario} - {placeid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of the largest connected component, first a just our investment, then combined with existing network, then by combined but only where its connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated LCC analysis results for no_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - no_ltn_scenario\n",
      "Updated LCC analysis results for current_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - current_ltn_scenario\n",
      "Updated LCC analysis results for more_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or 'LCC Growth - LCC Length' not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        lcc_lengths_betweenness = [utils.get_longest_connected_components(G) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - LCC Length\", lcc_lengths_betweenness))\n",
    "\n",
    "        random_runs_lcc_lengths = [[utils.get_longest_connected_components(G) for G in run[\"GTs\"]] for run in random_runs]\n",
    "        for i, run_lengths in enumerate(random_runs_lcc_lengths):\n",
    "            results_list.append((f\"Random Run {i+1} - LCC Length\", run_lengths))\n",
    "        results_list.append((\"random_runs_lcc_lengths\", random_runs_lcc_lengths))\n",
    "        random_lcc_mean = np.mean(random_runs_lcc_lengths, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - LCC Length\", random_lcc_mean))\n",
    "\n",
    "        lcc_lengths_demand = [utils.get_longest_connected_components(G) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - LCC Length\", lcc_lengths_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            lcc_lengths_demand_ltn_priority = [utils.get_longest_connected_components(G) for G in GTs_demand_ltn_priority]\n",
    "            results_list.append((\"Demand LTN Priority Growth - LCC Length\", lcc_lengths_demand_ltn_priority))\n",
    "            lcc_lengths_betweenness_ltn_priority = [utils.get_longest_connected_components(G) for G in GTs_betweenness_ltn_priority]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - LCC Length\", lcc_lengths_betweenness_ltn_priority))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated LCC analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - LCC Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - LCC Length\"], '--', color='blue', linewidth=2, label='Random Growth (mean)')\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - LCC Length\"], '-', color='orange', label='Betweenness Growth')\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - LCC Length\"], '-.', color='red', label='Demand Growth')\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - LCC Length\"], ':', color='green', label='Demand LTN Priority Growth')\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - LCC Length\"], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "    plt.xlabel('Investment Iteration')\n",
    "    plt.ylabel('LCC Length (meters)')\n",
    "    plt.title(f'Largest Connected Component Length per Iteration ({scenario})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"size_of_lcc.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LCC deviation-from-random results for no_ltn_scenario in newcastle\n",
      "Saved LCC deviation plot for newcastle - no_ltn_scenario\n",
      "Saved LCC deviation-from-random results for current_ltn_scenario in newcastle\n",
      "Saved LCC deviation plot for newcastle - current_ltn_scenario\n",
      "Saved LCC deviation-from-random results for more_ltn_scenario in newcastle\n",
      "Saved LCC deviation plot for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - LCC Length Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_lcc_lengths = analysis_results[scenario].get(\"random_runs_lcc_lengths\", [])\n",
    "        random_lcc_mean = np.array(analysis_results[scenario].get(\"Random Growth (mean) - LCC Length\", []))\n",
    "        random_runs_deviations = [(np.array(run) - random_lcc_mean).tolist() for run in random_runs_lcc_lengths]\n",
    "        random_deviations_mean = np.mean([np.array(dev) for dev in random_runs_deviations], axis=0).tolist()\n",
    "\n",
    "        betw_lcc = np.array(analysis_results[scenario].get(\"Betweenness Growth - LCC Length\", []))\n",
    "        dev_betw = (betw_lcc - random_lcc_mean).tolist()\n",
    "        results_list.append((\"Betweenness Growth - LCC Length Deviation from Random\", dev_betw))\n",
    "        demand_lcc = np.array(analysis_results[scenario].get(\"Demand Growth - LCC Length\", []))\n",
    "        dev_demand = (demand_lcc - random_lcc_mean).tolist()\n",
    "        results_list.append((\"Demand Growth - LCC Length Deviation from Random\", dev_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            demand_ltn_lcc = np.array(analysis_results[scenario].get(\"Demand LTN Priority Growth - LCC Length\", []))\n",
    "            dev_demand_ltn = (demand_ltn_lcc - random_lcc_mean).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - LCC Length Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            betw_ltn_lcc = np.array(analysis_results[scenario].get(\"Betweenness LTN Priority Growth - LCC Length\", []))\n",
    "            dev_betw_ltn = (betw_ltn_lcc - random_lcc_mean).tolist()\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - LCC Length Deviation from Random\", dev_betw_ltn))\n",
    "\n",
    "        for i, dev_series in enumerate(random_runs_deviations):\n",
    "            results_list.append((f\"Random Run {i+1} - LCC Length Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - LCC Length Deviation from Random\", random_deviations_mean))\n",
    "\n",
    "        # Save \n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved LCC deviation-from-random results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - LCC Length Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color='lightgray', linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "    strategy_lines = [(\"Betweenness Growth - LCC Length Deviation from Random\",    '-',  'orange',  'Betweenness Growth'),\n",
    "        (\"Demand Growth - LCC Length Deviation from Random\",         '-.', 'red',     'Demand Growth'),]\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        strategy_lines += [(\"Demand LTN Priority Growth - LCC Length Deviation from Random\",    ':',  'green',  'Demand LTN Priority Growth'),\n",
    "            (\"Betweenness LTN Priority Growth - LCC Length Deviation from Random\", '-', 'purple', 'Betweenness LTN Priority Growth'),]\n",
    "    for key, ls, color, label in strategy_lines:\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], linestyle=ls, color=color, label=label)\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Deviation in LCC Length from Random Baseline ({scenario})\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"lcc_length_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved LCC deviation plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCC including any addtionally connected cycle track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_composite_lcc_length` funciton is pretty slow currently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated composite LCC analysis results for no_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - no_ltn_scenario\n",
      "Updated composite LCC analysis results for current_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - current_ltn_scenario\n",
      "Updated composite LCC analysis results for more_ltn_scenario in newcastle\n",
      "Plots saved for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    GTs_betweenness = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Composite LCC Length\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        comp_lcc_betw = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Composite LCC Length\", comp_lcc_betw))\n",
    "        random_comp_lcc_runs = [[utils.get_composite_lcc_length(G, G_biketrack) for G in run[\"GTs\"]] for run in random_runs]\n",
    "        for i, run_lengths in enumerate(random_comp_lcc_runs):\n",
    "            results_list.append((f\"Random Run {i+1} - Composite LCC Length\", run_lengths))\n",
    "        results_list.append((\"random_runs_composite_lcc_lengths\", random_comp_lcc_runs))\n",
    "        random_comp_lcc_mean = np.mean(random_comp_lcc_runs, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Composite LCC Length\", random_comp_lcc_mean))\n",
    "        comp_lcc_demand = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Composite LCC Length\", comp_lcc_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            comp_lcc_demand_ltn = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_demand_ltn_priority]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Composite LCC Length\", comp_lcc_demand_ltn))\n",
    "            comp_lcc_betw_ltn = [utils.get_composite_lcc_length(G, G_biketrack) for G in GTs_betweenness_ltn_priority]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Composite LCC Length\", comp_lcc_betw_ltn))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated composite LCC analysis results for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Composite LCC Length\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Composite LCC Length\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Composite LCC Length\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Composite LCC Length\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Demand LTN Priority Growth - Composite LCC Length\"],\n",
    "            \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Betweenness LTN Priority Growth - Composite LCC Length\"],\n",
    "            \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Composite LCC Length (meters)\")\n",
    "    plt.title(f\"Composite LCC Length per Iteration ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"size_of_composite_lcc.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Plots saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved composite LCC deviation-from-random for no_ltn_scenario in newcastle\n",
      "Saved composite LCC deviation plot for newcastle - no_ltn_scenario\n",
      "Saved composite LCC deviation-from-random for current_ltn_scenario in newcastle\n",
      "Saved composite LCC deviation plot for newcastle - current_ltn_scenario\n",
      "Saved composite LCC deviation-from-random for more_ltn_scenario in newcastle\n",
      "Saved composite LCC deviation plot for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load \n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - Composite LCC Length Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_composite = analysis_results[scenario].get(\"random_runs_composite_lcc_lengths\", [])\n",
    "        random_composite_mean = np.array(analysis_results[scenario].get(\"Random Growth (mean) - Composite LCC Length\", []))\n",
    "        random_runs_dev = [\n",
    "            (np.array(run) - random_composite_mean).tolist()\n",
    "            for run in random_runs_composite\n",
    "        ]\n",
    "        random_dev_mean = np.mean([np.array(dev) for dev in random_runs_dev], axis=0).tolist()\n",
    "\n",
    "        comp_betw = np.array(analysis_results[scenario].get(\"Betweenness Growth - Composite LCC Length\", []))\n",
    "        dev_betw = (comp_betw - random_composite_mean).tolist()\n",
    "        results_list.append((\"Betweenness Growth - Composite LCC Length Deviation from Random\", dev_betw))\n",
    "\n",
    "    \n",
    "        comp_demand = np.array(analysis_results[scenario].get(\"Demand Growth - Composite LCC Length\", []))\n",
    "        dev_demand = (comp_demand - random_composite_mean).tolist()\n",
    "        results_list.append((\"Demand Growth - Composite LCC Length Deviation from Random\", dev_demand))\n",
    "\n",
    "        \n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            comp_demand_ltn = np.array(analysis_results[scenario].get(\"Demand LTN Priority Growth - Composite LCC Length\", []))\n",
    "            dev_demand_ltn = (comp_demand_ltn - random_composite_mean).tolist()\n",
    "            results_list.append((\"Demand LTN Priority Growth - Composite LCC Length Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            comp_betw_ltn = np.array(analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Composite LCC Length\", []))\n",
    "            dev_betw_ltn = (comp_betw_ltn - random_composite_mean).tolist()\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Composite LCC Length Deviation from Random\", dev_betw_ltn))\n",
    "\n",
    "        \n",
    "        for i, dev_series in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Composite LCC Length Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - Composite LCC Length Deviation from Random\", random_dev_mean))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved composite LCC deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Composite LCC Length Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Composite LCC Length Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Composite LCC Length Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Composite LCC Length Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Composite LCC Length Deviation from Random\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "    plt.title(f\"Composite LCC Length Deviation from Random ({scenario})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"composite_lcc_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to running any coverage analysis, we create buffers of each graph to avoid re-calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7351b7f343489ea91f3156eb703488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887c7778867241c4ac5e407d0b004782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7fd24a102d403db4b8c943e786dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_betweenness_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce349afdeb414ab0d9e36d86285d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_betweenness_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run01 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b6263b26864458a157f226a43c0476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run01:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run02 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1c0fdefff64d8e94f22a79ec80a649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run02:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run03 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35aa7c0af254ebeb3eb015411fe8c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run03:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8624a7e52b34108bf98e2b4cf813d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba34ef345d7f4e8a8189d11f18132b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9894c11d23884a99a5aab1e3247c9c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_betweenness_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504cc49273504b4b9fa07133ef3ae8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_betweenness_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run01 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b279fb17ce44d59365f0a67f1b9c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run01:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run02 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e20915f8e9474dbf7428434a249f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run02:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run03 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d057948cf7b144aca8598fc64222d345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run03:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3c7d4ee1814292ad2f1f3a102ef20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1502ec7273dc4ff2a08584acbea7e01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_demand_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20ef1b3435647bea2771398c17f8166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_demand_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_betweenness_ltn_priority buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1ec2807bba44bfa30e85b8cd942e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_betweenness_ltn_priority:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run01 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce7f64d5834c99ac20bb08e3499516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run01:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run02 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c880c40d1dc74cc787f2c61ae2ff452b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run02:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GTs_buffers_random_run03 buffers with parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e1d0a7c3cf41dcb92f5a03a3d7c23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GTs_buffers_random_run03:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    base_path = os.path.abspath(os.path.join(PATH[\"results\"], placeid, scenario))\n",
    "    GTs_buffers = utils.process_and_save_buffers_parallel(GTs, \"GTs_buffers\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_demand = utils.process_and_save_buffers_parallel(GTs_demand, \"GTs_buffers_demand\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_demand_ltn_priority = utils.process_and_save_buffers_parallel(GTs_demand_ltn_priority, \"GTs_buffers_demand_ltn_priority\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    GTs_buffers_betweenness_ltn_priority = utils.process_and_save_buffers_parallel(GTs_betweenness_ltn_priority, \"GTs_buffers_betweenness_ltn_priority\", rerun, base_path, params[\"buffer_walk\"])\n",
    "    # For multiple random runs\n",
    "    GTs_buffers_random_all = []\n",
    "    for run_id, run_res in enumerate(random_runs, start=1):\n",
    "        name = f\"GTs_buffers_random_run{run_id:02d}\"\n",
    "        buffers = utils.process_and_save_buffers_parallel(run_res[\"GTs\"], name, rerun, base_path, params[\"buffer_walk\"])\n",
    "        GTs_buffers_random_all.append(buffers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Area analysis cell\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'buffer_areas' not in analysis_results:\n",
    "#     target_crs = \"EPSG:3857\"\n",
    "#     boundary_proj = boundary.to_crs(target_crs)\n",
    "#     total_area = boundary_proj.unary_union.area\n",
    "\n",
    "#     def compute_metrics(buffer_list):\n",
    "#         areas = []\n",
    "#         percentages = []\n",
    "#         for gdf in buffer_list:\n",
    "#             gdf_proj = gdf.to_crs(target_crs)\n",
    "#             inter = gpd.overlay(gdf_proj, boundary_proj, how='intersection')\n",
    "#             inter_area = inter.unary_union.area if not inter.empty else 0\n",
    "#             areas.append(inter_area / 1e6)  # Convert m² to km²\n",
    "#             percentages.append((inter_area / total_area * 100) if total_area else 0)\n",
    "#         return areas, percentages\n",
    "\n",
    "#     buffer_metrics = {\n",
    "#         'buffer_areas': compute_metrics(GTs_buffers)[0],\n",
    "#         'buffer_percentages': compute_metrics(GTs_buffers)[1],\n",
    "#         'random_buffer_areas': compute_metrics(GTs_buffers_random)[0],\n",
    "#         'random_buffer_percentages': compute_metrics(GTs_buffers_random)[1],\n",
    "#         'demand_buffer_areas': compute_metrics(GTs_buffers_demand)[0],\n",
    "#         'demand_buffer_percentages': compute_metrics(GTs_buffers_demand)[1],\n",
    "#         'demand_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[0],\n",
    "#         'demand_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[1],\n",
    "#         'betweenness_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "#         'betweenness_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(buffer_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting - Area (km²)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['buffer_areas'], \n",
    "#     color='orange', \n",
    "#     linestyle='-', \n",
    "#     label='Betweenness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['random_buffer_areas'], \n",
    "#     color='blue', \n",
    "#     linestyle='--', \n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_areas'], \n",
    "#     color='red', \n",
    "#     linestyle='-.', \n",
    "#     label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_areas_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['betweenness_buffer_areas_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Area (km²)')\n",
    "# plt.title('Total Area Coverage')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/area_coverage_km2.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Plotting - Percentage Coverage\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['buffer_percentages'], \n",
    "#     color='orange', \n",
    "#     linestyle='-', \n",
    "#     label='Betweeness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['random_buffer_percentages'], \n",
    "#     color='blue', \n",
    "#     linestyle='--', \n",
    "#     label='Random Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_percentages'], \n",
    "#     color='red', \n",
    "#     linestyle='-.', \n",
    "#     label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['demand_buffer_percentages_ltn_priority'],\n",
    "#     color='green',\n",
    "#     linestyle=':',\n",
    "#     label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['betweenness_buffer_percentages_ltn_priority'],\n",
    "#     color='purple',\n",
    "#     linestyle='-',\n",
    "#     label='Betweenness LTN Growth'\n",
    "# )\n",
    "\n",
    "# plt.xlabel('Growth Iteration')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Boundary Coverage')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/boundary_cov_percentage.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streets coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_crs = G_biketrackcarall_edges.crs\n",
    "# total_network_length = G_biketrackcarall_edges[\"length\"].sum()\n",
    "\n",
    "# def compute_street_coverage(buffer_list):\n",
    "#     lengths = []\n",
    "#     percentages = []\n",
    "#     for gdf in buffer_list:\n",
    "#         # Reproject buffers to network CRS if needed\n",
    "#         gdf_proj = gdf.to_crs(network_crs)\n",
    "#         # Compute intersection between network and buffer\n",
    "#         inter = gpd.overlay(G_biketrackcarall_edges, gdf_proj, how='intersection')\n",
    "#         # Sum the existing \"length\" values from the intersected segments\n",
    "#         seg_length = inter[\"length\"].sum() if not inter.empty else 0\n",
    "#         lengths.append(seg_length)\n",
    "#         percentages.append((seg_length / total_network_length * 100) if total_network_length else 0)\n",
    "#     return lengths, percentages\n",
    "\n",
    "# # Compute metrics for both buffer sets\n",
    "# net_lengths1, net_perc1 = compute_street_coverage(GTs_buffers)\n",
    "# net_lengths2, net_perc2 = compute_street_coverage(GTs_buffers_random)\n",
    "\n",
    "# # Plot 1: Compare network lengths (in meters) within each buffer\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(net_lengths1, 'b-o', label='GTs_buffers Network (m)')\n",
    "# plt.plot(net_lengths2, 'g-o', label='GTs_buffers_random Network (m)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Network Length (m)')\n",
    "# plt.title('Street Network Length within Buffers')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot 2: Compare network coverage percentages\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(net_perc1, 'r-s', label='GTs_buffers Coverage (%)')\n",
    "# plt.plot(net_perc2, 'm-s', label='GTs_buffers_random Coverage (%)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Percentage of Total Network within Buffers')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "\n",
    "\n",
    "if rerun or 'street_lengths' not in analysis_results:\n",
    "    network_crs = G_biketrackcarall_edges.crs\n",
    "    total_network_length = G_biketrackcarall_edges[\"length\"].sum()\n",
    "\n",
    "    # simplfy to reduce computation time\n",
    "    proj_crs = network_crs if network_crs.is_projected else \"EPSG:3857\"\n",
    "    edges_proj = G_biketrackcarall_edges.to_crs(proj_crs)\n",
    "    edges_simpl = edges_proj.copy()\n",
    "    edges_simpl.geometry = edges_proj.geometry.simplify(tolerance=10,\n",
    "                                                         preserve_topology=True)\n",
    "    edges_simpl = edges_simpl.to_crs(network_crs)\n",
    "\n",
    "    def compute_street_coverage(buffer_list):\n",
    "        lengths = []\n",
    "        percentages = []\n",
    "        for gdf in buffer_list:\n",
    "            gdf_proj = gdf.to_crs(network_crs)\n",
    "            # simplfy to reduce computation time\n",
    "            gdf_proj = gdf.to_crs(proj_crs).copy()\n",
    "            gdf_proj.geometry = gdf_proj.geometry.simplify(tolerance=10,\n",
    "                                                           preserve_topology=True)\n",
    "            gdf_proj = gdf_proj.to_crs(network_crs)\n",
    "            \n",
    "            inter = gpd.overlay(G_biketrackcarall_edges, gdf_proj, how='intersection')\n",
    "            seg_length = inter[\"length\"].sum() if not inter.empty else 0\n",
    "            lengths.append(seg_length)\n",
    "            percentages.append((seg_length / total_network_length * 100) if total_network_length else 0)\n",
    "        return lengths, percentages\n",
    "\n",
    "    street_metrics = {\n",
    "        'street_cov_lengths': compute_street_coverage(GTs_buffers)[0],\n",
    "        'street_cov_percentages': compute_street_coverage(GTs_buffers)[1],\n",
    "        'random_street_cov_lengths': compute_street_coverage(GTs_buffers_random)[0],\n",
    "        'random_street_cov_percentages': compute_street_coverage(GTs_buffers_random)[1],\n",
    "        'demand_street_cov_lengths': compute_street_coverage(GTs_buffers_demand)[0],\n",
    "        'demand_street_cov_percentages': compute_street_coverage(GTs_buffers_demand)[1],\n",
    "        'demand_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[0],\n",
    "        'demand_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[1],\n",
    "        'betweenness_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "        'betweenness_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(street_metrics)\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "    df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plot: Network Length within Buffers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(analysis_results['street_cov_lengths'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['random_street_cov_lengths'], color='blue', linestyle='--', label='Random Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_lengths'], color='red', linestyle='-.', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_lengths_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_street_cov_lengths_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Street Network Length (m)')\n",
    "plt.title('Street Network Length within Buffers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/streets_within_cyclenet.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot: Percentage of Network within Buffers\n",
    "plt.figure(10, 6)\n",
    "plt.plot(analysis_results['street_cov_percentages'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['random_street_cov_percentages'], color='blue', linestyle='--', label='Random Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_percentages'], color='red', linestyle='-.', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_percentages_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_street_cov_percentages_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Coverage (%)')\n",
    "plt.title('Percentage of Total Network within Buffers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/percentage_within_cyclenet.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get population data from census, asign census data to buildings, find population within cycle route buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get lsoas and population\n",
    "# lsoa_bound = gpd.read_file(PATH[\"data\"] + \"/\" + placeid + \"/lsoa_bound.gpkg\")\n",
    "# boundary = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "# lsoa_bound = gpd.clip(lsoa_bound, boundary)\n",
    "# lsoa_bound = add_lsoa_population(lsoa_bound) # using 2011 census data\n",
    "\n",
    "# # get buildings\n",
    "# buildings = get_building_populations(lsoa_bound, boundary) ## add more detail??\n",
    "# buildings = buildings.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # pop_counts_GT = []\n",
    "# # pop_counts_random_GT = []\n",
    "\n",
    "\n",
    "# # # Function to calculate total pop_count within each buffer\n",
    "# # def calculate_pop_count(buffers_list, buildings):\n",
    "# #     pop_counts = []\n",
    "# #     for buffer in buffers_list:\n",
    "# #         intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "# #         total_pop = intersecting_buildings[\"pop_assigned\"].sum()\n",
    "# #         pop_counts.append(total_pop)\n",
    "# #     return pop_counts\n",
    "\n",
    "# # # Calculate for both sets of buffers\n",
    "# # pop_counts_GT = calculate_pop_count(GTs_buffers, buildings)\n",
    "# # pop_counts_random_GT = calculate_pop_count(GTs_buffers_random, buildings)\n",
    "\n",
    "# # plt.figure(figsize=(10, 5))\n",
    "# # buffer_indices = np.arange(len(GTs_buffers))  # Common x-axis indices for both datasets\n",
    "\n",
    "# # plt.plot(buffer_indices, pop_counts_GT, label=\"GTs Buffers\", linestyle='-', color='blue')\n",
    "# # plt.plot(buffer_indices, pop_counts_random_GT, label=\"Random GTs Buffers\", linestyle='--', color='orange')\n",
    "\n",
    "# # plt.xlabel(\"Buffer Index\")\n",
    "# # plt.ylabel(\"Total Population Count\")\n",
    "# # plt.title(\"Comparison of Population Within Buffers\")\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# # plt.show()\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'pop_counts_GT' not in analysis_results:\n",
    "#     def calculate_pop_count(buffers_list, buildings):\n",
    "#         pop_counts = []\n",
    "#         for buffer in buffers_list:\n",
    "#             intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "#             pop_counts.append(intersecting_buildings[\"pop_assigned\"].sum())\n",
    "#         return pop_counts\n",
    "\n",
    "#     pop_metrics = {\n",
    "#         'pop_counts_GT': calculate_pop_count(GTs_buffers, buildings),\n",
    "#         'pop_counts_random_GT': calculate_pop_count(GTs_buffers_random, buildings),\n",
    "#         'pop_counts_demand_GT': calculate_pop_count(GTs_buffers_demand, buildings)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(pop_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# buffer_indices = np.arange(len(GTs_buffers))\n",
    "\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_GT'],\n",
    "#     label=\"Betweenness Growth\",\n",
    "#     linestyle='-',\n",
    "#     color='orange'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_random_GT'],\n",
    "#     label=\"Random Growth\",\n",
    "#     linestyle='--',\n",
    "#     color='blue'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_demand_GT'],\n",
    "#     label=\"Demand-based Growth\",\n",
    "#     linestyle='-.',\n",
    "#     color='red'\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Buffer Index\")\n",
    "# plt.ylabel(\"Total Population Count\")\n",
    "# plt.title(\"Population Within Buffers Over Investment Iterations\")\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}  \n",
    "\n",
    "if rerun or 'points_covered_GT' not in analysis_results:\n",
    "    point_metrics = {\n",
    "        'points_covered_GT': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers\n",
    "        ],\n",
    "        'points_covered_random': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_random\n",
    "        ],\n",
    "        'points_covered_demand': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_demand\n",
    "        ],\n",
    "        'points_covered_demand_ltn_priority': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_demand_ltn_priority\n",
    "        ],\n",
    "        'points_covered_betweenness_ltn_priority': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "    analysis_results.update(point_metrics)\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Number of Points Covered')\n",
    "plt.title('Seed Points Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/seed_point_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LTN Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_buffers = []\n",
    "# counts_random = []\n",
    "\n",
    "# # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# for gdf in GTs_buffers:\n",
    "#     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     # Count the points that fall within this union\n",
    "#     count = ltn_points.within(buffer_union).sum()\n",
    "#     counts_buffers.append(count)\n",
    "\n",
    "# # Do the same for GTs_buffers_random\n",
    "# for gdf in GTs_buffers_random:\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     count = ltn_points.within(buffer_union).sum()\n",
    "#     counts_random.append(count)\n",
    "\n",
    "# # Plotting the results on a line graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Number of Points Covered')\n",
    "# plt.title('Points Covered by Each Buffer')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# LTN point coverage analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'ltn_points_covered_GT' not in analysis_results:\n",
    "    def compute_ltn_coverage(buffers_list):\n",
    "        return [\n",
    "            ltn_points.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "    \n",
    "    analysis_results.update({\n",
    "        'ltn_points_covered_GT': compute_ltn_coverage(GTs_buffers),\n",
    "        'ltn_points_covered_random': compute_ltn_coverage(GTs_buffers_random),\n",
    "        'ltn_points_covered_demand': compute_ltn_coverage(GTs_buffers_demand),\n",
    "        'ltn_points_covered_demand_ltn_priority': compute_ltn_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'ltn_points_covered_betweenness_ltn_priority': compute_ltn_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    })\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['ltn_points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Number of LTN Points Covered')\n",
    "plt.title('LTNs Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/ltns_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about how if we were to create future LTNs, where could these go based purely on making more cycling safe?\n",
    "\n",
    "# should these be where the most cycling is on? or which area has the longest bit of cycle network added? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_buffers = []\n",
    "# counts_random = []\n",
    "\n",
    "# # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# for gdf in GTs_buffers:\n",
    "#     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     # Count the points in combined_points that fall within this union\n",
    "#     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "#     counts_buffers.append(count)\n",
    "\n",
    "# # Do the same for GTs_buffers_random\n",
    "# for gdf in GTs_buffers_random:\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "#     counts_random.append(count)\n",
    "\n",
    "# # Plotting the results on a line graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Number of Points Covered')\n",
    "# plt.title('Points Covered by Each Buffer')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# Neighborhood centroids analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "    def count_neighborhood_coverage(buffers_list):\n",
    "        return [\n",
    "            all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "\n",
    "    neighborhood_metrics = {\n",
    "        'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "        'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "        'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "        'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    }\n",
    "\n",
    "    analysis_results.update(neighborhood_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['neighborhood_points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Neighbourhoods Covered')\n",
    "plt.title('Neighbourhoods Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/neighbourhoods_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## against random baseline\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "    def count_neighborhood_coverage(buffers_list):\n",
    "        return [\n",
    "            all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "\n",
    "    neighborhood_metrics = {\n",
    "        'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "        'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "        'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "        'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    }\n",
    "\n",
    "    analysis_results.update(neighborhood_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}) \\\n",
    "        .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Calculate deviation from random\n",
    "random_coverage = np.array(analysis_results['neighborhood_points_covered_random'])\n",
    "\n",
    "coverage_deviations = {\n",
    "    'Betweenness': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_GT']) - random_coverage,\n",
    "        'color': 'orange',\n",
    "        'linestyle': '-'\n",
    "    },\n",
    "    'Demand': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_demand']) - random_coverage,\n",
    "        'color': 'red',\n",
    "        'linestyle': '-.'\n",
    "    },\n",
    "    'Demand LTN': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_demand_ltn_priority']) - random_coverage,\n",
    "        'color': 'green',\n",
    "        'linestyle': ':'\n",
    "    },\n",
    "    'Betweenness LTN': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_betweenness_ltn_priority']) - random_coverage,\n",
    "        'color': 'purple',\n",
    "        'linestyle': '-'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Plot deviation from random\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(random_coverage) + 1)\n",
    "\n",
    "for label, data in coverage_deviations.items():\n",
    "    plt.plot(\n",
    "        x_vals,\n",
    "        data['values'],\n",
    "        linestyle=data['linestyle'],\n",
    "        color=data['color'],\n",
    "        label=label\n",
    "    )\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Deviation in Neighbourhoods Covered (vs Random)')\n",
    "plt.title('Neighbourhood Coverage — Deviation from Random Growth (Baseline)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "output_path = PATH[\"plots\"] + f\"/{placeid}/neighbourhoods_coverage__deviation_from_random.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap with existing infrastructure. Finding how much of the existing network we overlap, in terms of edges, distance, and % of total network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_against_reference(graph_list1, graph_list2, reference_graph):\n",
    "#     \"\"\"\n",
    "#     Compare two lists of graphs against a reference, calculating both:\n",
    "#     1. How much of the reference is covered by each graph (original metric)\n",
    "#     2. How much of each graph is covered by the reference (reverse metric)\n",
    "#     \"\"\"\n",
    "#     def calculate_both_ways(graph, reference):\n",
    "#         # Original: how much of reference is covered by graph\n",
    "#         orig_size_pct, orig_len_pct, orig_edges, orig_len = calculate_overlap_percentages(reference, graph)\n",
    "#         # Reverse: how much of graph is covered by reference\n",
    "#         rev_size_pct, rev_len_pct, rev_edges, rev_len = calculate_overlap_percentages(graph, reference)\n",
    "#         return (orig_size_pct, orig_len_pct, orig_edges, orig_len,\n",
    "#                 rev_size_pct, rev_len_pct, rev_edges, rev_len)\n",
    "    \n",
    "#     metrics_list1 = [calculate_both_ways(g, reference_graph) for g in graph_list1]\n",
    "#     metrics_list2 = [calculate_both_ways(g, reference_graph) for g in graph_list2]\n",
    "    \n",
    "#     return metrics_list1, metrics_list2\n",
    "\n",
    "# def plot_comparison(metrics_GTs, metrics_GTs_random):\n",
    "#     \"\"\"Plot comparison with separate views for both metrics\"\"\"\n",
    "#     fig, axes = plt.subplots(4, 1, figsize=(12, 16))\n",
    "    \n",
    "#     # Original percentage metrics (how much of REFERENCE is covered)\n",
    "#     axes[0].plot([m[0] for m in metrics_GTs], 'b-', label='GTs Size (Ref Covered)')\n",
    "#     axes[0].plot([m[0] for m in metrics_GTs_random], 'r--', label='GTs_random Size (Ref Covered)')\n",
    "#     axes[0].plot([m[1] for m in metrics_GTs], 'g-', label='GTs Length (Ref Covered)')\n",
    "#     axes[0].plot([m[1] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Ref Covered)')\n",
    "#     axes[0].set_title('Percentage of Reference Covered')\n",
    "#     axes[0].set_ylabel('Percentage')\n",
    "#     axes[0].legend()\n",
    "#     axes[0].grid(True)\n",
    "    \n",
    "#     # Reverse percentage metrics (how much of NETWORK is covered by reference)\n",
    "#     axes[1].plot([m[4] for m in metrics_GTs], 'b-', label='GTs Size (Network Covered)')\n",
    "#     axes[1].plot([m[4] for m in metrics_GTs_random], 'r--', label='GTs_random Size (Network Covered)')\n",
    "#     axes[1].plot([m[5] for m in metrics_GTs], 'g-', label='GTs Length (Network Covered)')\n",
    "#     axes[1].plot([m[5] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Network Covered)')\n",
    "#     axes[1].set_title('Percentage of Network Covered by Reference')\n",
    "#     axes[1].set_ylabel('Percentage')\n",
    "#     axes[1].legend()\n",
    "#     axes[1].grid(True)\n",
    "    \n",
    "#     # Raw edge counts\n",
    "#     axes[2].plot([m[2] for m in metrics_GTs], 'b-', label='GTs Edges (Ref Covered)')\n",
    "#     axes[2].plot([m[2] for m in metrics_GTs_random], 'r--', label='GTs_random Edges (Ref Covered)')\n",
    "#     axes[2].plot([m[6] for m in metrics_GTs], 'g-', label='GTs Edges (Network Covered)')\n",
    "#     axes[2].plot([m[6] for m in metrics_GTs_random], 'm--', label='GTs_random Edges (Network Covered)')\n",
    "#     axes[2].set_title('Raw Edge Counts')\n",
    "#     axes[2].set_ylabel('Edges')\n",
    "#     axes[2].legend()\n",
    "#     axes[2].grid(True)\n",
    "    \n",
    "#     # Raw lengths\n",
    "#     axes[3].plot([m[3] for m in metrics_GTs], 'b-', label='GTs Length (Ref Covered)')\n",
    "#     axes[3].plot([m[3] for m in metrics_GTs_random], 'r--', label='GTs_random Length (Ref Covered)')\n",
    "#     axes[3].plot([m[7] for m in metrics_GTs], 'g-', label='GTs Length (Network Covered)')\n",
    "#     axes[3].plot([m[7] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Network Covered)')\n",
    "#     axes[3].set_title('Raw Length Overlap')\n",
    "#     axes[3].set_ylabel('Length')\n",
    "#     axes[3].legend()\n",
    "#     axes[3].grid(True)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# reference = G_biketrack  # Your reference infrastructure\n",
    "# metrics_GTs, metrics_GTs_random = compare_against_reference(GTs, GTs_random, reference)\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated overlap-size analysis for no_ltn_scenario in newcastle\n",
      "Saved overlap-size plot for newcastle - no_ltn_scenario\n",
      "Updated overlap-size analysis for current_ltn_scenario in newcastle\n",
      "Saved overlap-size plot for newcastle - current_ltn_scenario\n",
      "Updated overlap-size analysis for more_ltn_scenario in newcastle\n",
      "Saved overlap-size plot for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness     = betweenness_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    GTs_demand          = demand_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn        = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "        GTs_betweenness_ltn   = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GTs\", [])\n",
    "    random_runs         = random_results[scenario].get(placeid, [])\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Overlap Size Percent\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        size_percent_betw = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_betweenness]\n",
    "        results_list.append((\"Betweenness Growth - Overlap Size Percent\", size_percent_betw))\n",
    "        random_runs_size = [\n",
    "            [utils.overlap_size_percent(G_biketrack, G) for G in run[\"GTs\"]]\n",
    "            for run in random_runs\n",
    "        ]\n",
    "        for i, run_sizes in enumerate(random_runs_size):\n",
    "            results_list.append((f\"Random Run {i+1} - Overlap Size Percent\", run_sizes))\n",
    "        results_list.append((\"random_runs_overlap_size_percent\", random_runs_size))\n",
    "        random_size_mean = np.mean(random_runs_size, axis=0).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Overlap Size Percent\", random_size_mean))\n",
    "        size_percent_demand = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_demand]\n",
    "        results_list.append((\"Demand Growth - Overlap Size Percent\", size_percent_demand))\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            size_percent_demand_ltn = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_demand_ltn]\n",
    "            results_list.append((\"Demand LTN Priority Growth - Overlap Size Percent\", size_percent_demand_ltn))\n",
    "\n",
    "            size_percent_betw_ltn = [utils.overlap_size_percent(G_biketrack, G) for G in GTs_betweenness_ltn]\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Overlap Size Percent\", size_percent_betw_ltn))\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated overlap-size analysis for {scenario} in {placeid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Overlap Size Percent\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(analysis_results[scenario][\"Random Growth (mean) - Overlap Size Percent\"], \"--\", color=\"blue\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Overlap Size Percent\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Overlap Size Percent\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Overlap Size Percent\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\" )\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Overlap Size Percent\"], \"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Overlap Size (%)\")\n",
    "    plt.title(f\"Overlap with Bike Network per Iteration ({scenario})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"overlap_size_percent.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved overlap-size plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved overlap-size deviation-from-random for no_ltn_scenario in newcastle\n",
      "Saved overlap-size deviation plot for newcastle - no_ltn_scenario\n",
      "Saved overlap-size deviation-from-random for current_ltn_scenario in newcastle\n",
      "Saved overlap-size deviation plot for newcastle - current_ltn_scenario\n",
      "Saved overlap-size deviation-from-random for more_ltn_scenario in newcastle\n",
      "Saved overlap-size deviation plot for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "for scenario in params[\"scenarios\"]:\n",
    "    # load \n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "    if rerun or \"Betweenness Growth - Overlap Size Percent Deviation from Random\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "        random_runs_size = analysis_results[scenario].get(\"random_runs_overlap_size_percent\", [])\n",
    "        random_size_mean = analysis_results[scenario].get(\"Random Growth (mean) - Overlap Size Percent\", [])\n",
    "        random_runs_dev = [utils.compute_abs_deviation(run, random_size_mean) for run in random_runs_size]\n",
    "        random_dev_mean = np.mean([np.array(dev) for dev in random_runs_dev], axis=0).tolist()\n",
    "\n",
    "        betw_series = analysis_results[scenario].get(\"Betweenness Growth - Overlap Size Percent\", [])\n",
    "        dev_betw = utils.compute_abs_deviation(betw_series, random_size_mean)\n",
    "        results_list.append((\"Betweenness Growth - Overlap Size Percent Deviation from Random\", dev_betw))\n",
    "\n",
    "        demand_series = analysis_results[scenario].get(\"Demand Growth - Overlap Size Percent\", [])\n",
    "        dev_demand = utils.compute_abs_deviation(demand_series, random_size_mean)\n",
    "        results_list.append((\"Demand Growth - Overlap Size Percent Deviation from Random\", dev_demand))\n",
    "\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            demand_ltn_series = analysis_results[scenario].get(\"Demand LTN Priority Growth - Overlap Size Percent\", [])\n",
    "            dev_demand_ltn = utils.compute_abs_deviation(demand_ltn_series, random_size_mean)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Overlap Size Percent Deviation from Random\", dev_demand_ltn))\n",
    "\n",
    "            betw_ltn_series = analysis_results[scenario].get(\"Betweenness LTN Priority Growth - Overlap Size Percent\", [])\n",
    "            dev_betw_ltn = utils.compute_abs_deviation(betw_ltn_series, random_size_mean)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Overlap Size Percent Deviation from Random\", dev_betw_ltn))\n",
    "        for i, dev_series in enumerate(random_runs_dev):\n",
    "            results_list.append((f\"Random Run {i+1} - Overlap Size Percent Deviation from Random\", dev_series))\n",
    "        results_list.append((\"Random Growth (mean) - Overlap Size Percent Deviation from Random\", random_dev_mean))\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Saved overlap-size deviation-from-random for {scenario} in {placeid}\")\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Overlap Size Percent Deviation from Random\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.4)\n",
    "        else:\n",
    "            break\n",
    "    plt.axhline(0, color=\"blue\", linestyle=\"--\", linewidth=2, label=\"Random Growth (mean)\")\n",
    "    plt.plot(analysis_results[scenario][\"Betweenness Growth - Overlap Size Percent Deviation from Random\"], \"-\", color=\"orange\", label=\"Betweenness Growth\")\n",
    "    plt.plot(analysis_results[scenario][\"Demand Growth - Overlap Size Percent Deviation from Random\"], \"-.\", color=\"red\", label=\"Demand Growth\")\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(analysis_results[scenario][\"Demand LTN Priority Growth - Overlap Size Percent Deviation from Random\"], \":\", color=\"green\", label=\"Demand LTN Priority Growth\")\n",
    "        plt.plot(analysis_results[scenario][\"Betweenness LTN Priority Growth - Overlap Size Percent Deviation from Random\"],\"-\", color=\"purple\", label=\"Betweenness LTN Priority Growth\")\n",
    "    plt.xlabel(\"Investment Iteration\")\n",
    "    plt.ylabel(\"Deviation from Random Overlap (%)\")\n",
    "    plt.title(f\"Overlap Size Percent Deviation from Random ({scenario})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"overlap_size_deviation_from_random.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved overlap-size deviation plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack_no_ltn) # no differance?\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to explore it\n",
    "\n",
    "# # work in meters\n",
    "# G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "# G_edges = G_edges.to_crs(epsg=3857)\n",
    "# G_biketrack_edges['geometry'] = G_biketrack_edges.geometry.buffer(1)\n",
    "# G_edges['geometry'] = G_edges.geometry.buffer(1)\n",
    "# joined = gpd.sjoin(G_biketrack_edges, G_edges, how=\"inner\", predicate=\"intersects\", lsuffix=\"_biketrack\", rsuffix=\"_edge\")\n",
    "\n",
    "# joined.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directness (Directness=Total Sum of Network Distances/Total Sum of Euclidean Distances​)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated directness analysis for no_ltn_scenario in newcastle\n",
      "Saved directness plot for newcastle - no_ltn_scenario\n",
      "Updated directness analysis for current_ltn_scenario in newcastle\n",
      "Saved directness plot for newcastle - current_ltn_scenario\n",
      "Updated directness analysis for more_ltn_scenario in newcastle\n",
      "Saved directness plot for newcastle - more_ltn_scenario\n"
     ]
    }
   ],
   "source": [
    "# new \n",
    "for scenario in params[\"scenarios\"]:\n",
    "    # load scenario-specific results and data\n",
    "    analysis_res_pickle = analysis_res_pickle_paths[scenario]\n",
    "    analysis_res_json   = analysis_res_json_paths[scenario]\n",
    "    analysis_results[scenario] = utils.load_results(analysis_res_pickle)\n",
    "\n",
    "    GTs_betweenness           = betweenness_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    GTs_demand                = demand_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        GTs_demand_ltn_priority      = demand_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "        GTs_betweenness_ltn_priority = betweenness_ltn_priority_results[scenario].get(placeid, {}).get(\"GT_abstracts\", [])\n",
    "    GTs_random                = random_results[scenario].get(placeid, [{}])[0].get(\"GT_abstracts\", [])\n",
    "    random_runs               = [run[\"GT_abstracts\"] for run in random_results[scenario].get(placeid, [])]\n",
    "\n",
    "    if rerun or \"Betweenness Growth - Directness\" not in analysis_results[scenario]:\n",
    "        results_list = []\n",
    "\n",
    "        # 1) Betweenness growth directness\n",
    "        direct_betw = []\n",
    "        for G in GTs_betweenness:\n",
    "            net_dist  = sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "            eucl_dist = sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True))\n",
    "            direct_betw.append(eucl_dist / net_dist if net_dist != 0 else None)\n",
    "        results_list.append((\"Betweenness Growth - Directness\", direct_betw))\n",
    "\n",
    "        # 2) Random-run directness\n",
    "        for i, run in enumerate(random_runs):\n",
    "            direct_rand = []\n",
    "            for G in run:\n",
    "                net_dist  = sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "                eucl_dist = sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True))\n",
    "                direct_rand.append(eucl_dist / net_dist if net_dist != 0 else None)\n",
    "            results_list.append((f\"Random Run {i+1} - Directness\", direct_rand))\n",
    "        random_direct_mean = np.nanmean(\n",
    "            np.array([\n",
    "                [val if val is not None else 0 for val in\n",
    "                 [(sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True)) /\n",
    "                   sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "                   if sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True)) != 0 else 0)\n",
    "                  for G in run]]\n",
    "                for run in random_runs\n",
    "            ]),\n",
    "            axis=0\n",
    "        ).tolist()\n",
    "        results_list.append((\"Random Growth (mean) - Directness\", random_direct_mean))\n",
    "\n",
    "        # 3) Demand growth directness\n",
    "        direct_demand = []\n",
    "        for G in GTs_demand:\n",
    "            net_dist  = sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "            eucl_dist = sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True))\n",
    "            direct_demand.append(eucl_dist / net_dist if net_dist != 0 else None)\n",
    "        results_list.append((\"Demand Growth - Directness\", direct_demand))\n",
    "\n",
    "        # 4) LTN-priority variants\n",
    "        if scenario != \"no_ltn_scenario\":\n",
    "            direct_demand_ltn = []\n",
    "            for G in GTs_demand_ltn_priority:\n",
    "                net_dist  = sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "                eucl_dist = sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True))\n",
    "                direct_demand_ltn.append(eucl_dist / net_dist if net_dist != 0 else None)\n",
    "            results_list.append((\"Demand LTN Priority Growth - Directness\", direct_demand_ltn))\n",
    "\n",
    "            direct_betw_ltn = []\n",
    "            for G in GTs_betweenness_ltn_priority:\n",
    "                net_dist  = sum(data.get(\"eucl_dist\", 0) for _, _, data in G.edges(data=True))\n",
    "                eucl_dist = sum(data.get(\"sp_true_distance\", 0) for _, _, data in G.edges(data=True))\n",
    "                direct_betw_ltn.append(eucl_dist / net_dist if net_dist != 0 else None)\n",
    "            results_list.append((\"Betweenness LTN Priority Growth - Directness\", direct_betw_ltn))\n",
    "\n",
    "        # save results\n",
    "        utils.save_results(results_list, analysis_res_pickle, analysis_res_json)\n",
    "        analysis_results[scenario] = {label: data for label, data in results_list}\n",
    "        print(f\"Updated directness analysis for {scenario} in {placeid}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(1, 100):\n",
    "        key = f\"Random Run {i} - Directness\"\n",
    "        if key in analysis_results[scenario]:\n",
    "            plt.plot(analysis_results[scenario][key], color=\"lightgray\", linewidth=1, alpha=0.5)\n",
    "        else:\n",
    "            break\n",
    "    plt.plot(\n",
    "        analysis_results[scenario][\"Random Growth (mean) - Directness\"],\n",
    "        \"--\", color=\"blue\", linewidth=2, label=\"Random\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        analysis_results[scenario][\"Betweenness Growth - Directness\"],\n",
    "        \"-\", color=\"orange\", label=\"Betweenness\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        analysis_results[scenario][\"Demand Growth - Directness\"],\n",
    "        \"-.\", color=\"red\", label=\"Demand\"\n",
    "    )\n",
    "    if scenario != \"no_ltn_scenario\":\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Demand LTN Priority Growth - Directness\"],\n",
    "            \":\", color=\"green\", label=\"Demand LTN\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            analysis_results[scenario][\"Betweenness LTN Priority Growth - Directness\"],\n",
    "            \"-\", color=\"purple\", label=\"Betweenness LTN\"\n",
    "        )\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Directness (Euclidean / Network)\")\n",
    "    plt.title(f\"Network Directness Comparison ({scenario} - {placeid})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(PATH[\"plots\"], placeid, scenario, \"directness.png\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved directness plot for {placeid} - {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_dist = []\n",
    "# eucl_dist = []\n",
    "# directness = []\n",
    "\n",
    "# for G in GT_abstracts:\n",
    "#     total_net_dist = sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "#     total_eucl_dist = sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "#     net_dist.append(total_net_dist)\n",
    "#     eucl_dist.append(total_eucl_dist)\n",
    "#     if total_net_dist != 0:\n",
    "#         ratio = total_eucl_dist / total_net_dist\n",
    "#     else:\n",
    "#         ratio = None\n",
    "#     directness.append(ratio)\n",
    "\n",
    "\n",
    "# net_dist_random = []\n",
    "# eucl_dist_random = []\n",
    "# directness_random = []\n",
    "\n",
    "# for G in GT_abstracts_random:\n",
    "#     total_net_dist = sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "#     total_eucl_dist = sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "#     net_dist_random.append(total_net_dist)\n",
    "#     eucl_dist_random.append(total_eucl_dist)\n",
    "#     if total_net_dist != 0:\n",
    "#         ratio = total_eucl_dist / total_net_dist\n",
    "#     else:\n",
    "#         ratio = None\n",
    "#     directness_random.append(ratio)\n",
    "\n",
    "\n",
    "\n",
    "# # Plotting \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(directness, linestyle='-', color='blue', label='Betweeness')\n",
    "# plt.plot(directness_random, linestyle='--', color='orange', label='Random')\n",
    "# plt.xlabel('Graph Index')\n",
    "# plt.ylabel('Directness (Euclidean / Network Distance)')\n",
    "# plt.title('Total Network Directness')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Directness analysis \n",
    "\n",
    "# old \n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'directness_demand' not in analysis_results:\n",
    "    directness_metrics = {\n",
    "        # Betweenness\n",
    "        'directness_net': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'directness_eucl': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'directness': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "\n",
    "        # Random\n",
    "        'directness_net_random': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'directness_eucl_random': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'directness_random': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "\n",
    "        # Demand\n",
    "        'directness_net_demand': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'directness_eucl_demand': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'directness_demand': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "\n",
    "        # Demand LTN Priority\n",
    "        'directness_net_demand_ltn_priority': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'directness_eucl_demand_ltn_priority': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'directness_demand_ltn_priority': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "\n",
    "        # Betweenness LTN Priority\n",
    "        'directness_net_betweenness_ltn_priority': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ],\n",
    "        'directness_eucl_betweenness_ltn_priority': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ],\n",
    "        'directness_betweenness_ltn_priority': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(directness_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    analysis_results['directness'],\n",
    "    linestyle='--', \n",
    "    color='orange', \n",
    "    label='Betweenness'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_random'],\n",
    "    linestyle='-', \n",
    "    color='blue', \n",
    "    label='Random'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_demand'],\n",
    "    linestyle='-.', \n",
    "    color='red', \n",
    "    label='Demand'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_demand_ltn_priority'],\n",
    "    linestyle=':', \n",
    "    color='green', \n",
    "    label='Demand LTN'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_betweenness_ltn_priority'],\n",
    "    linestyle='-', \n",
    "    color='purple', \n",
    "    label='Betweenness LTN'\n",
    ")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Directness (Euclidean / Network Distance)')\n",
    "plt.title('Network Directness Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/directness.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcaulate directness of existing network to compare against..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## edit plotting\n",
    "# def calculate_efficiency(G):\n",
    "#     \"\"\"Calculate global network efficiency using formula E = 1/(N(N-1)) * Σ 1/d_ij\"\"\"\n",
    "#     # Convert to undirected graph\n",
    "#     undirected_G = nx.Graph(G)\n",
    "#     try:\n",
    "#         return nx.global_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         return 0  # Handle disconnected graphs\n",
    "\n",
    "# def plot_efficiency_comparison(GTs, GTs_random):\n",
    "#     \"\"\"Calculate and plot global efficiency for both graph lists\"\"\"\n",
    "#     # Calculate efficiencies\n",
    "#     eff_GTs = [calculate_efficiency(G) for G in GTs]\n",
    "#     eff_random = [calculate_efficiency(G) for G in GTs_random]\n",
    "    \n",
    "#     # Create plot\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(eff_GTs, 'b-', linewidth=2, label='GTs Efficiency')\n",
    "#     plt.plot(eff_random, 'r--', linewidth=2, label='GTs_random Efficiency')\n",
    "    \n",
    "#     plt.title('Global Network Efficiency Comparison\\n$E = \\\\frac{1}{N(N-1)}\\\\sum_{i\\\\neq j} \\\\frac{1}{d_{ij}}$')\n",
    "#     plt.ylabel('Global Efficiency')\n",
    "#     plt.xlabel('Graph Instance Index')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Usage example:\n",
    "# plot_efficiency_comparison(GTs, GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_efficiency(G, numnodepairs=500, normalized=True, weight='weight', debug=False):\n",
    "    \"\"\"Calculates global network efficiency for a graph G.\"\"\"\n",
    "    if G is None or len(G) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    nodes = list(G.nodes)\n",
    "    N = len(nodes)\n",
    "    \n",
    "    if N > numnodepairs:\n",
    "        sampled_nodes = random.sample(nodes, numnodepairs)\n",
    "    else:\n",
    "        sampled_nodes = nodes\n",
    "    S = len(sampled_nodes)\n",
    "    if S < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    total_efficiency = 0.0\n",
    "    considered_pairs = S * (S - 1)  \n",
    "    \n",
    "    for u in sampled_nodes:\n",
    "        try:\n",
    "            lengths = nx.single_source_dijkstra_path_length(G, u, weight=weight)\n",
    "            for v in sampled_nodes:\n",
    "                if u == v: continue\n",
    "                d = lengths.get(v, float('inf'))\n",
    "                if 0 < d < float('inf'):\n",
    "                    total_efficiency += 1 / d\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if considered_pairs == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Always use considered_pairs for unnormalized\n",
    "    EG = total_efficiency / considered_pairs  # average efficiency\n",
    "    \n",
    "    if not normalized:\n",
    "        return EG  # Directly return average efficiency of sampled pairs\n",
    "    \n",
    "    # Normalisation logic \n",
    "    for node in sampled_nodes:\n",
    "        if 'x' not in G.nodes[node] or 'y' not in G.nodes[node]:\n",
    "            raise KeyError(\"Nodes need 'x' and 'y' for normalization.\")\n",
    "    \n",
    "    ideal_total = 0.0\n",
    "    for u, v in itertools.permutations(sampled_nodes, 2):\n",
    "        x1, y1 = G.nodes[u]['x'], G.nodes[u]['y']\n",
    "        x2, y2 = G.nodes[v]['x'], G.nodes[v]['y']\n",
    "        distance = ((x1-x2)**2 + (y1-y2)**2)**0.5\n",
    "        if distance > 0:\n",
    "            ideal_total += 1 / distance\n",
    "    \n",
    "    if ideal_total == 0:\n",
    "        return 0.0\n",
    "    \n",
    "\n",
    "    ideal_avg = ideal_total / considered_pairs\n",
    "    normalized_efficiency = EG / ideal_avg\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Actual Avg: {EG}, Ideal Avg: {ideal_avg}, Normalized: {normalized_efficiency}\")\n",
    "    \n",
    "    return normalized_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_global_efficiency(G, numnodepairs=500, normalized=True, weight='length', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'efficiency_demand' not in analysis_results:\n",
    "    efficiency_metrics = {\n",
    "        'efficiency': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'efficiency_random': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'efficiency_demand': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'efficiency_demand_ltn_priority': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'efficiency_betweenness_ltn_priority': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    analysis_results.update(efficiency_metrics)  \n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot efficiency from analysis_results\n",
    "plt.plot(\n",
    "    analysis_results['efficiency'],\n",
    "    linestyle='-', \n",
    "    color='orange',\n",
    "    label='Betweenness'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_random'],\n",
    "    linestyle='--', \n",
    "    color='blue',\n",
    "    label='Random'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_demand'],\n",
    "    linestyle='-.', \n",
    "    color='red',\n",
    "    label='Demand'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_demand_ltn_priority'],\n",
    "    linestyle=':', \n",
    "    color='green',\n",
    "    label='Demand LTN'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_betweenness_ltn_priority'],\n",
    "    linestyle='-', \n",
    "    color='purple',\n",
    "    label='Betweenness LTN'\n",
    ")\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Global Efficiency', fontsize=12)\n",
    "plt.title('Global Network Efficiency Comparison', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/global_eff.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot both lines\n",
    "plt.plot(x, eff_GTs, label='GTs',  linestyle='-', color='blue')\n",
    "plt.plot(x_random, eff_GTs_random, label='GTs Random', linestyle='--', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Graph Index', fontsize=12)\n",
    "plt.ylabel('Global Efficiency', fontsize=12)\n",
    "plt.title('Global Network Efficiency Comparison', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Customize ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_efficiencies(G):\n",
    "#     \"\"\"Calculate both global and local efficiencies\"\"\"\n",
    "#     # Convert to undirected graph\n",
    "#     undirected_G = nx.Graph(G)\n",
    "    \n",
    "#     try:\n",
    "#         global_eff = nx.global_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         global_eff = 0\n",
    "        \n",
    "#     try:\n",
    "#         local_eff = nx.local_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         local_eff = 0\n",
    "        \n",
    "#     return global_eff, local_eff\n",
    "\n",
    "# def plot_efficiency_comparison(GTs, GTs_random):\n",
    "#     \"\"\"Plot comparison of both efficiency metrics\"\"\"\n",
    "#     # Calculate efficiencies\n",
    "#     global_GTs, local_GTs = zip(*[calculate_efficiencies(G) for G in GTs])\n",
    "#     global_random, local_random = zip(*[calculate_efficiencies(G) for G in GTs_random])\n",
    "    \n",
    "#     # Create plots\n",
    "#     fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "#     # Global efficiency plot\n",
    "#     ax1.plot(global_GTs, 'b-', linewidth=2, label='GTs Global Eff')\n",
    "#     ax1.plot(global_random, 'r--', linewidth=2, label='GTs_random Global Eff')\n",
    "#     ax1.set_title('Global Network Efficiency Comparison')\n",
    "#     ax1.set_ylabel('Efficiency')\n",
    "#     ax1.legend()\n",
    "#     ax1.grid(True)\n",
    "#     ax1.set_ylim(0, 1)\n",
    "    \n",
    "#     # Local efficiency plot\n",
    "#     ax2.plot(local_GTs, 'g-', linewidth=2, label='GTs Local Eff')\n",
    "#     ax2.plot(local_random, 'm--', linewidth=2, label='GTs_random Local Eff')\n",
    "#     ax2.set_title('Local Network Efficiency Comparison')\n",
    "#     ax2.set_ylabel('Efficiency')\n",
    "#     ax2.legend()\n",
    "#     ax2.grid(True)\n",
    "#     ax2.set_ylim(0, 1)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Usage example:\n",
    "# plot_efficiency_comparison(GTs, GTs_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Pretty plots of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjust the width and height as needed\n",
    "\n",
    "\n",
    "\n",
    "G_biketrackcarall_edges = ox.graph_to_gdfs(G_biketrackcarall, nodes=False)\n",
    "G_biketrackcarall_edges = G_biketrackcarall_edges.to_crs(epsg=3857)  # Ensure CRS matches\n",
    "G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder = 0)  # Light grey with thin linewidth\n",
    "\n",
    "# Add bike track edges\n",
    "#G_biketrack = {}\n",
    "#G_biketrack[placeid] = csv_to_ox(PATH[\"data\"] + placeid + \"/\", placeid, 'biketrack')\n",
    "#G_biketrack[placeid].graph[\"crs\"] = 'epsg:4326'  # Needed for OSMNX's graph_to_gdfs in utils_graph.py\n",
    "#G_biketrack = copy.deepcopy(G_biketrack[placeid])\n",
    "G_biketrack_edges = ox.graph_to_gdfs(G_biketrack, nodes=False)\n",
    "G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder = 1)  # Light grey with thin linewidth\n",
    "\n",
    "\n",
    "# Plot the main graph and layers\n",
    "GT_nodes, GT_edges = ox.graph_to_gdfs(GTs[iteration_number])\n",
    "GT_edges = GT_edges.to_crs(epsg=3857)\n",
    "GT_edges.plot(ax=ax, color='orange')\n",
    "ltn_points.to_crs(epsg=3857).plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "tess_points.to_crs(epsg=3857).plot(ax=ax, color='green', markersize=5, zorder = 3)\n",
    "\n",
    "\n",
    "ltns = ltns.to_crs(epsg=3857)  # Ensure the CRS matches\n",
    "ltns.plot(ax=ax, color='blue', alpha=0.5, label=f\"Low Traffic Neighbourhoods\", zorder=2)\n",
    "\n",
    "\n",
    "# Remove x and y axis labels and ticks\n",
    "ax.axis('off')  # This removes the entire axis, including labels and ticks\n",
    "\n",
    "ax.set_title(f\"Iteration: {iteration_number + 1}\")\n",
    "#ax.legend(loc=\"upper left\")\n",
    "\n",
    "output_path = fr\"C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\Conferances etc\\GISRUK 2025\\Plots\\{iteration_number}_network_plot.png\"\n",
    "plt.savefig(output_path, dpi=600, bbox_inches='tight'\n",
    "            #, transparent=True\n",
    "            )\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif_path = r\"C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\networkGrowth\\bikenwgrowth_external\\videos\\newcastle\\investment_animation_pct.gif\"\n",
    "\n",
    "# # Set up a figure for animation\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# def update(idx):\n",
    "#     \"\"\"Update function for each frame in the animation.\"\"\"\n",
    "#     ax.clear()  # Clear previous frame\n",
    "#     G = GTs[idx]\n",
    "#     # Skip empty graphs\n",
    "#     if len(G.edges()) == 0:\n",
    "#         print(f\"Graph {idx + 1} has no edges, skipping plot.\")\n",
    "#         return\n",
    "    \n",
    "#     # Add G_weighted edges\n",
    "#     G_weighted_edges = ox.graph_to_gdfs(G_weighted, nodes=False)\n",
    "#     G_weighted_edges = G_weighted_edges.to_crs(epsg=3857)\n",
    "#     G_weighted_edges.plot(ax=ax, color='grey', linewidth=0.5, alpha=0.6, zorder=0)\n",
    "\n",
    "#     # Add bike track edges\n",
    "#     G_biketrack_nodes, G_biketrack_edges = ox.graph_to_gdfs(G_biketrack)\n",
    "#     G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "#     G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=0.5, alpha=0.8, zorder=1)\n",
    "\n",
    "#     # Plot main graph\n",
    "#     GT_nodes, GT_edges = ox.graph_to_gdfs(G)\n",
    "#     GT_edges = GT_edges.to_crs(epsg=3857)\n",
    "#     GT_edges.plot(ax=ax, color='orange')\n",
    "\n",
    "#     # Plot additional layers\n",
    "#     ltn_gdf.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "#     tess_gdf.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "\n",
    "#     # Plot the neighbourhood\n",
    "#     placename = \"Newcastle Upon Tyne\"\n",
    "#     if placename in neighbourhoods:\n",
    "#         neighbourhood_gdf = neighbourhoods[placename].to_crs(epsg=3857)\n",
    "#         neighbourhood_gdf.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "#     # Remove axis and set title\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(f\"Meters of investment: {D/10}\")\n",
    "\n",
    "# # Create animation\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(GTs), repeat=False)\n",
    "\n",
    "# # Save the animation as a GIF using PillowWriter\n",
    "# ani.save(gif_path, writer=animation.PillowWriter(fps=6))\n",
    "\n",
    "# print(f\"GIF saved to: {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete once happy with cell below\n",
    "# neighbourhoods = load_neighbourhoods(os.path.join(PATH[\"data\"], placeid))\n",
    "# G_biketrackcarall_edges = (\n",
    "#     ox.graph_to_gdfs(G_biketrackcarall, nodes=False)\n",
    "#       .to_crs(epsg=3857)\n",
    "# )\n",
    "# G_biketrack_edges = (\n",
    "#     ox.graph_to_gdfs(G_biketrack, nodes=False)\n",
    "#       .to_crs(epsg=3857)\n",
    "# )\n",
    "\n",
    "# ltn_points_crs = ltn_points.to_crs(epsg=3857)\n",
    "# tess_points_crs = tess_points.to_crs(epsg=3857)\n",
    "# neighbourhoods = load_neighbourhoods(PATH[\"data\"] + placeid + \"/\")\n",
    "# ltns = neighbourhoods.get(\"ltns\", None)\n",
    "# ltns_gdf = None\n",
    "# if neighbourhoods:\n",
    "#     _, ltns_gdf = next(iter(neighbourhoods.items())) # get the first geodataframe in neighbourhoods. Should fix this to a more elegant solution\n",
    "#     ltns = ltns_gdf.to_crs(epsg=3857) \n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))  \n",
    "\n",
    "# def update(idx):\n",
    "#     \"\"\"Update function called for each animation frame.\"\"\"\n",
    "#     ax.clear()  # clear the axis for the new frame\n",
    "\n",
    "#     # Plot the static background layers first.\n",
    "#     G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder=0)\n",
    "#     G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder=1)\n",
    "\n",
    "#     # Get the current main graph from your list of graphs GTs.\n",
    "#     current_graph = GTs[idx]\n",
    "#     if len(current_graph.edges()) == 0:\n",
    "#         print(f\"Graph {idx + 1} has no edges, skipping plot.\")\n",
    "#         return\n",
    "\n",
    "#     # Convert the main graph to GeoDataFrames and reproject\n",
    "#     GT_nodes, GT_edges = ox.graph_to_gdfs(current_graph)\n",
    "#     GT_edges.to_crs(epsg=3857).plot(ax=ax, color='orange')\n",
    "    \n",
    "#     # Plot additional layers.\n",
    "#     ltn_points_crs.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "#     tess_points_crs.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "#     ltns.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(f\"Iterations completed: {idx + 1}%\", fontsize=14)\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(GT_abstracts), repeat=False)\n",
    "\n",
    "# # Construct the output file path flexibly\n",
    "# output_gif = os.path.join(PATH[\"videos\"], placeid + \"/\" f\"investment_animation{prune_measure}.gif\")\n",
    "# output_gif = os.path.join(PATH[\"videos\"], placeid + \"/\" f\"betweenness_greedyTri.gif\")\n",
    "# # Create the directory if it doesn't exist.\n",
    "# os.makedirs(os.path.dirname(output_gif), exist_ok=True)\n",
    "\n",
    "# # Save the animation as a GIF with PillowWriter.\n",
    "# ani.save(output_gif, writer=animation.PillowWriter(fps=6))\n",
    "\n",
    "# print(f\"GIF saved to: {output_gif}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new plotting function\n",
    "def plot_investment_animation(\n",
    "    graph_list,\n",
    "    output_path,\n",
    "    G_biketrackcarall,\n",
    "    G_biketrack,\n",
    "    ltn_points,\n",
    "    tess_points,\n",
    "    neighbourhoods,\n",
    "    fps=4,\n",
    "    title_prefix=\"Iteration number: \",\n",
    "    crs_epsg=3857,\n",
    "    figsize=(12, 8)\n",
    "):\n",
    "    \"\"\"Generate and save an animated GIF showing network growth over time.\"\"\"\n",
    "\n",
    "    G_biketrackcarall_edges = (\n",
    "        ox.graph_to_gdfs(G_biketrackcarall, nodes=False).to_crs(epsg=crs_epsg)\n",
    "    )\n",
    "    G_biketrack_edges = (\n",
    "        ox.graph_to_gdfs(G_biketrack, nodes=False).to_crs(epsg=crs_epsg)\n",
    "    )\n",
    "    ltn_points_crs = ltn_points.to_crs(epsg=crs_epsg)\n",
    "    tess_points_crs = tess_points.to_crs(epsg=crs_epsg)\n",
    "\n",
    "    # Get a neighbourhood GeoDataFrame from the dictionary\n",
    "    ltns = None\n",
    "    if neighbourhoods:\n",
    "        _, ltns_gdf = next(iter(neighbourhoods.items()))\n",
    "        ltns = ltns_gdf.to_crs(epsg=crs_epsg)\n",
    "\n",
    "    # Set up the figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    def update(idx):\n",
    "        ax.clear()\n",
    "        G = graph_list[idx]\n",
    "        if 'crs' not in G.graph:\n",
    "            G.graph['crs'] = f\"epsg:{crs_epsg}\"\n",
    "\n",
    "        # Static background layers\n",
    "        G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder=0)\n",
    "        G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder=1)\n",
    "\n",
    "        # Skip empty graphs\n",
    "        if len(G.edges()) == 0:\n",
    "            print(f\"Graph {idx + 1} has no edges, skipping.\")\n",
    "            return\n",
    "\n",
    "        # Main graph\n",
    "        _, edges = ox.graph_to_gdfs(G)\n",
    "        edges.to_crs(epsg=crs_epsg).plot(ax=ax, color='orange')\n",
    "\n",
    "        # Point layers\n",
    "        ltn_points_crs.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "        tess_points_crs.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "\n",
    "        # LTN areas\n",
    "        if ltns is not None:\n",
    "            ltns.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{title_prefix} - iterations completed: {idx + 1}%\", fontsize=14)\n",
    "\n",
    "    # Create animation\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(graph_list), repeat=False)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "\n",
    "    ani.save(output_path, writer=animation.PillowWriter(fps=fps), dpi=400)\n",
    "    print(f\"GIF saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run plotting function\n",
    "plot_investment_animation(\n",
    "    graph_list=GT_abstracts_demand,\n",
    "    output_path=os.path.join(PATH[\"videos\"], placeid, f\"demand_abstract_animation.gif\"),\n",
    "    G_biketrackcarall=G_biketrackcarall,\n",
    "    G_biketrack=G_biketrack,\n",
    "    ltn_points=ltn_points,\n",
    "    tess_points=tess_points,\n",
    "    neighbourhoods=load_neighbourhoods(os.path.join(PATH[\"data\"], placeid)),\n",
    "    title_prefix=\"Demand growth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfinshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack_no_ltn) # no differance?\n",
    "plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
