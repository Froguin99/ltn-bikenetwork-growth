{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Analysis of bicycle network results\n",
    "## Project: Growing Urban Bicycle Networks with LTNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the existing infrastructure, the results from 03_poi_based_generation and calculates/analyzes a number of measures:\n",
    "* cost (length)\n",
    "* coverage  \n",
    "* directness  \n",
    "* efficiency\n",
    "* overlap with existing networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- find neighbourhoods where large amounts of residiental streets are used to potentially convert to LTNs\n",
    "- Comparison between LTN prioirtised and \"normal\" growth\n",
    "- only runs for one place at at time currently (my bad coding skills + getting stuck down rabbitholes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from src import utils\n",
    "PATH = utils.PATH # shortening the var name so that we don't have to change it below\n",
    "\n",
    "# System\n",
    "import csv\n",
    "import os\n",
    "import dill as pickle\n",
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from copy import deepcopy\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "# Math/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Network\n",
    "import networkx as nx\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Geo\n",
    "import osmnx as ox\n",
    "ox.settings.log_file = True\n",
    "ox.settings.requests_timeout = 300\n",
    "ox.settings.logs_folder = PATH[\"logs\"]\n",
    "import geopandas as gpd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "# if not debug: # Only do this if sure the code is bug-free!\n",
    "#     warnings.filterwarnings('ignore')\n",
    "rerun_existing = True # If True, will re-run the costly analysis of existing infra even if files already exist.\n",
    "rerun = True # If True, recompute the analysis. If false, just re-make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.load(\n",
    "    open(\"../parameters/parameters.yml\"), \n",
    "    Loader=yaml.FullLoader)\n",
    "osmnxparameters = json.load(open(\"../parameters/osmnxparameters.json\", \"r\"))\n",
    "plotparam = json.load(open(\"../parameters/plotparam.json\", \"r\"))\n",
    "plotparam_analysis = json.load(open(\"../parameters/plotparam_analysis.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network weighting by tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_lts = json.load(open(\"../parameters/tag_lts.json\", \"r\"))\n",
    "distance_cost = json.load(open(\"../parameters/distance_cost.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweeness\n",
    "filename = PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_poi_{poi_source}_{prune_measure}_weighted.pickle\"  \n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "else:\n",
    "    print(f\"File {filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random (many runs to get a distribution)\n",
    "pattern = os.path.join(PATH[\"results\"], placeid, f\"{placeid}_poi_{poi_source}_random_weighted_run*.pickle\")\n",
    "random_files = sorted(glob.glob(pattern))\n",
    "random_runs = []\n",
    "for fn in random_files:\n",
    "    with open(fn, \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "    random_runs.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand\n",
    "filename = PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_poi_{poi_source}_demand_weighted.pickle\"  \n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        results_demand = pickle.load(f)\n",
    "else:\n",
    "    print(f\"File {filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand LTN priority\n",
    "filename = PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_poi_{poi_source}_demand_ltn_priority_weighted.pickle\"  \n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        results_demand_ltn_priority = pickle.load(f)\n",
    "else:\n",
    "    print(f\"File {filename} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweeness LTN priority\n",
    "filename = PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_poi_{poi_source}_{prune_measure}_ltn_priority_weighted.pickle\"  \n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        results_betweenness_ltn_priority = pickle.load(f)\n",
    "else:\n",
    "    print(f\"File {filename} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to access....\n",
    "# investment_levels = results[\"prune_quantiles\"]\n",
    "# GTs = results[\"GTs\"]\n",
    "# GT_abstracts = results[\"GT_abstracts\"]\n",
    "\n",
    "# # For example, convert the first graph in GTs to GeoDataFrames\n",
    "# import osmnx as ox\n",
    "# nodes, edges = ox.graph_to_gdfs(GTs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find investment level, split results into GTs, GT_abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_levels = results[\"prune_quantiles\"]\n",
    "GTs = results[\"GTs\"]\n",
    "GT_abstracts = results[\"GT_abstracts\"]\n",
    "\n",
    "if random_runs:\n",
    "    GTs_random = [res[\"GTs\"] for res in random_runs]\n",
    "    GT_abstracts_random = [res[\"GT_abstracts\"] for res in random_runs]\n",
    "    investment_levels_random = random_runs[0][\"prune_quantiles\"] \n",
    "\n",
    "if results_demand:\n",
    "    GTs_demand = results_demand[\"GTs\"]\n",
    "    GT_abstracts_demand = results_demand[\"GT_abstracts\"]\n",
    "    investment_levels_demand = results_demand[\"prune_quantiles\"]\n",
    "\n",
    "if results_demand_ltn_priority:\n",
    "    GTs_demand_ltn_priority = results_demand_ltn_priority[\"GTs\"]\n",
    "    GT_abstracts_demand_ltn_priority = results_demand_ltn_priority[\"GT_abstracts\"]\n",
    "    investment_levels_demand_ltn_priority = results_demand_ltn_priority[\"prune_quantiles\"]\n",
    "\n",
    "if results_betweenness_ltn_priority:\n",
    "    GTs_betweenness_ltn_priority = results_betweenness_ltn_priority[\"GTs\"]\n",
    "    GT_abstracts_betweenness_ltn_priority = results_betweenness_ltn_priority[\"GT_abstracts\"]\n",
    "    investment_levels_betweenness_ltn_priority = results_betweenness_ltn_priority[\"prune_quantiles\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing networks, nodes, GeoDataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc=\"Networks for Cities\"):\n",
    "    # get biketrack graph\n",
    "    gpkg_path = PATH[\"data\"] + placeid + \"/\" + placeid + '_biketrack.gpkg'\n",
    "    G_biketrack = ox_gpkg_to_graph(gpkg_path)\n",
    "    G_biketrack.remove_nodes_from(list(nx.isolates(G_biketrack)))\n",
    "\n",
    "\n",
    "    # get biketrack graph without LTNs\n",
    "    gpkg_path = PATH[\"data\"] + placeid + \"/\" + placeid + '_biketrack_no_ltn.gpkg'\n",
    "    G_biketrack_no_ltn = ox_gpkg_to_graph(gpkg_path)\n",
    "    G_biketrack_no_ltn.remove_nodes_from(list(nx.isolates(G_biketrack)))\n",
    "\n",
    "\n",
    "    # get biketrack graph without LTNs\n",
    "    gpkg_path = PATH[\"data\"] + placeid + \"/\" + placeid + '_biketrackcarall.gpkg'\n",
    "    G_biketrackcarall = ox_gpkg_to_graph(gpkg_path)\n",
    "    G_biketrackcarall.remove_nodes_from(list(nx.isolates(G_biketrackcarall)))\n",
    "    \n",
    "    G_biketrackcarall_edges = ox.graph_to_gdfs(G_biketrackcarall, nodes=False)\n",
    "    boundary = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes \n",
    "\n",
    "for placeid, placeinfo in tqdm(cities.items(), desc=\"Points for Cities\"):\n",
    "    tess_points = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + placeid + '_tess_points.gpkg')\n",
    "    ltn_points = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + placeid + '_ltn_points.gpkg')\n",
    "    combined_points = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + placeid + '_combined_points.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ltns and all neighbourhoods\n",
    "ltns = load_neighbourhoods(PATH[\"data\"] + placeid + \"/\")\n",
    "key, df = next(iter(ltns.items()))  # Get the first key and its GeoDataFrame  \n",
    "ltns = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  \n",
    "\n",
    "\n",
    "# all neighbourhoods (regardless of their \"low traffic\" status)\n",
    "all_neighbourhoods = gpd.read_file(PATH[\"data\"] + placeid + \"/\" + 'neighbourhoods_'+  placeid + '.gpkg') # currently need to manually drag and drop in\n",
    "all_neighbourhoods_centroids = all_neighbourhoods.geometry.centroid\n",
    "all_neighbourhoods_centroids = gpd.GeoDataFrame(geometry= all_neighbourhoods_centroids, crs=all_neighbourhoods.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "def csv_to_ox(p, placeid, parameterid):\n",
    "    '''\n",
    "    Load graph from csv files (nodes and edge)\n",
    "    Include OSMID, length, highway, x, y attributes\n",
    "    '''\n",
    "\n",
    "    prefix = placeid + '_' + parameterid\n",
    "    compress = check_extract_zip(p, prefix)\n",
    "    \n",
    "    with open(p + prefix + '_edges.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        lines = []\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = str(eval(line_list[header.index(\"osmid\")])[0]) if isinstance(eval(line_list[header.index(\"osmid\")]), list) else line_list[header.index(\"osmid\")]\n",
    "            length = str(eval(line_list[header.index(\"length\")])[0]) if isinstance(eval(line_list[header.index(\"length\")]), list) else line_list[header.index(\"length\")]\n",
    "            highway = line_list[header.index(\"highway\")]\n",
    "            if highway.startswith(\"[\") and highway.endswith(\"]\"):\n",
    "                highway = highway.strip(\"[]\").split(\",\")[0].strip(\" '\")\n",
    "            line_string = f\"{line_list[header.index('u')]} {line_list[header.index('v')]} {osmid} {length} {highway}\"\n",
    "            lines.append(line_string)\n",
    "        G = nx.parse_edgelist(lines, nodetype=int, data=((\"osmid\", int), (\"length\", float), (\"highway\", str)), create_using=nx.MultiDiGraph)\n",
    "    \n",
    "    with open(p + prefix + '_nodes.csv', 'r') as f:\n",
    "        header = f.readline().strip().split(\",\")\n",
    "        values_x = {}\n",
    "        values_y = {}\n",
    "        for line in csv.reader(f, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            line_list = [c for c in line]\n",
    "            osmid = int(line_list[header.index(\"osmid\")])\n",
    "            values_x[osmid] = float(line_list[header.index(\"x\")])\n",
    "            values_y[osmid] = float(line_list[header.index(\"y\")])\n",
    "        nx.set_node_attributes(G, values_x, \"x\")\n",
    "        nx.set_node_attributes(G, values_y, \"y\")\n",
    "    \n",
    "    if compress:\n",
    "        os.remove(p + prefix + '_nodes.csv')\n",
    "        os.remove(p + prefix + '_edges.csv')\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis saving setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res_pickle = os.path.join(PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_analysis_results.pickle\")\n",
    "analysis_res_csv = os.path.join(PATH[\"results\"] + placeid + \"/\" + f\"{placeid}_analysis_results.csv\")\n",
    "analysis_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelimiary Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length - finding the distance of the connected network, along with the investment distance (length - existing infrastructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first 5 edges\n",
    "# edges = list(G.edges(data=True))[:5]\n",
    "\n",
    "# # Print the edge attributes\n",
    "# for edge in edges:\n",
    "#     print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing results if available\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "# Calculate values first (for both print and plot)\n",
    "total_biketrack = sum(nx.get_edge_attributes(G_biketrack, 'length').values())\n",
    "total_biketrack_no_ltn = sum(nx.get_edge_attributes(G_biketrack_no_ltn, 'length').values())\n",
    "total_network = sum(nx.get_edge_attributes(GTs[-1], 'length').values())\n",
    "investment_length = sum(\n",
    "    data.get('length', 0) * distance_cost.get(data.get('highway', 'unclassified'), 1)\n",
    "    for _, _, data in GTs[-1].edges(data=True)\n",
    ")\n",
    "\n",
    "\n",
    "# Store in analysis results (with both formats)\n",
    "length_stats = {\n",
    "    # For plotting\n",
    "    'length_comparison_labels': [\n",
    "        \"Existing Cycle Infrastructure (Including LTNs)\",\n",
    "        \"Existing Cycle Infrastructure (Excluding LTNs)\", \n",
    "        \"LTNs\",\n",
    "        \"Fully Connected Cycle Network\",\n",
    "        \"Investment Distance\"\n",
    "    ],\n",
    "    'length_comparison_values': [\n",
    "        total_biketrack,\n",
    "        total_biketrack_no_ltn,\n",
    "        abs(total_biketrack - total_biketrack_no_ltn),\n",
    "        total_network,\n",
    "        investment_length\n",
    "    ],\n",
    "    'length_comparison_colors': ['deepskyblue', 'deepskyblue', 'deepskyblue'],\n",
    "    \n",
    "    # For easy printing access\n",
    "    'total_network_length': total_network,\n",
    "    'total_biketrack_length': total_biketrack,\n",
    "    'total_biketrack_no_ltn_length': total_biketrack_no_ltn,\n",
    "    'length_difference': abs(total_biketrack - total_biketrack_no_ltn),\n",
    "    'total_investment_length': investment_length\n",
    "}\n",
    "\n",
    "# Non-destructive update\n",
    "analysis_results.update(length_stats)\n",
    "\n",
    "# Save updated results\n",
    "with open(analysis_res_pickle, 'wb') as f:\n",
    "    pickle.dump(analysis_results, f)\n",
    "\n",
    "# Update CSV\n",
    "pd.DataFrame({k: [v] for k,v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(\n",
    "    analysis_results['length_comparison_labels'], \n",
    "    analysis_results['length_comparison_values'],\n",
    "    color=analysis_results['length_comparison_colors']\n",
    ")\n",
    "plt.xlabel('Network Type')\n",
    "plt.ylabel('Total Length (meters)')\n",
    "plt.title('Lengths of Cycle Networks')\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/allLengths.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print statements\n",
    "print(f\"Total length of fully connected network: {length_stats['total_network_length']}\")\n",
    "print(f\"Total length of G_biketrack: {length_stats['total_biketrack_length']}\")\n",
    "print(f\"Total length of G_biketrack_no_ltn: {length_stats['total_biketrack_no_ltn_length']}\")\n",
    "print(f\"Difference in total length: {length_stats['length_difference']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute difference\n",
    "ltn_difference = abs(total_biketrack  - total_biketrack_no_ltn)\n",
    "\n",
    "# Data for plotting\n",
    "labels = [\n",
    "    \"Total Cycle Infrastructure\",\n",
    "    \"Protected Cycle Infrastructure\",\n",
    "    \"LTNs\"]\n",
    "values = [total_biketrack, total_biketrack_no_ltn, ltn_difference]\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, values, color=['deepskyblue', 'deepskyblue', 'deepskyblue'])\n",
    "plt.xlabel('Network Type')\n",
    "plt.ylabel('Total Length (meters)')\n",
    "plt.title('Total lengths of cycle networks ')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/TotalLengthsCycleNet.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pure length - how is the budget used per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_results = {}\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "\n",
    "\n",
    "# if rerun or 'total_lengths' not in analysis_results:\n",
    "#     # Perform analysis for GTs\n",
    "#     total_lengths = []\n",
    "#     for G in GTs:\n",
    "#         lengths = nx.get_edge_attributes(G, 'length')\n",
    "#         total_lengths.append(sum(lengths.values()))\n",
    "    \n",
    "#     # Perform analysis for GTs_random\n",
    "#     random_total_lengths = []\n",
    "#     for G in GTs_random:\n",
    "#         lengths = nx.get_edge_attributes(G, 'length')\n",
    "#         random_total_lengths.append(sum(lengths.values()))\n",
    "\n",
    "#     # Perform for demand\n",
    "#     demand_total_lengths = []\n",
    "#     for G in GTs_demand:\n",
    "#         lengths = nx.get_edge_attributes(G, 'length')\n",
    "#         demand_total_lengths.append(sum(lengths.values()))\n",
    "\n",
    "#     # Perform for demand LTN priority\n",
    "#     demand_total_lengths_ltn_priority = []\n",
    "#     for G in GTs_demand_ltn_priority:\n",
    "#         lengths = nx.get_edge_attributes(G, 'length')\n",
    "#         demand_total_lengths_ltn_priority.append(sum(lengths.values()))\n",
    "\n",
    "#     # Perform for betweenness LTN priority\n",
    "#     betweenness_total_lengths_ltn_priority = []\n",
    "#     for G in GTs_betweenness_ltn_priority:\n",
    "#         lengths = nx.get_edge_attributes(G, 'length')\n",
    "#         betweenness_total_lengths_ltn_priority.append(sum(lengths.values()))\n",
    "\n",
    "    \n",
    "#     # Update dictionary\n",
    "#     analysis_results.update({\n",
    "#         'total_lengths': total_lengths,\n",
    "#         'random_total_lengths': random_total_lengths,\n",
    "#         'demand_total_lengths': demand_total_lengths,\n",
    "#         'demand_total_lengths_ltn_priority': demand_total_lengths_ltn_priority,\n",
    "#         'betweenness_total_lengths_ltn_priority': betweenness_total_lengths_ltn_priority,\n",
    "#     })\n",
    "    \n",
    "#     # Save updated results\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "    \n",
    "#     # save to csv\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k,v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot the analysis results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(analysis_results['total_lengths'], linestyle='-', color='orange', label='Betweeness Growth')\n",
    "# plt.plot(analysis_results['random_total_lengths'], linestyle='--', color='blue', label='Random Growth')\n",
    "# plt.plot(analysis_results['demand_total_lengths'], linestyle='-.', color='red', label='Demand Growth')\n",
    "# plt.plot(analysis_results['demand_total_lengths_ltn_priority'], linestyle=':', color='green', label='Demand LTN Priority Growth')\n",
    "# plt.plot(analysis_results['betweenness_total_lengths_ltn_priority'], linestyle='-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.title('Length of Invested Cycle Network')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/loInvestment.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "if rerun or 'total_lengths' not in analysis_results:\n",
    "    analysis_results.update({\n",
    "        'total_lengths': compute_total_lengths(GTs),\n",
    "        'random_runs_total_lengths': [\n",
    "            compute_total_lengths(run[\"GTs\"]) for run in random_runs\n",
    "        ],\n",
    "        'random_total_lengths_mean': np.mean(\n",
    "            [compute_total_lengths(run[\"GTs\"]) for run in random_runs],\n",
    "            axis=0\n",
    "        ).tolist(),\n",
    "        'demand_total_lengths': compute_total_lengths(GTs_demand),\n",
    "        'demand_total_lengths_ltn_priority': compute_total_lengths(GTs_demand_ltn_priority),\n",
    "        'betweenness_total_lengths_ltn_priority': compute_total_lengths(GTs_betweenness_ltn_priority),\n",
    "    })\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for TL in analysis_results['random_runs_total_lengths']:\n",
    "    plt.plot(TL, color='lightgray', linewidth=1, alpha=0.5)\n",
    "plt.plot(analysis_results['random_total_lengths_mean'], linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "plt.plot(analysis_results['total_lengths'], '-', label='Betweenness Growth', color='orange')\n",
    "plt.plot(analysis_results['demand_total_lengths'], '-.', label='Demand Growth', color='red')\n",
    "plt.plot(analysis_results['demand_total_lengths_ltn_priority'], ':', label='Demand LTN Priority Growth', color='green')\n",
    "plt.plot(analysis_results['betweenness_total_lengths_ltn_priority'], '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Total Length (meters)')\n",
    "plt.title('Length of Invested Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"loInvestment.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Calculate % deviation from random baseline\n",
    "# if rerun or 'pct_deviation_from_random' not in analysis_results:\n",
    "#     def pct_deviation(series, baseline):\n",
    "#         \"\"\"Calculate % deviation from baseline\"\"\"\n",
    "#         return [(s - b) / b * 100 if b else 0 for s, b in zip(series, baseline)]\n",
    "#     pct_dev_data = {\n",
    "#         'pct_dev_betweenness': pct_deviation(\n",
    "#             analysis_results['total_lengths'],\n",
    "#             analysis_results['random_total_lengths']\n",
    "#         ),\n",
    "#         'pct_dev_demand': pct_deviation(\n",
    "#             analysis_results['demand_total_lengths'],\n",
    "#             analysis_results['random_total_lengths']\n",
    "#         ),\n",
    "#         'pct_dev_demand_ltn_priority': pct_deviation(\n",
    "#             analysis_results['demand_total_lengths_ltn_priority'],\n",
    "#             analysis_results['random_total_lengths']\n",
    "#         ),\n",
    "#         'pct_dev_betweenness_ltn_priority': pct_deviation(\n",
    "#             analysis_results['betweenness_total_lengths_ltn_priority'],\n",
    "#             analysis_results['random_total_lengths']\n",
    "#         ),\n",
    "#     }\n",
    "#     analysis_results['pct_deviation_from_random'] = pct_dev_data\n",
    "#     # Save \n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     # Flatten for CSV\n",
    "#     df_pct = pd.DataFrame({k: pd.Series(v) for k, v in pct_dev_data.items()})\n",
    "#     df_pct.to_csv(analysis_res_csv, mode='a', index=False)  # Append to same CSV\n",
    "\n",
    "# # --- Plot % deviation from random baseline ---\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plt.plot(\n",
    "#     analysis_results['pct_deviation_from_random']['pct_dev_betweenness'],\n",
    "#     linestyle='-', color='orange', label='Betweenness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['pct_deviation_from_random']['pct_dev_demand'],\n",
    "#     linestyle='-.', color='red', label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['pct_deviation_from_random']['pct_dev_demand_ltn_priority'],\n",
    "#     linestyle=':', color='green', label='Demand LTN Priority Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['pct_deviation_from_random']['pct_dev_betweenness_ltn_priority'],\n",
    "#     linestyle='-', color='purple', label='Betweenness LTN Priority Growth'\n",
    "# )\n",
    "# plt.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Deviation from Random (%)')\n",
    "# plt.title('Length of invested Network Compared to Random Growth (%)')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/pct_dev_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation from random baseline\n",
    "analysis_results = load_results(analysis_res_pickle)\n",
    "if rerun or 'abs_deviation_from_random' not in analysis_results:\n",
    "    # Calculate deviations for all random runs first\n",
    "    random_runs_deviations = [\n",
    "        np.array(run) - np.array(analysis_results['random_total_lengths_mean'])\n",
    "        for run in analysis_results['random_runs_total_lengths']]\n",
    "    # Calculate mean deviation of random runs\n",
    "    random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "    abs_dev_data = {\n",
    "        'abs_dev_betweenness': compute_abs_deviation(\n",
    "            analysis_results['total_lengths'],\n",
    "            analysis_results['random_total_lengths_mean']\n",
    "        ),\n",
    "        'abs_dev_demand': compute_abs_deviation(\n",
    "            analysis_results['demand_total_lengths'],\n",
    "            analysis_results['random_total_lengths_mean']\n",
    "        ),\n",
    "        'abs_dev_demand_ltn_priority': compute_abs_deviation(\n",
    "            analysis_results['demand_total_lengths_ltn_priority'],\n",
    "            analysis_results['random_total_lengths_mean']\n",
    "        ),\n",
    "        'abs_dev_betweenness_ltn_priority': compute_abs_deviation(\n",
    "            analysis_results['betweenness_total_lengths_ltn_priority'],\n",
    "            analysis_results['random_total_lengths_mean']\n",
    "        ),\n",
    "        'random_runs_deviations': random_runs_deviations,\n",
    "        'random_deviations_mean': random_deviations_mean\n",
    "    }\n",
    "    analysis_results.update(abs_dev_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot absolute deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot individual deviations of each random run\n",
    "for run in analysis_results['random_runs_total_lengths']:\n",
    "    deviation = np.array(run) - np.array(analysis_results['random_total_lengths_mean'])\n",
    "    plt.plot(deviation, color='lightgray', linewidth=1, alpha=0.4)\n",
    "# baseline = mean random\n",
    "plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "# Plot deviations from mean random growth for each strategy\n",
    "for key, style in [\n",
    "    ('abs_dev_betweenness', ('-', 'orange', 'Betweenness Growth')),\n",
    "    ('abs_dev_demand', ('-.', 'red', 'Demand Growth')),\n",
    "    ('abs_dev_demand_ltn_priority', (':', 'green', 'Demand LTN Priority Growth')),\n",
    "    ('abs_dev_betweenness_ltn_priority', ('-', 'purple', 'Betweenness LTN Priority Growth')),\n",
    "]:\n",
    "    plt.plot(\n",
    "        analysis_results['abs_deviation_from_random'][key],\n",
    "        linestyle=style[0], color=style[1], label=style[2]\n",
    "    )\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Deviation from Random Growth Baseline (meters)')\n",
    "plt.title('Deviation from Random Growth Baseline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"abs_dev_from_random.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Actual\" investment length - how much do we actually need to use to close gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate length, minus the existing infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for G in GTs:\n",
    "#     for u, v, data in G.edges(data=True):\n",
    "#         highway_type = data.get('highway', 'unclassified') # Default to unclassified if no highway attribute\n",
    "#         length = data.get('length', 0) # Default to 0 if no length attribute\n",
    "#         investment_length = length * distance_cost.get(highway_type, 1) \n",
    "#         data['investment_length'] = investment_length # make a new edge attribute called investment_length\n",
    "\n",
    "# if GTs_random:\n",
    "#     for G in GTs_random:\n",
    "#         for u, v, data in G.edges(data=True):\n",
    "#             highway_type = data.get('highway', 'unclassified')\n",
    "#             length = data.get('length', 0)\n",
    "#             investment_length = length * distance_cost.get(highway_type, 1)\n",
    "#             data['investment_length'] = investment_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find how much we actually need to invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total_investment_lengths = []\n",
    "# for G in GTs:\n",
    "#     lengths = nx.get_edge_attributes(G, 'investment_length')\n",
    "#     total_investment_length = sum(lengths.values())\n",
    "#     total_investment_lengths.append(total_investment_length)\n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.plot(total_investment_lengths, linestyle='-', color='orange', label='Betweeness Growth')\n",
    "\n",
    "# # Plot the total lengths for Random_GTs\n",
    "# random_total_investment_lengths = []\n",
    "# for G in GTs_random:\n",
    "#     lengths = nx.get_edge_attributes(G, 'investment_length')\n",
    "#     total_investment_length = sum(lengths.values())\n",
    "#     random_total_investment_lengths.append(total_investment_length)\n",
    "\n",
    "# plt.plot(random_total_lengths, linestyle='--', color='blue', label='Random Growth')\n",
    "\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.title('Length of Investment needed')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "if rerun or 'total_investment_lengths' not in analysis_results:\n",
    "    analysis_results.update({\n",
    "        'total_investment_lengths': compute_total_investment_lengths(GTs, distance_cost),\n",
    "        'random_runs_total_investment_lengths': [\n",
    "            compute_total_investment_lengths(run[\"GTs\"], distance_cost)\n",
    "            for run in random_runs\n",
    "        ],\n",
    "        'random_total_investment_lengths_mean': np.mean(\n",
    "            [compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs],\n",
    "            axis=0\n",
    "        ).tolist(),\n",
    "        'demand_total_investment_lengths': compute_total_investment_lengths(GTs_demand, distance_cost),\n",
    "        'demand_total_investment_lengths_ltn_priority': compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost),\n",
    "        'betweenness_total_investment_lengths_ltn_priority': compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost),\n",
    "    })\n",
    "\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "for run in analysis_results['random_runs_total_investment_lengths']:\n",
    "    plt.plot(run, color='lightgray', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.plot(\n",
    "    analysis_results['random_total_investment_lengths_mean'],\n",
    "    linestyle='--', linewidth=2, color='blue', label='Random Growth (mean)'\n",
    ")\n",
    "\n",
    "# Plot other strategies\n",
    "plt.plot(analysis_results['total_investment_lengths'], '-', color='orange', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['demand_total_investment_lengths'], '-.', color='red', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_total_investment_lengths_ltn_priority'], ':', color='green', label='Demand LTN Priority Growth')\n",
    "plt.plot(analysis_results['betweenness_total_investment_lengths_ltn_priority'], '-', color='purple', label='Betweenness LTN Priority Growth')\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Total Investment Cost (meters × weight)')\n",
    "plt.title('Total Investment Cost per Growth Strategy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"RequiredloInvestment.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate investment deviations from mean random baseline\n",
    "if rerun or 'abs_dev_investment_from_random' not in analysis_results:\n",
    "    random_investment_deviations = [\n",
    "        np.array(run) - np.array(analysis_results['random_total_investment_lengths_mean'])\n",
    "        for run in analysis_results['random_runs_total_investment_lengths']\n",
    "    ]\n",
    "\n",
    "    abs_dev_investment_data = {\n",
    "        'abs_dev_investment_betweenness': compute_abs_deviation(\n",
    "            analysis_results['total_investment_lengths'],\n",
    "            analysis_results['random_total_investment_lengths_mean']  \n",
    "        ),\n",
    "        'abs_dev_investment_demand': compute_abs_deviation(\n",
    "            analysis_results['demand_total_investment_lengths'], \n",
    "            analysis_results['random_total_investment_lengths_mean']\n",
    "        ),\n",
    "        'abs_dev_investment_demand_ltn_priority': compute_abs_deviation(\n",
    "            analysis_results['demand_total_investment_lengths_ltn_priority'],\n",
    "            analysis_results['random_total_investment_lengths_mean']\n",
    "        ),\n",
    "        'abs_dev_investment_betweenness_ltn_priority': compute_abs_deviation(\n",
    "            analysis_results['betweenness_total_investment_lengths_ltn_priority'],\n",
    "            analysis_results['random_total_investment_lengths_mean']\n",
    "        ),\n",
    "        'random_investment_deviations': random_investment_deviations,\n",
    "        'random_investment_deviations_mean': np.mean(random_investment_deviations, axis=0).tolist()\n",
    "    }\n",
    "    \n",
    "    analysis_results.update(abs_dev_investment_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "# --- Plot investment deviations ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot individual random run deviations in background\n",
    "for dev in analysis_results['random_investment_deviations']:\n",
    "    plt.plot(dev, color='lightgray', linewidth=1, alpha=0.3)\n",
    "\n",
    "# Plot zero baseline (mean random)\n",
    "plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Baseline')\n",
    "\n",
    "# Plot strategy deviations\n",
    "strategies = [\n",
    "    ('abs_dev_investment_betweenness', '-', 'orange', 'Betweenness'),\n",
    "    ('abs_dev_investment_demand', '-.', 'red', 'Demand'),\n",
    "    ('abs_dev_investment_demand_ltn_priority', ':', 'green', 'Demand+LTN'),\n",
    "    ('abs_dev_investment_betweenness_ltn_priority', '-', 'purple', 'Betweenness+LTN')\n",
    "]\n",
    "\n",
    "for key, style, color, label in strategies:\n",
    "    plt.plot(analysis_results[key], style, color=color, label=label)\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Deviation from Random (meters × weight)')\n",
    "plt.title('Investment Cost Deviation from Random Baseline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"abs_dev_investment_from_random.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find comparison between how much we need against full route lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute total lengths using 'investment_length'\n",
    "# investment_total_lengths = [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs]\n",
    "# random_investment_total_lengths = [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs_random]\n",
    "\n",
    "# # Compute total lengths using 'length'\n",
    "# length_total_lengths = [sum(nx.get_edge_attributes(G, 'length').values()) for G in GTs]\n",
    "# random_length_total_lengths = [sum(nx.get_edge_attributes(G, 'length').values()) for G in GTs_random]\n",
    "\n",
    "# # Plot both sets of lines\n",
    "# plt.figure(figsize=(6, 6))\n",
    "\n",
    "# # Original lines\n",
    "# plt.plot(investment_total_lengths, linestyle='-', color='orange', label='Betweenness Growth (Investment Length)')\n",
    "# plt.plot(random_investment_total_lengths, linestyle='--', color='blue', label='Random Growth (Investment Length)')\n",
    "\n",
    "# # Darker lines for 'length' attribute\n",
    "# plt.plot(length_total_lengths, linestyle='-', color='darkorange', alpha=0.7, label='Betweenness Growth (Total Length)')\n",
    "# plt.plot(random_length_total_lengths, linestyle='--', color='darkblue', alpha=0.7, label='Random Growth (Total Length)')\n",
    "\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.title('Network size vs investment required comparison')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_results = {}\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "\n",
    "# if rerun or 'length_total_lengths' not in analysis_results:\n",
    "#     if rerun or 'total_investment_lengths' not in analysis_results:\n",
    "    \n",
    "#         for G in GTs:\n",
    "#             for u, v, data in G.edges(data=True):\n",
    "#                 hwy = data.get('highway', 'unclassified')\n",
    "#                 data['investment_length'] = data.get('length', 0) * distance_cost.get(hwy, 1)\n",
    "     \n",
    "#         if GTs_random:\n",
    "#             for G in GTs_random:\n",
    "#                 for u, v, data in G.edges(data=True):\n",
    "#                     hwy = data.get('highway', 'unclassified')\n",
    "#                     data['investment_length'] = data.get('length', 0) * distance_cost.get(hwy, 1)\n",
    "   \n",
    "#         if GTs_demand:\n",
    "#             for G in GTs_demand:\n",
    "#                 for u, v, data in G.edges(data=True):\n",
    "#                     hwy = data.get('highway', 'unclassified')\n",
    "#                     data['investment_length'] = data.get('length', 0) * distance_cost.get(hwy, 1)\n",
    "        \n",
    "#         if GTs_demand_ltn_priority:\n",
    "#             for G in GTs_demand_ltn_priority:\n",
    "#                 for u, v, data in G.edges(data=True):\n",
    "#                     hwy = data.get('highway', 'unclassified')\n",
    "#                     data['investment_length'] = data.get('length', 0) * distance_cost.get(hwy, 1)\n",
    "        \n",
    "#         if GTs_betweenness_ltn_priority:\n",
    "#             for G in GTs_betweenness_ltn_priority:\n",
    "#                 for u, v, data in G.edges(data=True):\n",
    "#                     hwy = data.get('highway', 'unclassified')\n",
    "#                     data['investment_length'] = data.get('length', 0) * distance_cost.get(hwy, 1)\n",
    "\n",
    "\n",
    "#     metrics = {\n",
    "#         'investment_total_lengths':        [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs],\n",
    "#         'random_investment_total_lengths': [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs_random],\n",
    "#         'demand_investment_total_lengths': [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs_demand],\n",
    "#         'length_total_lengths':            [sum(nx.get_edge_attributes(G, 'length').values())            for G in GTs],\n",
    "#         'random_length_total_lengths':     [sum(nx.get_edge_attributes(G, 'length').values())            for G in GTs_random],\n",
    "#         'demand_length_total_lengths':     [sum(nx.get_edge_attributes(G, 'length').values())            for G in GTs_demand],\n",
    "#         'demand_length_total_lengths_ltn_priority': [sum(nx.get_edge_attributes(G, 'length').values()) for G in GTs_demand_ltn_priority],\n",
    "#         'betweenness_length_total_lengths_ltn_priority': [sum(nx.get_edge_attributes(G, 'length').values()) for G in GTs_betweenness_ltn_priority]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(metrics)\n",
    "    \n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot comparison\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(analysis_results['investment_total_lengths'],        '-',  color='orange',    label='Betweenness (Invest)')\n",
    "# plt.plot(analysis_results['random_investment_total_lengths'], '--', color='blue',     label='Random (Invest)')\n",
    "# plt.plot(analysis_results['demand_investment_total_lengths'], '-.', color='red',      label='Demand (Invest)')\n",
    "# plt.plot(analysis_results['length_total_lengths'],            '-',  color='darkorange', alpha=0.7, label='Betweenness (Length)')\n",
    "# plt.plot(analysis_results['random_length_total_lengths'],     '--', color='darkblue',   alpha=0.7, label='Random (Length)')\n",
    "# plt.plot(analysis_results['demand_length_total_lengths'],     '-.', color='darkred',    alpha=0.7, label='Demand (Length)')\n",
    "# plt.plot(analysis_results['demand_length_total_lengths_ltn_priority'], '-.', color='green', label='Demand LTN (Length)')\n",
    "# plt.plot(analysis_results['betweenness_length_total_lengths_ltn_priority'], '-', color='purple', label='Betweenness LTN (Length)')\n",
    "\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.title('Network size vs Investment required comparison')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/Required_vs_networksize_loInvestment.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find differance between network size and required investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize analysis results\n",
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "if rerun or 'length_differences' not in analysis_results:\n",
    "    # Compute differences\n",
    "    length_diff_data = {\n",
    "        'length_differences': compute_length_difference(GTs),\n",
    "        'random_runs_length_differences': [\n",
    "            compute_length_difference(run[\"GTs\"]) for run in random_runs\n",
    "        ],\n",
    "        'demand_length_differences': compute_length_difference(GTs_demand),\n",
    "        'demand_length_differences_ltn_priority': compute_length_difference(GTs_demand_ltn_priority),\n",
    "        'betweenness_length_differences_ltn_priority': compute_length_difference(GTs_betweenness_ltn_priority)}\n",
    "    # Compute mean random length difference\n",
    "    length_diff_data['random_length_differences_mean'] = np.mean(\n",
    "        length_diff_data['random_runs_length_differences'], axis=0\n",
    "    ).tolist()\n",
    "    analysis_results.update(length_diff_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each individual random run\n",
    "for run_diff in analysis_results['random_runs_length_differences']:\n",
    "    plt.plot(run_diff, color='lightgray', linewidth=1, alpha=0.4)\n",
    "\n",
    "# Plot mean of randoms\n",
    "plt.plot(\n",
    "    analysis_results['random_length_differences_mean'],\n",
    "    linestyle='--', color='blue', linewidth=2, label='Random Growth (mean)'\n",
    ")\n",
    "\n",
    "# Plot other strategies\n",
    "plt.plot(analysis_results['length_differences'], '-', color='orange', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['demand_length_differences'], '-.', color='red', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_length_differences_ltn_priority'], ':', color='green', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_length_differences_ltn_priority'], '-', color='purple', label='Betweenness LTN Growth')\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Length Difference (meters)')\n",
    "plt.title('Difference Between Total Network Size and Investment Size Required')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"loInvestment_diff.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute deviation from mean random baseline for length differences ---\n",
    "if rerun or 'deviation_from_random__length_differences' not in analysis_results:\n",
    "    baseline = np.array(analysis_results['random_length_differences_mean'])\n",
    "\n",
    "    deviation_data = {\n",
    "        'deviation_from_random__length_differences':\n",
    "            (np.array(analysis_results['length_differences']) - baseline).tolist(),\n",
    "        'deviation_from_random__demand_length_differences':\n",
    "            (np.array(analysis_results['demand_length_differences']) - baseline).tolist(),\n",
    "        'deviation_from_random__demand_length_differences_ltn_priority':\n",
    "            (np.array(analysis_results['demand_length_differences_ltn_priority']) - baseline).tolist(),\n",
    "        'deviation_from_random__betweenness_length_differences_ltn_priority':\n",
    "            (np.array(analysis_results['betweenness_length_differences_ltn_priority']) - baseline).tolist(),\n",
    "    }\n",
    "\n",
    "    analysis_results.update(deviation_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for run in analysis_results['random_runs_length_differences']:\n",
    "    deviation = np.array(run) - np.array(analysis_results['random_length_differences_mean'])\n",
    "    plt.plot(deviation, color='lightgray', linewidth=1, alpha=0.4)\n",
    "plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "plt.plot(\n",
    "    analysis_results['deviation_from_random__length_differences'],\n",
    "    '-', color='orange', label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['deviation_from_random__demand_length_differences'],\n",
    "    '-.', color='red', label='Demand Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['deviation_from_random__demand_length_differences_ltn_priority'],\n",
    "    ':', color='green', label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['deviation_from_random__betweenness_length_differences_ltn_priority'],\n",
    "    '-', color='purple', label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Deviation from Random (meters)')\n",
    "plt.title('Deviation from Random Growth Strategy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"loInvestment_deviation_from_random.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths_list = []\n",
    "# investment_lengths_list = []\n",
    "\n",
    "# random_lengths_list = []\n",
    "# random_investment_lengths_list = []\n",
    "\n",
    "# # Process GTs\n",
    "# for G in GTs:\n",
    "#     lengths = nx.get_edge_attributes(G, 'length')\n",
    "#     investment_lengths = nx.get_edge_attributes(G, 'investment_length')\n",
    "    \n",
    "#     total_length = sum(lengths.values())\n",
    "#     total_investment_length = sum(investment_lengths.values())\n",
    "    \n",
    "#     lengths_list.append(total_length)\n",
    "#     investment_lengths_list.append(total_investment_length)\n",
    "\n",
    "# # Process GTs_random\n",
    "# for G in GTs_random:\n",
    "#     lengths = nx.get_edge_attributes(G, 'length')\n",
    "#     investment_lengths = nx.get_edge_attributes(G, 'investment_length')\n",
    "    \n",
    "#     total_length = sum(lengths.values())\n",
    "#     total_investment_length = sum(investment_lengths.values())\n",
    "    \n",
    "#     random_lengths_list.append(total_length)\n",
    "#     random_investment_lengths_list.append(total_investment_length)\n",
    "\n",
    "# # Plot the lengths against investment lengths\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(lengths_list, investment_lengths_list, '-', color='purple', label='Betweenness Growth')\n",
    "# plt.plot(random_lengths_list, random_investment_lengths_list, '--', color='blue', label='Random Growth')\n",
    "# plt.xlabel('Total Length (meters)')\n",
    "# plt.ylabel('Total Investment Length (meters)')\n",
    "# plt.title('Investment Length vs. Length for GTs and GTs_random')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "if rerun or 'lengths_vs_investment' not in analysis_results:\n",
    "    metrics = {\n",
    "        'lengths_list': compute_total_lengths(GTs),\n",
    "        'investment_lengths_list': compute_total_investment_lengths(GTs, distance_cost),\n",
    "\n",
    "        'random_runs_lengths_list': [\n",
    "            compute_total_lengths(run[\"GTs\"]) for run in random_runs\n",
    "        ],\n",
    "        'random_runs_investment_lengths_list': [\n",
    "            compute_total_investment_lengths(run[\"GTs\"], distance_cost) for run in random_runs\n",
    "        ],\n",
    "\n",
    "        'demand_lengths_list': compute_total_lengths(GTs_demand),\n",
    "        'demand_investment_lengths_list': compute_total_investment_lengths(GTs_demand, distance_cost),\n",
    "\n",
    "        'demand_lengths_list_ltn_priority': compute_total_lengths(GTs_demand_ltn_priority),\n",
    "        'demand_investment_lengths_list_ltn_priority': compute_total_investment_lengths(GTs_demand_ltn_priority, distance_cost),\n",
    "\n",
    "        'betweenness_lengths_list_ltn_priority': compute_total_lengths(GTs_betweenness_ltn_priority),\n",
    "        'betweenness_investment_lengths_list_ltn_priority': compute_total_investment_lengths(GTs_betweenness_ltn_priority, distance_cost),\n",
    "    }\n",
    "\n",
    "    metrics['random_lengths_list_mean'] = np.mean(metrics['random_runs_lengths_list'], axis=0).tolist()\n",
    "    metrics['random_investment_lengths_list_mean'] = np.mean(metrics['random_runs_investment_lengths_list'], axis=0).tolist()\n",
    "\n",
    "    analysis_results.update(metrics)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for x, y in zip(analysis_results['random_runs_lengths_list'], analysis_results['random_runs_investment_lengths_list']):\n",
    "    plt.plot(x, y, color='lightgray', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.plot(\n",
    "    analysis_results['random_lengths_list_mean'],\n",
    "    analysis_results['random_investment_lengths_list_mean'],\n",
    "    '--', color='blue', linewidth=2, label='Random Growth (mean)'\n",
    ")\n",
    "\n",
    "plt.plot(analysis_results['lengths_list'], analysis_results['investment_lengths_list'], '-', color='orange', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['demand_lengths_list'], analysis_results['demand_investment_lengths_list'], '-.', color='red', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_lengths_list_ltn_priority'], analysis_results['demand_investment_lengths_list_ltn_priority'], '-.', color='green', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_lengths_list_ltn_priority'], analysis_results['betweenness_investment_lengths_list_ltn_priority'], '-', color='purple', label='Betweenness LTN Growth')\n",
    "\n",
    "plt.xlabel('Total Length (meters)')\n",
    "plt.ylabel('Total Investment Length (meters)')\n",
    "plt.title('Investment Cost vs Physical Network Length')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"loInvestmentcost_vs_length.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## against random baseline \n",
    "\n",
    "# analysis_results = {}\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "\n",
    "# # Compute and cache values if needed\n",
    "# if rerun or 'lengths_vs_investment' not in analysis_results:\n",
    "#     metrics = {\n",
    "#         'lengths_list':                   [sum(nx.get_edge_attributes(G, 'length').values())             for G in GTs],\n",
    "#         'investment_lengths_list':        [sum(nx.get_edge_attributes(G, 'investment_length').values())  for G in GTs],\n",
    "#         'random_lengths_list':            [sum(nx.get_edge_attributes(G, 'length').values())             for G in GTs_random],\n",
    "#         'random_investment_lengths_list': [sum(nx.get_edge_attributes(G, 'investment_length').values())  for G in GTs_random],\n",
    "#         'demand_lengths_list':            [sum(nx.get_edge_attributes(G, 'length').values())             for G in GTs_demand],\n",
    "#         'demand_investment_lengths_list': [sum(nx.get_edge_attributes(G, 'investment_length').values())  for G in GTs_demand],\n",
    "#         'demand_lengths_list_ltn_priority': [sum(nx.get_edge_attributes(G, 'length').values())           for G in GTs_demand_ltn_priority],\n",
    "#         'demand_investment_lengths_list_ltn_priority': [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs_demand_ltn_priority],\n",
    "#         'betweenness_length_total_lengths_ltn_priority': [sum(nx.get_edge_attributes(G, 'length').values()) for G in GTs_betweenness_ltn_priority],\n",
    "#         'betweenness_total_investment_lengths_ltn_priority': [sum(nx.get_edge_attributes(G, 'investment_length').values()) for G in GTs_betweenness_ltn_priority]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(metrics)\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # --- Compute Deviations from Random Strategy ---\n",
    "\n",
    "# random_lengths = np.array(analysis_results['random_lengths_list'])\n",
    "# random_investments = np.array(analysis_results['random_investment_lengths_list'])\n",
    "\n",
    "# # Define strategies and their colors/styles\n",
    "# strategies = {\n",
    "#     'Betweenness Growth': {\n",
    "#         'lengths': np.array(analysis_results['lengths_list']),\n",
    "#         'investments': np.array(analysis_results['investment_lengths_list']),\n",
    "#         'color': 'orange', 'style': '-'\n",
    "#     },\n",
    "#     'Demand Growth': {\n",
    "#         'lengths': np.array(analysis_results['demand_lengths_list']),\n",
    "#         'investments': np.array(analysis_results['demand_investment_lengths_list']),\n",
    "#         'color': 'red', 'style': '-.'\n",
    "#     },\n",
    "#     'Demand LTN Growth': {\n",
    "#         'lengths': np.array(analysis_results['demand_lengths_list_ltn_priority']),\n",
    "#         'investments': np.array(analysis_results['demand_investment_lengths_list_ltn_priority']),\n",
    "#         'color': 'green', 'style': '-.'\n",
    "#     },\n",
    "#     'Betweenness LTN Growth': {\n",
    "#         'lengths': np.array(analysis_results['betweenness_length_total_lengths_ltn_priority']),\n",
    "#         'investments': np.array(analysis_results['betweenness_total_investment_lengths_ltn_priority']),\n",
    "#         'color': 'purple', 'style': '-'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Compute and save deviations from random\n",
    "# for label, data in strategies.items():\n",
    "#     deviation_lengths = data['lengths'] - random_lengths\n",
    "#     deviation_investments = data['investments'] - random_investments\n",
    "#     analysis_results[f'deviation_from_random__{label.lower().replace(\" \", \"_\")}_lengths'] = deviation_lengths.tolist()\n",
    "#     analysis_results[f'deviation_from_random__{label.lower().replace(\" \", \"_\")}_investments'] = deviation_investments.tolist()\n",
    "\n",
    "# # Save updated analysis results\n",
    "# with open(analysis_res_pickle, 'wb') as f:\n",
    "#     pickle.dump(analysis_results, f)\n",
    "# df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "# df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # --- Plot Deviations from Random Strategy ---\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label, data in strategies.items():\n",
    "#     x_dev = data['lengths'] - random_lengths\n",
    "#     y_dev = data['investments'] - random_investments\n",
    "#     plt.plot(x_dev, y_dev, data['style'], color=data['color'], label=label)\n",
    "\n",
    "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.xlabel('Deviation in Total Length (meters) from Random')\n",
    "# plt.ylabel('Deviation in Investment Length (meters) from Random')\n",
    "# plt.title('Deviation from Random: Investment vs Physical Length')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/loInvestmentcost_vs_length__deviation_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "# Use mean random runs as baseline (better statistical baseline)\n",
    "random_lengths_mean = np.array(analysis_results['random_lengths_list_mean'])\n",
    "random_investments_mean = np.array(analysis_results['random_investment_lengths_list_mean'])\n",
    "\n",
    "# Define strategies with proper keys (fix those typos)\n",
    "strategies = {\n",
    "    'Betweenness Growth': {\n",
    "        'lengths': np.array(analysis_results['lengths_list']),\n",
    "        'investments': np.array(analysis_results['investment_lengths_list']),\n",
    "        'color': 'orange', 'marker': 'o'\n",
    "    },\n",
    "    'Demand Growth': {\n",
    "        'lengths': np.array(analysis_results['demand_lengths_list']),\n",
    "        'investments': np.array(analysis_results['demand_investment_lengths_list']),\n",
    "        'color': 'red', 'marker': 's'\n",
    "    },\n",
    "    'Demand LTN Growth': {\n",
    "        'lengths': np.array(analysis_results['demand_lengths_list_ltn_priority']),\n",
    "        'investments': np.array(analysis_results['demand_investment_lengths_list_ltn_priority']),\n",
    "        'color': 'green', 'marker': '^'\n",
    "    },\n",
    "    'Betweenness LTN Growth': {\n",
    "        'lengths': np.array(analysis_results['betweenness_lengths_list_ltn_priority']),\n",
    "        'investments': np.array(analysis_results['betweenness_investment_lengths_list_ltn_priority']),\n",
    "        'color': 'purple', 'marker': 'D'\n",
    "    }\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(analysis_results['random_runs_lengths_list'])):\n",
    "    plt.scatter(\n",
    "        np.array(analysis_results['random_runs_lengths_list'][i]) - random_lengths_mean,\n",
    "        np.array(analysis_results['random_runs_investment_lengths_list'][i]) - random_investments_mean,\n",
    "        color='lightgray', alpha=0.3, s=10, label='_nolegend_'\n",
    "    )\n",
    "\n",
    "# Plot strategy deviations from random mean baseline\n",
    "for label, data in strategies.items():\n",
    "    x_dev = data['lengths'] - random_lengths_mean\n",
    "    y_dev = data['investments'] - random_investments_mean\n",
    "    plt.scatter(x_dev, y_dev, label=label, color=data['color'], marker=data['marker'], alpha=0.8, s=50)\n",
    "\n",
    "# Reference lines at zero deviation\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Deviation in Total Length (m) from Random Growth (mean)')\n",
    "plt.ylabel('Deviation in Investment Length (m) from Random Growth (mean)')\n",
    "plt.title('Investment Cost vs Length of Network: Deviation from Random Growth')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"loInvestmentcost_vs_length__deviation_from_random_scatter.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance gained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to find how much of the existing network is connected per iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total bike network - G_bikeall\n",
    "\n",
    "G'investment_length' - investment size\n",
    "\n",
    "G'length' - length of created network, not including netowrk size\n",
    "\n",
    "need to do a compose of G_bikeall and G in GTs\n",
    "\n",
    "but only compose where infrastucutre is connected to our generated network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of infrastructure connected to generated network, along with the combined length. Thus we now know how much extra cycle network is connected per level of investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "if rerun or 'biketrack_lengths' not in analysis_results:\n",
    "    analysis_results.update({\n",
    "        'GT_lengths': compute_biketrack_connected_lengths(GTs, G_biketrack)[0],\n",
    "        'biketrack_lengths': compute_biketrack_connected_lengths(GTs, G_biketrack)[1],\n",
    "        'combined_lengths': compute_biketrack_connected_lengths(GTs, G_biketrack)[2],\n",
    "\n",
    "        'random_runs_GT_lengths': [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[0] for run in random_runs],\n",
    "        'random_runs_biketrack_lengths': [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[1] for run in random_runs],\n",
    "        'random_runs_combined_lengths': [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[2] for run in random_runs],\n",
    "\n",
    "        'GT_random_lengths': np.mean(\n",
    "            [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[0] for run in random_runs],\n",
    "            axis=0\n",
    "        ).tolist(),\n",
    "        'biketrack_random_lengths': np.mean(\n",
    "            [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[1] for run in random_runs],\n",
    "            axis=0\n",
    "        ).tolist(),\n",
    "        'combined_random_lengths': np.mean(\n",
    "            [compute_biketrack_connected_lengths(run[\"GTs\"], G_biketrack)[2] for run in random_runs],\n",
    "            axis=0\n",
    "        ).tolist(),\n",
    "\n",
    "        'GT_demand_lengths': compute_biketrack_connected_lengths(GTs_demand, G_biketrack)[0],\n",
    "        'biketrack_demand_lengths': compute_biketrack_connected_lengths(GTs_demand, G_biketrack)[1],\n",
    "        'combined_demand_lengths': compute_biketrack_connected_lengths(GTs_demand, G_biketrack)[2],\n",
    "\n",
    "        'GT_demand_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_demand_ltn_priority, G_biketrack)[0],\n",
    "        'biketrack_demand_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_demand_ltn_priority, G_biketrack)[1],\n",
    "        'combined_demand_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_demand_ltn_priority, G_biketrack)[2],\n",
    "\n",
    "        'GT_betweenness_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_betweenness_ltn_priority, G_biketrack)[0],\n",
    "        'biketrack_betweenness_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_betweenness_ltn_priority, G_biketrack)[1],\n",
    "        'combined_betweenness_lengths_ltn_priority': compute_biketrack_connected_lengths(GTs_betweenness_ltn_priority, G_biketrack)[2],\n",
    "    })\n",
    "\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot individual random runs\n",
    "for run_lengths in analysis_results['random_runs_biketrack_lengths']:\n",
    "    plt.plot(run_lengths, color='lightgray', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Plot mean of random runs\n",
    "plt.plot(analysis_results['biketrack_random_lengths'], '--', color='blue', linewidth=2, label=\"Random Growth (mean)\")\n",
    "\n",
    "# Other strategies\n",
    "plt.plot(analysis_results['biketrack_lengths'], '-', color='orange', label=\"Betweenness\")\n",
    "plt.plot(analysis_results['biketrack_demand_lengths'], '-.', color='red', label=\"Demand\")\n",
    "plt.plot(analysis_results['biketrack_demand_lengths_ltn_priority'], ':', color='green', label=\"Demand LTN Priority\")\n",
    "plt.plot(analysis_results['biketrack_betweenness_lengths_ltn_priority'], '-', color='purple', label=\"Betweenness LTN Priority\")\n",
    "\n",
    "plt.xlabel(\"Investment Iteration\")\n",
    "plt.ylabel(\"Additional Cycle Infrastructure Connected Length (meters)\")\n",
    "plt.title(\"Additional Cycle Infrastructure Connected per Iteration\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"additional_cyclenet_connected.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "if rerun or 'biketrack_deviation_from_random' not in analysis_results:\n",
    "\n",
    "    random_runs = analysis_results['random_runs_biketrack_lengths']\n",
    "    random_mean = np.mean(random_runs, axis=0)\n",
    "\n",
    "    # Deviation of each random run from mean\n",
    "    random_runs_deviations = [np.array(run) - random_mean for run in random_runs]\n",
    "    random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "\n",
    "    biketrack_dev_data = {\n",
    "        'dev_betweenness': compute_abs_deviation(\n",
    "            analysis_results['biketrack_lengths'], random_mean\n",
    "        ),\n",
    "        'dev_demand': compute_abs_deviation(\n",
    "            analysis_results['biketrack_demand_lengths'], random_mean\n",
    "        ),\n",
    "        'dev_demand_ltn': compute_abs_deviation(\n",
    "            analysis_results['biketrack_demand_lengths_ltn_priority'], random_mean\n",
    "        ),\n",
    "        'dev_betweenness_ltn': compute_abs_deviation(\n",
    "            analysis_results['biketrack_betweenness_lengths_ltn_priority'], random_mean\n",
    "        ),\n",
    "        'random_runs_deviations': [d.tolist() for d in random_runs_deviations],\n",
    "        'random_deviations_mean': random_deviations_mean\n",
    "    }\n",
    "\n",
    "    analysis_results['biketrack_deviation_from_random'] = biketrack_dev_data\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "\n",
    "# Plot deviation from random for biketrack-connected lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "for dev in analysis_results['biketrack_deviation_from_random']['random_runs_deviations']:\n",
    "    plt.plot(dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "for key, style in [\n",
    "    ('dev_betweenness', ('-', 'orange', 'Betweenness Growth')),\n",
    "    ('dev_demand', ('-.', 'red', 'Demand Growth')),\n",
    "    ('dev_demand_ltn', (':', 'green', 'Demand LTN Priority Growth')),\n",
    "    ('dev_betweenness_ltn', ('-', 'purple', 'Betweenness LTN Priority Growth')),\n",
    "]:\n",
    "    plt.plot(\n",
    "        analysis_results['biketrack_deviation_from_random'][key],\n",
    "        linestyle=style[0], color=style[1], label=style[2]\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Investment Iteration\")\n",
    "plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "plt.title(\"Deviation in Connected Biketrack Length from Random Growth Baseline\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"biketrack_connected__deviation_from_random.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deviation from Random: Biketrack connected lengths\n",
    "# random_baseline = np.array(analysis_results['biketrack_random_lengths'])\n",
    "\n",
    "# # Prepare deviations from random for each strategy\n",
    "# deviations = {\n",
    "#     'Betweenness': {\n",
    "#         'values': np.array(analysis_results['biketrack_lengths']) - random_baseline,\n",
    "#         'color': 'orange',\n",
    "#         'linestyle': '--'\n",
    "#     },\n",
    "#     'Demand': {\n",
    "#         'values': np.array(analysis_results['biketrack_demand_lengths']) - random_baseline,\n",
    "#         'color': 'red',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Demand LTN': {\n",
    "#         'values': np.array(analysis_results['biketrack_demand_lengths_ltn_priority']) - random_baseline,\n",
    "#         'color': 'green',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Betweenness LTN': {\n",
    "#         'values': np.array(analysis_results['biketrack_betweenness_lengths_ltn_priority']) - random_baseline,\n",
    "#         'color': 'purple',\n",
    "#         'linestyle': '-'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label, data in deviations.items():\n",
    "#     plt.plot(\n",
    "#         range(1, len(data['values']) + 1),\n",
    "#         data['values'],\n",
    "#         linestyle=data['linestyle'],\n",
    "#         color=data['color'],\n",
    "#         label=label\n",
    "#     )\n",
    "\n",
    "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"Deviation in Connected Length vs Random (meters)\")\n",
    "# plt.title(\"Additional Cycle Infrastructure Connected — Deviation from Random Growth (Baseline)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/additional_cyclenet_connected__deviation_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of the largest connected component, first a just our investment, then combined with existing network, then by combined but only where its connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this computes LCC in the \"typical\" way by measuring componet size by number of nodes\n",
    "\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'lcc_lengths_GTs' not in analysis_results:\n",
    "#     # Compute LCC lengths\n",
    "#     lcc_data = {\n",
    "#         'lcc_lengths_GTs': [\n",
    "#             sum(data['length'] for _, _, data in \n",
    "#                 G.subgraph(max(nx.weakly_connected_components(G), key=len)).edges(data=True))\n",
    "#             for G in GTs\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_random': [\n",
    "#             sum(data['length'] for _, _, data in \n",
    "#                 G.subgraph(max(nx.weakly_connected_components(G), key=len)).edges(data=True))\n",
    "#             for G in GTs_random\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_demand': [\n",
    "#             sum(data['length'] for _, _, data in \n",
    "#                 G.subgraph(max(nx.weakly_connected_components(G), key=len)).edges(data=True))\n",
    "#             for G in GTs_demand\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_demand_ltn_priority': [\n",
    "#             sum(data['length'] for _, _, data in \n",
    "#                 G.subgraph(max(nx.weakly_connected_components(G), key=len)).edges(data=True))\n",
    "#             for G in GTs_demand_ltn_priority\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_betweenness_ltn_priority': [\n",
    "#             sum(data['length'] for _, _, data in \n",
    "#                 G.subgraph(max(nx.weakly_connected_components(G), key=len)).edges(data=True))\n",
    "#             for G in GTs_betweenness_ltn_priority\n",
    "#         ]\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(lcc_data)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k,v in analysis_results.items()}) \\\n",
    "#       .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot LCC lengths\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs'], \n",
    "#     '--', color='orange', label='Betweeness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_random'], \n",
    "#     '-', color='blue', label='Random Growth'\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_demand'],\n",
    "#     '-.', color='red', label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_demand_ltn_priority'],\n",
    "#     '-.', color='green', label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_betweenness_ltn_priority'],\n",
    "#     '-', color='purple', label='Betweenness LTN Growth'\n",
    "# )\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Length (meters)')\n",
    "# plt.title('Size of Largest Connected Component per Iteration')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/size_of_lcc.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun or 'lcc_lengths' not in analysis_results:\n",
    "    lcc_data = {\n",
    "        'lcc_lengths': [get_longest_connected_components(G) for G in GTs],\n",
    "        'random_runs_lcc_lengths': [\n",
    "            [get_longest_connected_components(G) for G in run[\"GTs\"]] for run in random_runs\n",
    "        ],\n",
    "        'demand_lcc_lengths': [get_longest_connected_components(G) for G in GTs_demand],\n",
    "        'demand_lcc_lengths_ltn_priority': [get_longest_connected_components(G) for G in GTs_demand_ltn_priority],\n",
    "        'betweenness_lcc_lengths_ltn_priority': [get_longest_connected_components(G) for G in GTs_betweenness_ltn_priority]\n",
    "    }\n",
    "\n",
    "    # Compute mean random lcc lengths across runs and graphs\n",
    "    lcc_data['random_lcc_lengths_mean'] = np.mean(\n",
    "    lcc_data['random_runs_lcc_lengths'], axis=0\n",
    "    ).tolist()\n",
    "\n",
    "    analysis_results.update(lcc_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for run in analysis_results['random_runs_lcc_lengths']:\n",
    "    plt.plot(run, color='lightgray', linewidth=1, alpha=0.4)\n",
    "\n",
    "plt.plot(analysis_results['random_lcc_lengths_mean'], linestyle='--', linewidth=2, label='Random Growth (mean)', color='blue')\n",
    "plt.plot(analysis_results['lcc_lengths'], '-', label='Betweenness Growth', color='orange')\n",
    "plt.plot(analysis_results['demand_lcc_lengths'], '-.', label='Demand Growth', color='red')\n",
    "plt.plot(analysis_results['demand_lcc_lengths_ltn_priority'], ':', label='Demand LTN Priority Growth', color='green')\n",
    "plt.plot(analysis_results['betweenness_lcc_lengths_ltn_priority'], '-', label='Betweenness LTN Priority Growth', color='purple')\n",
    "\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('LCC Length (meters)')\n",
    "plt.title('Size of Largest Connected Component per Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"size_of_lcc.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## largest connected component is calculated as longest (length of edges) connected component\n",
    "# # this is because we are interested in how far a cyclist can travel, rather than the numeber of nodes\n",
    "\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'lcc_lengths_GTs' not in analysis_results:\n",
    "#     # Compute LCC lengths\n",
    "#         lcc_data = {\n",
    "#             'lcc_lengths_GTs': [\n",
    "#                 get_longest_connected_components(G) for G in GTs\n",
    "#             ],\n",
    "#             'lcc_lengths_GTs_random': [\n",
    "#                 get_longest_connected_components(G) for G in GTs_random\n",
    "#             ],\n",
    "#             'lcc_lengths_GTs_demand': [\n",
    "#                 get_longest_connected_components(G) for G in GTs_demand\n",
    "#             ],\n",
    "#             'lcc_lengths_GTs_demand_ltn_priority': [\n",
    "#                 get_longest_connected_components(G) for G in GTs_demand_ltn_priority\n",
    "#             ],\n",
    "#             'lcc_lengths_GTs_betweenness_ltn_priority': [\n",
    "#                 get_longest_connected_components(G) for G in GTs_betweenness_ltn_priority\n",
    "#             ]\n",
    "#         }\n",
    "\n",
    "\n",
    "# analysis_results.update(lcc_data)\n",
    "\n",
    "# with open(analysis_res_pickle, 'wb') as f:\n",
    "#     pickle.dump(analysis_results, f)\n",
    "# pd.DataFrame({k: pd.Series(v) for k,v in analysis_results.items()}) \\\n",
    "#     .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot LCC lengths\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs'], \n",
    "#     '--', color='orange', label='Betweeness Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_random'], \n",
    "#     '-', color='blue', label='Random Growth'\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_demand'],\n",
    "#     '-.', color='red', label='Demand Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_demand_ltn_priority'],\n",
    "#     '-.', color='green', label='Demand LTN Growth'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['lcc_lengths_GTs_betweenness_ltn_priority'],\n",
    "#     '-', color='purple', label='Betweenness LTN Growth'\n",
    "# )\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Length (meters)')\n",
    "# plt.title('Size of Largest Connected Component per Iteration')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/size_of_lcc.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "if rerun or 'lcc_deviation_from_random' not in analysis_results:\n",
    "    random_runs = analysis_results['random_runs_lcc_lengths']\n",
    "    random_mean = np.array(analysis_results['random_lcc_lengths_mean'])\n",
    "\n",
    "    # Deviation of each random run from the mean\n",
    "    random_runs_deviations = [np.array(run) - random_mean for run in random_runs]\n",
    "    random_deviations_mean = np.mean(random_runs_deviations, axis=0).tolist()\n",
    "\n",
    "    lcc_dev_data = {\n",
    "        'dev_betweenness': np.array(analysis_results['lcc_lengths']) - random_mean,\n",
    "        'dev_demand': np.array(analysis_results['demand_lcc_lengths']) - random_mean,\n",
    "        'dev_demand_ltn': np.array(analysis_results['demand_lcc_lengths_ltn_priority']) - random_mean,\n",
    "        'dev_betweenness_ltn': np.array(analysis_results['betweenness_lcc_lengths_ltn_priority']) - random_mean,\n",
    "        'random_runs_deviations': [d.tolist() for d in random_runs_deviations],\n",
    "        'random_deviations_mean': random_deviations_mean\n",
    "    }\n",
    "\n",
    "    analysis_results['lcc_deviation_from_random'] = lcc_dev_data\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gray lines: deviation of each random run from the mean\n",
    "for dev in analysis_results['lcc_deviation_from_random']['random_runs_deviations']:\n",
    "    plt.plot(dev, color='lightgray', linewidth=1, alpha=0.4)\n",
    "\n",
    "# Dashed blue line at 0 deviation\n",
    "plt.axhline(0, color='blue', linestyle='--', linewidth=2, label='Random Growth (mean)')\n",
    "\n",
    "# Plot deviations for each strategy\n",
    "for key, style in [\n",
    "    ('dev_betweenness', ('-', 'orange', 'Betweenness Growth')),\n",
    "    ('dev_demand', ('-.', 'red', 'Demand Growth')),\n",
    "    ('dev_demand_ltn', (':', 'green', 'Demand LTN Priority Growth')),\n",
    "    ('dev_betweenness_ltn', ('-', 'purple', 'Betweenness LTN Priority Growth')),\n",
    "]:\n",
    "    plt.plot(\n",
    "        analysis_results['lcc_deviation_from_random'][key],\n",
    "        linestyle=style[0], color=style[1], label=style[2]\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Investment Iteration\")\n",
    "plt.ylabel(\"Deviation from Random Growth Baseline (meters)\")\n",
    "plt.title(\"Deviation in LCC Length from Random Growth Baseline\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"lcc_length__deviation_from_random.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## compared to random baseline\n",
    "# #  Load previous results\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# # Recalculate if needed\n",
    "# if rerun or 'lcc_lengths_GTs' not in analysis_results:\n",
    "#     lcc_data = {\n",
    "#         'lcc_lengths_GTs': [\n",
    "#             get_longest_connected_components(G) for G in GTs\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_random': [\n",
    "#             get_longest_connected_components(G) for G in GTs_random\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_demand': [\n",
    "#             get_longest_connected_components(G) for G in GTs_demand\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_demand_ltn_priority': [\n",
    "#             get_longest_connected_components(G) for G in GTs_demand_ltn_priority\n",
    "#         ],\n",
    "#         'lcc_lengths_GTs_betweenness_ltn_priority': [\n",
    "#             get_longest_connected_components(G) for G in GTs_betweenness_ltn_priority\n",
    "#         ]\n",
    "#     }\n",
    "#     analysis_results.update(lcc_data)\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     pd.DataFrame({k: pd.Series(v) for k,v in analysis_results.items()}) \\\n",
    "#         .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Calculate deviation from random\n",
    "# random_lcc = np.array(analysis_results['lcc_lengths_GTs_random'])\n",
    "\n",
    "# lcc_deviations = {\n",
    "#     'Betweenness': {\n",
    "#         'values': np.array(analysis_results['lcc_lengths_GTs']) - random_lcc,\n",
    "#         'color': 'orange',\n",
    "#         'linestyle': '--'\n",
    "#     },\n",
    "#     'Demand': {\n",
    "#         'values': np.array(analysis_results['lcc_lengths_GTs_demand']) - random_lcc,\n",
    "#         'color': 'red',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Demand LTN': {\n",
    "#         'values': np.array(analysis_results['lcc_lengths_GTs_demand_ltn_priority']) - random_lcc,\n",
    "#         'color': 'green',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Betweenness LTN': {\n",
    "#         'values': np.array(analysis_results['lcc_lengths_GTs_betweenness_ltn_priority']) - random_lcc,\n",
    "#         'color': 'purple',\n",
    "#         'linestyle': '-'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label, data in lcc_deviations.items():\n",
    "#     plt.plot(\n",
    "#         range(1, len(data['values']) + 1),\n",
    "#         data['values'],\n",
    "#         linestyle=data['linestyle'],\n",
    "#         color=data['color'],\n",
    "#         label=label\n",
    "#     )\n",
    "\n",
    "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Deviation in LCC Length vs Random (meters)')\n",
    "# plt.title('Size of Largest Connected Component — Deviation from Random Growth (Baseline)')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/size_of_lcc__deviation_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "# #     \"\"\"Computes the total length of the largest connected component for each graph in the list.\"\"\"\n",
    "# #     total_lengths_lcc = []\n",
    "    \n",
    "# #     for G in graph_list:\n",
    "# #         # Compose graphs and find largest connected component\n",
    "# #         merged = nx.compose(G, G_biketrack)\n",
    "        \n",
    "# #         # Get weakly connected components (works for both directed/undirected graphs)\n",
    "# #         components = list(nx.weakly_connected_components(merged))\n",
    "        \n",
    "# #         if not components:\n",
    "# #             total_length = 0.0  # Handle empty graph case\n",
    "# #         else:\n",
    "# #             # Find largest component by node count\n",
    "# #             largest_component_nodes = max(components, key=len)\n",
    "# #             largest_component = merged.subgraph(largest_component_nodes)\n",
    "            \n",
    "# #             # Calculate total edge length in the largest component\n",
    "# #             total_length = sum(data['length'] for u, v, data in largest_component.edges(data=True))\n",
    "        \n",
    "# #         total_lengths_lcc.append(total_length)\n",
    "    \n",
    "# #     return total_lengths_lcc\n",
    "\n",
    "# # # Compute LCC lengths for GTs and GTs_random\n",
    "# # total_lengths_lcc_GTs = compute_lcc_lengths(GTs, G_biketrack)\n",
    "# # total_lengths_lcc_GTs_random = compute_lcc_lengths(GTs_random, G_biketrack)\n",
    "\n",
    "# # # Create the plot\n",
    "# # plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # # Plot GTs\n",
    "# # plt.plot(\n",
    "# #     range(len(total_lengths_lcc_GTs)), total_lengths_lcc_GTs, linestyle='-', color='blue', label=\"GTs\"\n",
    "# # )\n",
    "\n",
    "# # # Plot GTs_random\n",
    "# # plt.plot(\n",
    "# #     range(len(total_lengths_lcc_GTs_random)), total_lengths_lcc_GTs_random, linestyle='--', color='orange', label=\"GTs_random\"\n",
    "# # )\n",
    "\n",
    "# # # Labels and title\n",
    "# # plt.title('Total Length of Largest Connected Component')\n",
    "# # plt.xlabel('Graph Index')\n",
    "# # plt.ylabel('Total Length (meters)')\n",
    "# # plt.grid(True, axis='y', alpha=0.3)\n",
    "# # plt.legend()\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'composite_lcc_GTs' not in analysis_results:\n",
    "#     def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "#         total_lengths_lcc = []\n",
    "#         for G in graph_list:\n",
    "#             merged = nx.compose(G, G_biketrack)\n",
    "#             components = list(nx.weakly_connected_components(merged))\n",
    "#             max_length = 0.0\n",
    "#             for comp in components:\n",
    "#                 subgraph = merged.subgraph(comp)\n",
    "#                 total_length = sum(data.get('length', 0) for _, _, data in subgraph.edges(data=True))\n",
    "#                 if total_length > max_length:\n",
    "#                     max_length = total_length\n",
    "#             total_lengths_lcc.append(max_length)\n",
    "#         return total_lengths_lcc\n",
    "\n",
    "#     composite_data = {\n",
    "#         'composite_lcc_GTs': compute_lcc_lengths(GTs, G_biketrack),\n",
    "#         'composite_lcc_GTs_random': compute_lcc_lengths(GTs_random, G_biketrack),\n",
    "#         'composite_lcc_GTs_demand': compute_lcc_lengths(GTs_demand, G_biketrack),\n",
    "#         'composite_lcc_GTs_demand_ltn_priority': compute_lcc_lengths(GTs_demand_ltn_priority, G_biketrack),\n",
    "#         'composite_lcc_GTs_betweenness_ltn_priority': compute_lcc_lengths(GTs_betweenness_ltn_priority, G_biketrack)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(composite_data)\n",
    "    \n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plot composite LCC results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     analysis_results['composite_lcc_GTs'],\n",
    "#     '--', color='orange',\n",
    "#     label='Betweenness Growth (with Bike Track)'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['composite_lcc_GTs_random'],\n",
    "#     '-', color='blue',\n",
    "#     label='Random Growth (with Bike Track)'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['composite_lcc_GTs_demand'],\n",
    "#     '-.', color='red',\n",
    "#     label='Demand Growth (with Bike Track)'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['composite_lcc_GTs_demand_ltn_priority'],\n",
    "#     '-.', color='green',\n",
    "#     label='Demand LTN Growth (with Bike Track)'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     analysis_results['composite_lcc_GTs_betweenness_ltn_priority'],\n",
    "#     '-', color='purple',\n",
    "#     label='Betweenness LTN Growth (with Bike Track)'\n",
    "# )\n",
    "\n",
    "# plt.title('Largest Connected Component (Including Bike Network)')\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.grid(True, axis='y', alpha=0.3)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/lengthof_lcc_inc_cyclenet.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "#     \"\"\"Computes the total length of the largest connected component for each graph in the list.\"\"\"\n",
    "#     total_lengths_lcc = []\n",
    "    \n",
    "#     for G in graph_list:\n",
    "#         # Compose graphs and find largest connected component\n",
    "#         merged = nx.compose(G, G_biketrack)\n",
    "        \n",
    "#         # Get weakly connected components (works for both directed/undirected graphs)\n",
    "#         components = list(nx.weakly_connected_components(merged))\n",
    "        \n",
    "#         if not components:\n",
    "#             total_length = 0.0  # Handle empty graph case\n",
    "#         else:\n",
    "#             # Find largest component by node count\n",
    "#             largest_component_nodes = max(components, key=len)\n",
    "#             largest_component = merged.subgraph(largest_component_nodes)\n",
    "            \n",
    "#             # Calculate total edge length in the largest component\n",
    "#             total_length = sum(data['length'] for u, v, data in largest_component.edges(data=True))\n",
    "        \n",
    "#         total_lengths_lcc.append(total_length)\n",
    "    \n",
    "#     return total_lengths_lcc\n",
    "\n",
    "# # Compute LCC lengths for GTs and GTs_random\n",
    "# total_lengths_lcc_GTs = compute_lcc_lengths(GTs, G_biketrack)\n",
    "# total_lengths_lcc_GTs_random = compute_lcc_lengths(GTs_random, G_biketrack)\n",
    "\n",
    "# # Create the plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot GTs\n",
    "# plt.plot(\n",
    "#     range(len(total_lengths_lcc_GTs)), total_lengths_lcc_GTs, linestyle='-', color='blue', label=\"GTs\"\n",
    "# )\n",
    "\n",
    "# # Plot GTs_random\n",
    "# plt.plot(\n",
    "#     range(len(total_lengths_lcc_GTs_random)), total_lengths_lcc_GTs_random, linestyle='--', color='orange', label=\"GTs_random\"\n",
    "# )\n",
    "\n",
    "# # Labels and title\n",
    "# plt.title('Total Length of Largest Connected Component')\n",
    "# plt.xlabel('Graph Index')\n",
    "# plt.ylabel('Total Length (meters)')\n",
    "# plt.grid(True, axis='y', alpha=0.3)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# --- Load or init results ---\n",
    "analysis_results = load_results(analysis_res_pickle)\n",
    "if rerun or 'composite_lcc_lengths' not in analysis_results:\n",
    "    composite_lcc_data = {\n",
    "    'composite_lcc_lengths': [get_composite_lcc_length(G, G_biketrack) for G in GTs],\n",
    "    'random_runs_composite_lcc_lengths': [\n",
    "        [get_composite_lcc_length(G, G_biketrack) for G in run['GTs']] for run in random_runs\n",
    "    ],\n",
    "    'composite_lcc_lengths_demand': [get_composite_lcc_length(G, G_biketrack) for G in GTs_demand],\n",
    "    'composite_lcc_lengths_demand_ltn_priority': [get_composite_lcc_length(G, G_biketrack) for G in GTs_demand_ltn_priority],\n",
    "    'composite_lcc_lengths_betweenness_ltn_priority': [get_composite_lcc_length(G, G_biketrack) for G in GTs_betweenness_ltn_priority]\n",
    "    }\n",
    "\n",
    "    composite_lcc_data['random_composite_lcc_lengths_mean'] = np.mean(\n",
    "        composite_lcc_data['random_runs_composite_lcc_lengths'], axis=0\n",
    "    ).tolist()\n",
    "\n",
    "    analysis_results.update(composite_lcc_data)\n",
    "    save_results(analysis_results, analysis_res_pickle, analysis_res_csv)\n",
    "\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for run in analysis_results['random_runs_composite_lcc_lengths']:\n",
    "    plt.plot(run, color='lightgray', linewidth=1, alpha=0.4)\n",
    "\n",
    "plt.plot(\n",
    "    analysis_results['random_composite_lcc_lengths_mean'],\n",
    "    linestyle='--', linewidth=2, label='Random Growth (mean)', color='blue'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['composite_lcc_lengths'],\n",
    "    '-', label='Betweenness Growth', color='orange'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['composite_lcc_lengths_demand'],\n",
    "    '-.', label='Demand Growth', color='red'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['composite_lcc_lengths_demand_ltn_priority'],\n",
    "    ':', label='Demand LTN Priority Growth', color='green'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['composite_lcc_lengths_betweenness_ltn_priority'],\n",
    "    '-', label='Betweenness LTN Priority Growth', color='purple'\n",
    ")\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('LCC Length (meters)')\n",
    "plt.title('Size of Largest Connected Component Including Bike Network per Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"size_of_composite_lcc.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = load_results(analysis_res_pickle)\n",
    "\n",
    "# Extract baseline and strategies\n",
    "random_runs_array = np.array(analysis_results['random_runs_composite_lcc_lengths'])\n",
    "random_lcc_mean = np.array(analysis_results['random_composite_lcc_lengths_mean'])\n",
    "\n",
    "# Compute deviation of each strategy from mean random baseline\n",
    "composite_deviations = {\n",
    "    'Betweenness': np.array(analysis_results['composite_lcc_lengths']) - random_lcc_mean,\n",
    "    'Demand': np.array(analysis_results['composite_lcc_lengths_demand']) - random_lcc_mean,\n",
    "    'Demand LTN': np.array(analysis_results['composite_lcc_lengths_demand_ltn_priority']) - random_lcc_mean,\n",
    "    'Betweenness LTN': np.array(analysis_results['composite_lcc_lengths_betweenness_ltn_priority']) - random_lcc_mean,\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot baseline (mean of random runs)\n",
    "plt.plot(random_lcc_mean, color='blue', linestyle='-', linewidth=2, label='Random Growth Mean Baseline')\n",
    "for run in random_runs_array:\n",
    "    plt.plot(run, color='lightgray', linewidth=1, alpha=0.3)\n",
    "\n",
    "# Plot strategies relative to baseline\n",
    "styles = {\n",
    "    'Betweenness': ('--', 'orange'),\n",
    "    'Demand': ('-.', 'red'),\n",
    "    'Demand LTN': (':', 'green'),\n",
    "    'Betweenness LTN': ('-', 'purple'),\n",
    "}\n",
    "\n",
    "for label, deviation in composite_deviations.items():\n",
    "    absolute_values = deviation + random_lcc_mean  # Plot absolute LCC lengths\n",
    "    linestyle, color = styles[label]\n",
    "    plt.plot(range(1, len(absolute_values) + 1), absolute_values, linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "# Finalize plot\n",
    "plt.title('Composite LCC Length Compared to Random Growth Baseline')\n",
    "plt.xlabel('Investment Iteration')\n",
    "plt.ylabel('Total Length (meters)')\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = os.path.join(PATH[\"plots\"], placeid, \"lengthof_lcc_inc_cyclenet_vs_random_mean_baseline.png\")\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# # Recalculate composite LCCs if needed\n",
    "# if rerun or 'composite_lcc_GTs' not in analysis_results:\n",
    "#     def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "#         total_lengths_lcc = []\n",
    "#         for G in graph_list:\n",
    "#             merged = nx.compose(G, G_biketrack)\n",
    "#             components = list(nx.weakly_connected_components(merged))\n",
    "#             max_length = 0.0\n",
    "#             for comp in components:\n",
    "#                 subgraph = merged.subgraph(comp)\n",
    "#                 total_length = sum(data.get('length', 0) for _, _, data in subgraph.edges(data=True))\n",
    "#                 if total_length > max_length:\n",
    "#                     max_length = total_length\n",
    "#             total_lengths_lcc.append(max_length)\n",
    "#         return total_lengths_lcc\n",
    "\n",
    "#     composite_data = {\n",
    "#         'composite_lcc_GTs': compute_lcc_lengths(GTs, G_biketrack),\n",
    "#         'composite_lcc_GTs_random': compute_lcc_lengths(GTs_random, G_biketrack),\n",
    "#         'composite_lcc_GTs_demand': compute_lcc_lengths(GTs_demand, G_biketrack),\n",
    "#         'composite_lcc_GTs_demand_ltn_priority': compute_lcc_lengths(GTs_demand_ltn_priority, G_biketrack),\n",
    "#         'composite_lcc_GTs_betweenness_ltn_priority': compute_lcc_lengths(GTs_betweenness_ltn_priority, G_biketrack)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(composite_data)\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Compute deviation from random\n",
    "# random_composite = np.array(analysis_results['composite_lcc_GTs_random'])\n",
    "\n",
    "# composite_deviations = {\n",
    "#     'Betweenness': {\n",
    "#         'values': np.array(analysis_results['composite_lcc_GTs']) - random_composite,\n",
    "#         'color': 'orange',\n",
    "#         'linestyle': '--'\n",
    "#     },\n",
    "#     'Demand': {\n",
    "#         'values': np.array(analysis_results['composite_lcc_GTs_demand']) - random_composite,\n",
    "#         'color': 'red',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Demand LTN': {\n",
    "#         'values': np.array(analysis_results['composite_lcc_GTs_demand_ltn_priority']) - random_composite,\n",
    "#         'color': 'green',\n",
    "#         'linestyle': '-.'\n",
    "#     },\n",
    "#     'Betweenness LTN': {\n",
    "#         'values': np.array(analysis_results['composite_lcc_GTs_betweenness_ltn_priority']) - random_composite,\n",
    "#         'color': 'purple',\n",
    "#         'linestyle': '-'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Plot deviation from random\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label, data in composite_deviations.items():\n",
    "#     plt.plot(\n",
    "#         range(1, len(data['values']) + 1),\n",
    "#         data['values'],\n",
    "#         linestyle=data['linestyle'],\n",
    "#         color=data['color'],\n",
    "#         label=label\n",
    "#     )\n",
    "\n",
    "# plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "# plt.title('Composite LCC Length (With Cycle Network) — Deviation from Random Growth (Baseline)')\n",
    "# plt.xlabel('Investment Iteration')\n",
    "# plt.ylabel('Deviation in Total Length vs Random (meters)')\n",
    "# plt.legend()\n",
    "# plt.grid(True, axis='y', alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save\n",
    "# output_path = PATH[\"plots\"] + f\"/{placeid}/lengthof_lcc_inc_cyclenet__deviation_from_random.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # def total_length(G):\n",
    "# #     \"\"\"Computes total edge length in a graph.\"\"\"\n",
    "# #     return sum(data.get('length', 1) for _, _, data in G.edges(data=True))\n",
    "\n",
    "# # def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "# #     \"\"\"Computes the total length of the largest connected component for each graph in the list.\"\"\"\n",
    "# #     lcc_lengths = []\n",
    "\n",
    "# #     for G in graph_list:\n",
    "# #         # Find the common nodes between G and G_biketrack\n",
    "# #         common_nodes = set(G.nodes) & set(G_biketrack.nodes)\n",
    "\n",
    "# #         # If there are no common nodes, we can't compose, so we skip and set LCC length to 0\n",
    "# #         if not common_nodes:\n",
    "# #             lcc_lengths.append(0.0)\n",
    "# #             continue\n",
    "        \n",
    "# #         # Create a subgraph of G_biketrack with only the common nodes\n",
    "# #         G_biketrack_subgraph = G_biketrack.subgraph(common_nodes)\n",
    "\n",
    "# #         # Merge G with the G_biketrack subgraph\n",
    "# #         merged = nx.compose(G, G_biketrack_subgraph)\n",
    "\n",
    "# #         # Find weakly connected components (works for both directed/undirected graphs)\n",
    "# #         components = list(nx.weakly_connected_components(merged))\n",
    "\n",
    "# #         if not components:\n",
    "# #             total_length_lcc = 0.0  # Handle empty graph case\n",
    "# #         else:\n",
    "# #             # Find the largest connected component by node count\n",
    "# #             largest_component_nodes = max(components, key=len)\n",
    "# #             largest_component = merged.subgraph(largest_component_nodes)\n",
    "\n",
    "# #             # Calculate total edge length in the largest component\n",
    "# #             total_length_lcc = sum(data.get('length', 1) for u, v, data in largest_component.edges(data=True))\n",
    "\n",
    "# #         lcc_lengths.append(total_length_lcc)\n",
    "\n",
    "# #     return lcc_lengths\n",
    "\n",
    "# # # Compute LCC lengths for both GTs and GTs_random\n",
    "# # lcc_lengths_GTs = compute_lcc_lengths(GTs, G_biketrack)\n",
    "# # lcc_lengths_GTs_random = compute_lcc_lengths(GTs_random, G_biketrack)\n",
    "\n",
    "# # # Create the plot\n",
    "# # plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # # Plot LCC lengths for GTs\n",
    "# # plt.plot(range(1, len(lcc_lengths_GTs) + 1), lcc_lengths_GTs, linestyle='-', color='blue', label=\"GTs - LCC Length\")\n",
    "\n",
    "# # # Plot LCC lengths for GTs_random\n",
    "# # plt.plot(range(1, len(lcc_lengths_GTs_random) + 1), lcc_lengths_GTs_random, linestyle='--', color='orange', label=\"GTs_random - LCC Length\")\n",
    "\n",
    "# # # Labels and title\n",
    "# # plt.xlabel(\"Graph Index\")\n",
    "# # plt.ylabel(\"Largest Connected Component Length (meters)\")\n",
    "# # plt.title(\"Largest Connected Component Length (GTs vs. GTs_random)\")\n",
    "# # plt.legend()\n",
    "# # plt.grid(True, alpha=0.3)\n",
    "\n",
    "# # # Show the plot\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'lcc_lengths_GTs' not in analysis_results:\n",
    "\n",
    "#     def total_length(G):\n",
    "#         return sum(data.get('length', 1) for _, _, data in G.edges(data=True))  \n",
    "\n",
    "#     def compute_lcc_lengths(graph_list, G_biketrack):\n",
    "#         lcc_lengths = []\n",
    "#         for G in graph_list:\n",
    "#             common_nodes = set(G.nodes) & set(G_biketrack.nodes)\n",
    "#             if not common_nodes:\n",
    "#                 lcc_lengths.append(0.0)\n",
    "#                 continue\n",
    "\n",
    "#             G_biketrack_subgraph = G_biketrack.subgraph(common_nodes)\n",
    "#             merged = nx.compose(G, G_biketrack_subgraph)\n",
    "#             components = list(nx.weakly_connected_components(merged))\n",
    "\n",
    "#             max_length = 0.0\n",
    "#             for comp in components:\n",
    "#                 subgraph = merged.subgraph(comp)\n",
    "#                 total_length = sum(data.get('length', 1) for _, _, data in subgraph.edges(data=True))\n",
    "#                 if total_length > max_length:\n",
    "#                     max_length = total_length\n",
    "\n",
    "#             lcc_lengths.append(max_length)\n",
    "#         return lcc_lengths\n",
    "\n",
    "#     lcc_data = {\n",
    "#         'lcc_lengths_GTs':        compute_lcc_lengths(GTs, G_biketrack),\n",
    "#         'lcc_lengths_GTs_random': compute_lcc_lengths(GTs_random, G_biketrack),\n",
    "#         'lcc_lengths_GTs_demand': compute_lcc_lengths(GTs_demand, G_biketrack),\n",
    "#         'lcc_lengths_GTs_demand_ltn_priority': compute_lcc_lengths(GTs_demand_ltn_priority, G_biketrack),\n",
    "#         'lcc_lengths_GTs_betweenness_ltn_priority': compute_lcc_lengths(GTs_betweenness_ltn_priority, G_biketrack)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(lcc_data)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k,v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(\n",
    "#     range(1, len(analysis_results['lcc_lengths_GTs']) + 1), \n",
    "#     analysis_results['lcc_lengths_GTs'], \n",
    "#     linestyle='-', color='orange',  \n",
    "#     label=\"Betweenness growth\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     range(1, len(analysis_results['lcc_lengths_GTs_random']) + 1), \n",
    "#     analysis_results['lcc_lengths_GTs_random'], \n",
    "#     linestyle='--', color='blue', \n",
    "#     label=\"Random growth\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     range(1, len(analysis_results['lcc_lengths_GTs_demand']) + 1), \n",
    "#     analysis_results['lcc_lengths_GTs_demand'], \n",
    "#     linestyle='-.', color='red', \n",
    "#     label=\"Demand growth\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     range(1, len(analysis_results['lcc_lengths_GTs_demand_ltn_priority']) + 1), \n",
    "#     analysis_results['lcc_lengths_GTs_demand_ltn_priority'], \n",
    "#     linestyle='-.', color='green', \n",
    "#     label=\"Demand LTN growth\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     range(1, len(analysis_results['lcc_lengths_GTs_betweenness_ltn_priority']) + 1), \n",
    "#     analysis_results['lcc_lengths_GTs_betweenness_ltn_priority'], \n",
    "#     linestyle='-', color='purple', \n",
    "#     label=\"Betweenness LTN growth\"\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Graph Index\")\n",
    "# plt.ylabel(\"Largest Connected Component Length (meters)\")\n",
    "# plt.title(\"Largest Connected Component Length\")\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# output_path = PATH[\"plots\"] + \"/\" + placeid + \"/lcc_length.png\"\n",
    "# plt.savefig(output_path, dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to running any coverage analysis, we create buffers of each graph to avoid re-calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if rerun == True or 'GTs_buffers' not in locals():\n",
    "#     GTs_buffers = []\n",
    "#     for G in GTs:\n",
    "#         gdf_edges = ox.graph_to_gdfs(G, nodes=False).to_crs(epsg=3857) # convert graph to geodataframe\n",
    "#         buffer_gdf = gdf_edges.geometry.buffer(buffer_walk).unary_union # make a buffer\n",
    "#         buffer_gdf = gpd.GeoDataFrame(geometry=[buffer_gdf], crs=gdf_edges.crs) # set crs and geometry\n",
    "#         buffer_gdf = buffer_gdf.to_crs(epsg=4326)\n",
    "#         GTs_buffers.append(buffer_gdf) # add buffer to a list\n",
    "#     with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers.pickle\", \"wb\") as f:\n",
    "#         pickle.dump(GTs_buffers, f) # save buffers\n",
    "\n",
    "#     GTs_buffers_random = []\n",
    "#     for G in GTs_random:\n",
    "#         gdf_edges = ox.graph_to_gdfs(G, nodes=False).to_crs(epsg=3857)\n",
    "#         buffer_gdf = gdf_edges.geometry.buffer(buffer_walk).unary_union\n",
    "#         buffer_gdf = gpd.GeoDataFrame(geometry=[buffer_gdf], crs=gdf_edges.crs)\n",
    "#         buffer_gdf = buffer_gdf.to_crs(epsg=4326)\n",
    "#         GTs_buffers_random.append(buffer_gdf)\n",
    "#     with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_random.pickle\", \"wb\") as f:\n",
    "#         pickle.dump(GTs_buffers_random, f)\n",
    "\n",
    "#     GTs_buffers_demand = []\n",
    "#     for G in GTs_demand:\n",
    "#         gdf_edges = ox.graph_to_gdfs(G, nodes=False).to_crs(epsg=3857)\n",
    "#         buffer_gdf = gdf_edges.geometry.buffer(buffer_walk).unary_union\n",
    "#         buffer_gdf = gpd.GeoDataFrame(geometry=[buffer_gdf], crs=gdf_edges.crs)\n",
    "#         buffer_gdf = buffer_gdf.to_crs(epsg=4326)\n",
    "#         GTs_buffers_demand.append(buffer_gdf)\n",
    "#     with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_demand.pickle\", \"wb\") as f:\n",
    "#         pickle.dump(GTs_buffers_demand, f)\n",
    "\n",
    "\n",
    "#     GTs_buffers_demand_ltn_priority = []\n",
    "#     for G in GTs_demand_ltn_priority:\n",
    "#         gdf_edges = ox.graph_to_gdfs(G, nodes=False).to_crs(epsg=3857)\n",
    "#         buffer_gdf = gdf_edges.geometry.buffer(buffer_walk).unary_union\n",
    "#         buffer_gdf = gpd.GeoDataFrame(geometry=[buffer_gdf], crs=gdf_edges.crs)\n",
    "#         buffer_gdf = buffer_gdf.to_crs(epsg=4326)\n",
    "#         GTs_buffers_demand_ltn_priority.append(buffer_gdf)\n",
    "#     with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_demand_ltn_priority.pickle\", \"wb\") as f:\n",
    "#         pickle.dump(GTs_buffers_demand_ltn_priority, f)\n",
    "\n",
    "    \n",
    "#     GTs_buffers_betweenness_ltn_priority = []\n",
    "#     for G in GTs_betweenness_ltn_priority:\n",
    "#         gdf_edges = ox.graph_to_gdfs(G, nodes=False).to_crs(epsg=3857)\n",
    "#         buffer_gdf = gdf_edges.geometry.buffer(buffer_walk).unary_union\n",
    "#         buffer_gdf = gpd.GeoDataFrame(geometry=[buffer_gdf], crs=gdf_edges.crs)\n",
    "#         buffer_gdf = buffer_gdf.to_crs(epsg=4326)\n",
    "#         GTs_buffers_betweenness_ltn_priority.append(buffer_gdf)\n",
    "#     with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_betweenness_ltn_priority.pickle\", \"wb\") as f:\n",
    "#         pickle.dump(GTs_buffers_betweenness_ltn_priority, f)\n",
    "\n",
    "# else:\n",
    "#     try:\n",
    "#         with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers.pickle\", \"rb\") as f:\n",
    "#             GTs_buffers = pickle.load(f)\n",
    "#         with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_random.pickle\", \"rb\") as f:\n",
    "#             GTs_buffers_random = pickle.load(f)\n",
    "#         with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_demand.pickle\", \"rb\") as f:\n",
    "#             GTs_buffers_demand = pickle.load(f)\n",
    "#         with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_demand_ltn_priority.pickle\", \"rb\") as f:\n",
    "#             GTs_buffers_demand_ltn_priority = pickle.load(f)\n",
    "#         with open(PATH[\"results\"] + placeid + \"/\" + placeid + \"_GTs_buffers_betweenness_ltn_priority.pickle\", \"rb\") as f:\n",
    "#             GTs_buffers_betweenness_ltn_priority = pickle.load(f)\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"Buffer files not found. Please set rerun to True to regenerate them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(PATH[\"results\"], placeid, placeid)\n",
    "GTs_buffers = process_and_save_buffers_parallel(GTs, \"GTs_buffers\", rerun, base_path, buffer_walk)\n",
    "GTs_buffers_demand = process_and_save_buffers_parallel(GTs_demand, \"GTs_buffers_demand\", rerun, base_path, buffer_walk)\n",
    "GTs_buffers_demand_ltn_priority = process_and_save_buffers_parallel(GTs_demand_ltn_priority, \"GTs_buffers_demand_ltn_priority\", rerun, base_path, buffer_walk)\n",
    "GTs_buffers_betweenness_ltn_priority = process_and_save_buffers_parallel(GTs_betweenness_ltn_priority, \"GTs_buffers_betweenness_ltn_priority\", rerun, base_path, buffer_walk)\n",
    "# For multiple random runs\n",
    "GTs_buffers_random_all = []\n",
    "for run_id, run_res in enumerate(random_runs, start=1):\n",
    "    name = f\"GTs_buffers_random_run{run_id:02d}\"\n",
    "    buffers = process_and_save_buffers_parallel(run_res[\"GTs\"], name, rerun, base_path, buffer_walk)\n",
    "    GTs_buffers_random_all.append(buffers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # area\n",
    "# target_crs = \"EPSG:3857\"\n",
    "# boundary_proj = boundary.to_crs(target_crs)\n",
    "# total_area = boundary_proj.unary_union.area  # total area in m²\n",
    "\n",
    "# # Function to compute areas (km²) and percentage coverage for a list of buffers\n",
    "# def compute_metrics(buffer_list):\n",
    "#     areas = []\n",
    "#     percentages = []\n",
    "#     for gdf in buffer_list:\n",
    "#         gdf_proj = gdf.to_crs(target_crs)\n",
    "#         inter = gpd.overlay(gdf_proj, boundary_proj, how='intersection')\n",
    "#         inter_area = inter.unary_union.area if not inter.empty else 0\n",
    "#         areas.append(inter_area / 1e6)  # convert m² to km²\n",
    "#         percentages.append((inter_area / total_area * 100) if total_area else 0)\n",
    "#     return areas, percentages\n",
    "\n",
    "# # Compute metrics for both buffer sets\n",
    "# areas1, perc1 = compute_metrics(GTs_buffers)\n",
    "# areas2, perc2 = compute_metrics(GTs_buffers_random)\n",
    "\n",
    "# # Plot 1: Compare areas (in km²) for both buffer sets on one graph\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(areas1, 'b-o', label='GTs_buffers Area (km²)')\n",
    "# plt.plot(areas2, 'g-o', label='GTs_buffers_random Area (km²)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Area (km²)')\n",
    "# plt.title('Boundary Intersection Area Comparison')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot 2: Compare coverage percentages for both buffer sets on one graph\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(perc1, 'r-s', label='GTs_buffers Coverage (%)')\n",
    "# plt.plot(perc2, 'm-s', label='GTs_buffers_random Coverage (%)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Boundary Coverage Percentage Comparison')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Area analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'buffer_areas' not in analysis_results:\n",
    "    target_crs = \"EPSG:3857\"\n",
    "    boundary_proj = boundary.to_crs(target_crs)\n",
    "    total_area = boundary_proj.unary_union.area\n",
    "\n",
    "    def compute_metrics(buffer_list):\n",
    "        areas = []\n",
    "        percentages = []\n",
    "        for gdf in buffer_list:\n",
    "            gdf_proj = gdf.to_crs(target_crs)\n",
    "            inter = gpd.overlay(gdf_proj, boundary_proj, how='intersection')\n",
    "            inter_area = inter.unary_union.area if not inter.empty else 0\n",
    "            areas.append(inter_area / 1e6)  # Convert m² to km²\n",
    "            percentages.append((inter_area / total_area * 100) if total_area else 0)\n",
    "        return areas, percentages\n",
    "\n",
    "    buffer_metrics = {\n",
    "        'buffer_areas': compute_metrics(GTs_buffers)[0],\n",
    "        'buffer_percentages': compute_metrics(GTs_buffers)[1],\n",
    "        'random_buffer_areas': compute_metrics(GTs_buffers_random)[0],\n",
    "        'random_buffer_percentages': compute_metrics(GTs_buffers_random)[1],\n",
    "        'demand_buffer_areas': compute_metrics(GTs_buffers_demand)[0],\n",
    "        'demand_buffer_percentages': compute_metrics(GTs_buffers_demand)[1],\n",
    "        'demand_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[0],\n",
    "        'demand_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_demand_ltn_priority)[1],\n",
    "        'betweenness_buffer_areas_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "        'betweenness_buffer_percentages_ltn_priority': compute_metrics(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(buffer_metrics)\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting - Area (km²)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    analysis_results['buffer_areas'], \n",
    "    color='orange', \n",
    "    linestyle='-', \n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['random_buffer_areas'], \n",
    "    color='blue', \n",
    "    linestyle='--', \n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['demand_buffer_areas'], \n",
    "    color='red', \n",
    "    linestyle='-.', \n",
    "    label='Demand Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['demand_buffer_areas_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['betweenness_buffer_areas_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Area (km²)')\n",
    "plt.title('Total Area Coverage')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True, alpha=0.3)\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/area_coverage_km2.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plotting - Percentage Coverage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    analysis_results['buffer_percentages'], \n",
    "    color='orange', \n",
    "    linestyle='-', \n",
    "    label='Betweeness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['random_buffer_percentages'], \n",
    "    color='blue', \n",
    "    linestyle='--', \n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['demand_buffer_percentages'], \n",
    "    color='red', \n",
    "    linestyle='-.', \n",
    "    label='Demand Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['demand_buffer_percentages_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['betweenness_buffer_percentages_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Coverage (%)')\n",
    "plt.title('Boundary Coverage')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True, alpha=0.3)\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/boundary_cov_percentage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streets coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_crs = G_biketrackcarall_edges.crs\n",
    "# total_network_length = G_biketrackcarall_edges[\"length\"].sum()\n",
    "\n",
    "# def compute_street_coverage(buffer_list):\n",
    "#     lengths = []\n",
    "#     percentages = []\n",
    "#     for gdf in buffer_list:\n",
    "#         # Reproject buffers to network CRS if needed\n",
    "#         gdf_proj = gdf.to_crs(network_crs)\n",
    "#         # Compute intersection between network and buffer\n",
    "#         inter = gpd.overlay(G_biketrackcarall_edges, gdf_proj, how='intersection')\n",
    "#         # Sum the existing \"length\" values from the intersected segments\n",
    "#         seg_length = inter[\"length\"].sum() if not inter.empty else 0\n",
    "#         lengths.append(seg_length)\n",
    "#         percentages.append((seg_length / total_network_length * 100) if total_network_length else 0)\n",
    "#     return lengths, percentages\n",
    "\n",
    "# # Compute metrics for both buffer sets\n",
    "# net_lengths1, net_perc1 = compute_street_coverage(GTs_buffers)\n",
    "# net_lengths2, net_perc2 = compute_street_coverage(GTs_buffers_random)\n",
    "\n",
    "# # Plot 1: Compare network lengths (in meters) within each buffer\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(net_lengths1, 'b-o', label='GTs_buffers Network (m)')\n",
    "# plt.plot(net_lengths2, 'g-o', label='GTs_buffers_random Network (m)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Network Length (m)')\n",
    "# plt.title('Street Network Length within Buffers')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot 2: Compare network coverage percentages\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(net_perc1, 'r-s', label='GTs_buffers Coverage (%)')\n",
    "# plt.plot(net_perc2, 'm-s', label='GTs_buffers_random Coverage (%)')\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Coverage (%)')\n",
    "# plt.title('Percentage of Total Network within Buffers')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "\n",
    "\n",
    "if rerun or 'street_lengths' not in analysis_results:\n",
    "    network_crs = G_biketrackcarall_edges.crs\n",
    "    total_network_length = G_biketrackcarall_edges[\"length\"].sum()\n",
    "\n",
    "    # simplfy to reduce computation time\n",
    "    proj_crs = network_crs if network_crs.is_projected else \"EPSG:3857\"\n",
    "    edges_proj = G_biketrackcarall_edges.to_crs(proj_crs)\n",
    "    edges_simpl = edges_proj.copy()\n",
    "    edges_simpl.geometry = edges_proj.geometry.simplify(tolerance=10,\n",
    "                                                         preserve_topology=True)\n",
    "    edges_simpl = edges_simpl.to_crs(network_crs)\n",
    "\n",
    "    def compute_street_coverage(buffer_list):\n",
    "        lengths = []\n",
    "        percentages = []\n",
    "        for gdf in buffer_list:\n",
    "            gdf_proj = gdf.to_crs(network_crs)\n",
    "            # simplfy to reduce computation time\n",
    "            gdf_proj = gdf.to_crs(proj_crs).copy()\n",
    "            gdf_proj.geometry = gdf_proj.geometry.simplify(tolerance=10,\n",
    "                                                           preserve_topology=True)\n",
    "            gdf_proj = gdf_proj.to_crs(network_crs)\n",
    "            \n",
    "            inter = gpd.overlay(G_biketrackcarall_edges, gdf_proj, how='intersection')\n",
    "            seg_length = inter[\"length\"].sum() if not inter.empty else 0\n",
    "            lengths.append(seg_length)\n",
    "            percentages.append((seg_length / total_network_length * 100) if total_network_length else 0)\n",
    "        return lengths, percentages\n",
    "\n",
    "    street_metrics = {\n",
    "        'street_cov_lengths': compute_street_coverage(GTs_buffers)[0],\n",
    "        'street_cov_percentages': compute_street_coverage(GTs_buffers)[1],\n",
    "        'random_street_cov_lengths': compute_street_coverage(GTs_buffers_random)[0],\n",
    "        'random_street_cov_percentages': compute_street_coverage(GTs_buffers_random)[1],\n",
    "        'demand_street_cov_lengths': compute_street_coverage(GTs_buffers_demand)[0],\n",
    "        'demand_street_cov_percentages': compute_street_coverage(GTs_buffers_demand)[1],\n",
    "        'demand_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[0],\n",
    "        'demand_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_demand_ltn_priority)[1],\n",
    "        'betweenness_street_cov_lengths_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[0],\n",
    "        'betweenness_street_cov_percentages_ltn_priority': compute_street_coverage(GTs_buffers_betweenness_ltn_priority)[1]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(street_metrics)\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "    df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plot: Network Length within Buffers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(analysis_results['street_cov_lengths'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['random_street_cov_lengths'], color='blue', linestyle='--', label='Random Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_lengths'], color='red', linestyle='-.', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_lengths_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_street_cov_lengths_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Street Network Length (m)')\n",
    "plt.title('Street Network Length within Buffers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/streets_within_cyclenet.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot: Percentage of Network within Buffers\n",
    "plt.figure(10, 6)\n",
    "plt.plot(analysis_results['street_cov_percentages'], color='orange', linestyle='-', label='Betweenness Growth')\n",
    "plt.plot(analysis_results['random_street_cov_percentages'], color='blue', linestyle='--', label='Random Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_percentages'], color='red', linestyle='-.', label='Demand Growth')\n",
    "plt.plot(analysis_results['demand_street_cov_percentages_ltn_priority'], color='green', linestyle=':', label='Demand LTN Growth')\n",
    "plt.plot(analysis_results['betweenness_street_cov_percentages_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN Growth')\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Coverage (%)')\n",
    "plt.title('Percentage of Total Network within Buffers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/percentage_within_cyclenet.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get population data from census, asign census data to buildings, find population within cycle route buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get lsoas and population\n",
    "# lsoa_bound = gpd.read_file(PATH[\"data\"] + \"/\" + placeid + \"/lsoa_bound.gpkg\")\n",
    "# boundary = ox.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "# lsoa_bound = gpd.clip(lsoa_bound, boundary)\n",
    "# lsoa_bound = add_lsoa_population(lsoa_bound) # using 2011 census data\n",
    "\n",
    "# # get buildings\n",
    "# buildings = get_building_populations(lsoa_bound, boundary) ## add more detail??\n",
    "# buildings = buildings.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # pop_counts_GT = []\n",
    "# # pop_counts_random_GT = []\n",
    "\n",
    "\n",
    "# # # Function to calculate total pop_count within each buffer\n",
    "# # def calculate_pop_count(buffers_list, buildings):\n",
    "# #     pop_counts = []\n",
    "# #     for buffer in buffers_list:\n",
    "# #         intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "# #         total_pop = intersecting_buildings[\"pop_assigned\"].sum()\n",
    "# #         pop_counts.append(total_pop)\n",
    "# #     return pop_counts\n",
    "\n",
    "# # # Calculate for both sets of buffers\n",
    "# # pop_counts_GT = calculate_pop_count(GTs_buffers, buildings)\n",
    "# # pop_counts_random_GT = calculate_pop_count(GTs_buffers_random, buildings)\n",
    "\n",
    "# # plt.figure(figsize=(10, 5))\n",
    "# # buffer_indices = np.arange(len(GTs_buffers))  # Common x-axis indices for both datasets\n",
    "\n",
    "# # plt.plot(buffer_indices, pop_counts_GT, label=\"GTs Buffers\", linestyle='-', color='blue')\n",
    "# # plt.plot(buffer_indices, pop_counts_random_GT, label=\"Random GTs Buffers\", linestyle='--', color='orange')\n",
    "\n",
    "# # plt.xlabel(\"Buffer Index\")\n",
    "# # plt.ylabel(\"Total Population Count\")\n",
    "# # plt.title(\"Comparison of Population Within Buffers\")\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# # plt.show()\n",
    "# if os.path.exists(analysis_res_pickle):\n",
    "#     with open(analysis_res_pickle, 'rb') as f:\n",
    "#         analysis_results = pickle.load(f)\n",
    "# else:\n",
    "#     analysis_results = {}\n",
    "\n",
    "# if rerun or 'pop_counts_GT' not in analysis_results:\n",
    "#     def calculate_pop_count(buffers_list, buildings):\n",
    "#         pop_counts = []\n",
    "#         for buffer in buffers_list:\n",
    "#             intersecting_buildings = gpd.sjoin(buildings, buffer, predicate=\"intersects\")\n",
    "#             pop_counts.append(intersecting_buildings[\"pop_assigned\"].sum())\n",
    "#         return pop_counts\n",
    "\n",
    "#     pop_metrics = {\n",
    "#         'pop_counts_GT': calculate_pop_count(GTs_buffers, buildings),\n",
    "#         'pop_counts_random_GT': calculate_pop_count(GTs_buffers_random, buildings),\n",
    "#         'pop_counts_demand_GT': calculate_pop_count(GTs_buffers_demand, buildings)\n",
    "#     }\n",
    "\n",
    "#     analysis_results.update(pop_metrics)\n",
    "\n",
    "#     with open(analysis_res_pickle, 'wb') as f:\n",
    "#         pickle.dump(analysis_results, f)\n",
    "#     df = pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()})\n",
    "#     df.to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# buffer_indices = np.arange(len(GTs_buffers))\n",
    "\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_GT'],\n",
    "#     label=\"Betweenness Growth\",\n",
    "#     linestyle='-',\n",
    "#     color='orange'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_random_GT'],\n",
    "#     label=\"Random Growth\",\n",
    "#     linestyle='--',\n",
    "#     color='blue'\n",
    "# )\n",
    "# plt.plot(\n",
    "#     buffer_indices,\n",
    "#     analysis_results['pop_counts_demand_GT'],\n",
    "#     label=\"Demand-based Growth\",\n",
    "#     linestyle='-.',\n",
    "#     color='red'\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Buffer Index\")\n",
    "# plt.ylabel(\"Total Population Count\")\n",
    "# plt.title(\"Population Within Buffers Over Investment Iterations\")\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_buffers = []\n",
    "# counts_random = []\n",
    "\n",
    "# # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# for gdf in GTs_buffers:\n",
    "#     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     # Count the points in combined_points that fall within this union\n",
    "#     count = combined_points.within(buffer_union).sum()\n",
    "#     counts_buffers.append(count)\n",
    "\n",
    "# # Do the same for GTs_buffers_random\n",
    "# for gdf in GTs_buffers_random:\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     count = combined_points.within(buffer_union).sum()\n",
    "#     counts_random.append(count)\n",
    "\n",
    "# # Plotting the results on a line graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Number of Points Covered')\n",
    "# plt.title('Points Covered by Each Buffer')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# Seed point analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}  \n",
    "\n",
    "if rerun or 'points_covered_GT' not in analysis_results:\n",
    "    point_metrics = {\n",
    "        'points_covered_GT': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers\n",
    "        ],\n",
    "        'points_covered_random': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_random\n",
    "        ],\n",
    "        'points_covered_demand': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_demand\n",
    "        ],\n",
    "        'points_covered_demand_ltn_priority': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_demand_ltn_priority\n",
    "        ],\n",
    "        'points_covered_betweenness_ltn_priority': [\n",
    "            combined_points.within(gdf.unary_union).sum()\n",
    "            for gdf in GTs_buffers_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "    analysis_results.update(point_metrics)\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Number of Points Covered')\n",
    "plt.title('Seed Points Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/seed_point_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LTN Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_buffers = []\n",
    "# counts_random = []\n",
    "\n",
    "# # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# for gdf in GTs_buffers:\n",
    "#     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     # Count the points that fall within this union\n",
    "#     count = ltn_points.within(buffer_union).sum()\n",
    "#     counts_buffers.append(count)\n",
    "\n",
    "# # Do the same for GTs_buffers_random\n",
    "# for gdf in GTs_buffers_random:\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     count = ltn_points.within(buffer_union).sum()\n",
    "#     counts_random.append(count)\n",
    "\n",
    "# # Plotting the results on a line graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Number of Points Covered')\n",
    "# plt.title('Points Covered by Each Buffer')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# LTN point coverage analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'ltn_points_covered_GT' not in analysis_results:\n",
    "    def compute_ltn_coverage(buffers_list):\n",
    "        return [\n",
    "            ltn_points.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "    \n",
    "    analysis_results.update({\n",
    "        'ltn_points_covered_GT': compute_ltn_coverage(GTs_buffers),\n",
    "        'ltn_points_covered_random': compute_ltn_coverage(GTs_buffers_random),\n",
    "        'ltn_points_covered_demand': compute_ltn_coverage(GTs_buffers_demand),\n",
    "        'ltn_points_covered_demand_ltn_priority': compute_ltn_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'ltn_points_covered_betweenness_ltn_priority': compute_ltn_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    })\n",
    "\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['ltn_points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['ltn_points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Number of LTN Points Covered')\n",
    "plt.title('LTNs Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/ltns_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about how if we were to create future LTNs, where could these go based purely on making more cycling safe?\n",
    "\n",
    "# should these be where the most cycling is on? or which area has the longest bit of cycle network added? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_buffers = []\n",
    "# counts_random = []\n",
    "\n",
    "# # Iterate over each buffer GeoDataFrame in GTs_buffers\n",
    "# for gdf in GTs_buffers:\n",
    "#     # Create a union of all polygons in the buffer gdf (if there is more than one)\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     # Count the points in combined_points that fall within this union\n",
    "#     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "#     counts_buffers.append(count)\n",
    "\n",
    "# # Do the same for GTs_buffers_random\n",
    "# for gdf in GTs_buffers_random:\n",
    "#     buffer_union = gdf.unary_union\n",
    "#     count = all_neighbourhoods_centroids.within(buffer_union).sum()\n",
    "#     counts_random.append(count)\n",
    "\n",
    "# # Plotting the results on a line graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_vals = range(1, len(counts_buffers) + 1)  # Assuming you want x-axis as buffer index\n",
    "\n",
    "# plt.plot(x_vals, counts_buffers, marker='o', label='GTs_buffers')\n",
    "# plt.plot(x_vals, counts_random, marker='o', label='GTs_buffers_random')\n",
    "\n",
    "# plt.xlabel('Buffer Index')\n",
    "# plt.ylabel('Number of Points Covered')\n",
    "# plt.title('Points Covered by Each Buffer')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# Neighborhood centroids analysis cell\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "    def count_neighborhood_coverage(buffers_list):\n",
    "        return [\n",
    "            all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "\n",
    "    neighborhood_metrics = {\n",
    "        'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "        'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "        'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "        'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    }\n",
    "\n",
    "    analysis_results.update(neighborhood_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(analysis_results['neighborhood_points_covered_GT']) + 1)\n",
    "\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_GT'],\n",
    "    color='orange',\n",
    "    linestyle='-',\n",
    "    label='Betweenness Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_random'],\n",
    "    color='blue',\n",
    "    linestyle='--',\n",
    "    label='Random Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_demand'],\n",
    "    color='red',\n",
    "    linestyle='-.',\n",
    "    label='Demand-based Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_demand_ltn_priority'],\n",
    "    color='green',\n",
    "    linestyle=':',\n",
    "    label='Demand LTN Growth'\n",
    ")\n",
    "plt.plot(\n",
    "    x_vals,\n",
    "    analysis_results['neighborhood_points_covered_betweenness_ltn_priority'],\n",
    "    color='purple',\n",
    "    linestyle='-',\n",
    "    label='Betweenness LTN Growth'\n",
    ")\n",
    "\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Neighbourhoods Covered')\n",
    "plt.title('Neighbourhoods Covered by Cycle Network')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/neighbourhoods_coverage.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## against random baseline\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {} \n",
    "\n",
    "if rerun or 'neighborhood_points_covered_GT' not in analysis_results:\n",
    "    def count_neighborhood_coverage(buffers_list):\n",
    "        return [\n",
    "            all_neighbourhoods_centroids.within(gdf.unary_union).sum()\n",
    "            for gdf in buffers_list\n",
    "        ]\n",
    "\n",
    "    neighborhood_metrics = {\n",
    "        'neighborhood_points_covered_GT': count_neighborhood_coverage(GTs_buffers),\n",
    "        'neighborhood_points_covered_random': count_neighborhood_coverage(GTs_buffers_random),\n",
    "        'neighborhood_points_covered_demand': count_neighborhood_coverage(GTs_buffers_demand),\n",
    "        'neighborhood_points_covered_demand_ltn_priority': count_neighborhood_coverage(GTs_buffers_demand_ltn_priority),\n",
    "        'neighborhood_points_covered_betweenness_ltn_priority': count_neighborhood_coverage(GTs_buffers_betweenness_ltn_priority)\n",
    "    }\n",
    "\n",
    "    analysis_results.update(neighborhood_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}) \\\n",
    "        .to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "# Calculate deviation from random\n",
    "random_coverage = np.array(analysis_results['neighborhood_points_covered_random'])\n",
    "\n",
    "coverage_deviations = {\n",
    "    'Betweenness': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_GT']) - random_coverage,\n",
    "        'color': 'orange',\n",
    "        'linestyle': '-'\n",
    "    },\n",
    "    'Demand': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_demand']) - random_coverage,\n",
    "        'color': 'red',\n",
    "        'linestyle': '-.'\n",
    "    },\n",
    "    'Demand LTN': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_demand_ltn_priority']) - random_coverage,\n",
    "        'color': 'green',\n",
    "        'linestyle': ':'\n",
    "    },\n",
    "    'Betweenness LTN': {\n",
    "        'values': np.array(analysis_results['neighborhood_points_covered_betweenness_ltn_priority']) - random_coverage,\n",
    "        'color': 'purple',\n",
    "        'linestyle': '-'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Plot deviation from random\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_vals = range(1, len(random_coverage) + 1)\n",
    "\n",
    "for label, data in coverage_deviations.items():\n",
    "    plt.plot(\n",
    "        x_vals,\n",
    "        data['values'],\n",
    "        linestyle=data['linestyle'],\n",
    "        color=data['color'],\n",
    "        label=label\n",
    "    )\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Growth Iteration')\n",
    "plt.ylabel('Deviation in Neighbourhoods Covered (vs Random)')\n",
    "plt.title('Neighbourhood Coverage — Deviation from Random Growth (Baseline)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "output_path = PATH[\"plots\"] + f\"/{placeid}/neighbourhoods_coverage__deviation_from_random.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap with existing infrastructure. Finding how much of the existing network we overlap, in terms of edges, distance, and % of total network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_against_reference(graph_list1, graph_list2, reference_graph):\n",
    "#     \"\"\"\n",
    "#     Compare two lists of graphs against a reference, calculating both:\n",
    "#     1. How much of the reference is covered by each graph (original metric)\n",
    "#     2. How much of each graph is covered by the reference (reverse metric)\n",
    "#     \"\"\"\n",
    "#     def calculate_both_ways(graph, reference):\n",
    "#         # Original: how much of reference is covered by graph\n",
    "#         orig_size_pct, orig_len_pct, orig_edges, orig_len = calculate_overlap_percentages(reference, graph)\n",
    "#         # Reverse: how much of graph is covered by reference\n",
    "#         rev_size_pct, rev_len_pct, rev_edges, rev_len = calculate_overlap_percentages(graph, reference)\n",
    "#         return (orig_size_pct, orig_len_pct, orig_edges, orig_len,\n",
    "#                 rev_size_pct, rev_len_pct, rev_edges, rev_len)\n",
    "    \n",
    "#     metrics_list1 = [calculate_both_ways(g, reference_graph) for g in graph_list1]\n",
    "#     metrics_list2 = [calculate_both_ways(g, reference_graph) for g in graph_list2]\n",
    "    \n",
    "#     return metrics_list1, metrics_list2\n",
    "\n",
    "# def plot_comparison(metrics_GTs, metrics_GTs_random):\n",
    "#     \"\"\"Plot comparison with separate views for both metrics\"\"\"\n",
    "#     fig, axes = plt.subplots(4, 1, figsize=(12, 16))\n",
    "    \n",
    "#     # Original percentage metrics (how much of REFERENCE is covered)\n",
    "#     axes[0].plot([m[0] for m in metrics_GTs], 'b-', label='GTs Size (Ref Covered)')\n",
    "#     axes[0].plot([m[0] for m in metrics_GTs_random], 'r--', label='GTs_random Size (Ref Covered)')\n",
    "#     axes[0].plot([m[1] for m in metrics_GTs], 'g-', label='GTs Length (Ref Covered)')\n",
    "#     axes[0].plot([m[1] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Ref Covered)')\n",
    "#     axes[0].set_title('Percentage of Reference Covered')\n",
    "#     axes[0].set_ylabel('Percentage')\n",
    "#     axes[0].legend()\n",
    "#     axes[0].grid(True)\n",
    "    \n",
    "#     # Reverse percentage metrics (how much of NETWORK is covered by reference)\n",
    "#     axes[1].plot([m[4] for m in metrics_GTs], 'b-', label='GTs Size (Network Covered)')\n",
    "#     axes[1].plot([m[4] for m in metrics_GTs_random], 'r--', label='GTs_random Size (Network Covered)')\n",
    "#     axes[1].plot([m[5] for m in metrics_GTs], 'g-', label='GTs Length (Network Covered)')\n",
    "#     axes[1].plot([m[5] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Network Covered)')\n",
    "#     axes[1].set_title('Percentage of Network Covered by Reference')\n",
    "#     axes[1].set_ylabel('Percentage')\n",
    "#     axes[1].legend()\n",
    "#     axes[1].grid(True)\n",
    "    \n",
    "#     # Raw edge counts\n",
    "#     axes[2].plot([m[2] for m in metrics_GTs], 'b-', label='GTs Edges (Ref Covered)')\n",
    "#     axes[2].plot([m[2] for m in metrics_GTs_random], 'r--', label='GTs_random Edges (Ref Covered)')\n",
    "#     axes[2].plot([m[6] for m in metrics_GTs], 'g-', label='GTs Edges (Network Covered)')\n",
    "#     axes[2].plot([m[6] for m in metrics_GTs_random], 'm--', label='GTs_random Edges (Network Covered)')\n",
    "#     axes[2].set_title('Raw Edge Counts')\n",
    "#     axes[2].set_ylabel('Edges')\n",
    "#     axes[2].legend()\n",
    "#     axes[2].grid(True)\n",
    "    \n",
    "#     # Raw lengths\n",
    "#     axes[3].plot([m[3] for m in metrics_GTs], 'b-', label='GTs Length (Ref Covered)')\n",
    "#     axes[3].plot([m[3] for m in metrics_GTs_random], 'r--', label='GTs_random Length (Ref Covered)')\n",
    "#     axes[3].plot([m[7] for m in metrics_GTs], 'g-', label='GTs Length (Network Covered)')\n",
    "#     axes[3].plot([m[7] for m in metrics_GTs_random], 'm--', label='GTs_random Length (Network Covered)')\n",
    "#     axes[3].set_title('Raw Length Overlap')\n",
    "#     axes[3].set_ylabel('Length')\n",
    "#     axes[3].legend()\n",
    "#     axes[3].grid(True)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# reference = G_biketrack  # Your reference infrastructure\n",
    "# metrics_GTs, metrics_GTs_random = compare_against_reference(GTs, GTs_random, reference)\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_overlap_percentages(G_biketrack, G):\n",
    "#     # Calculate edge overlap and length overlap\n",
    "#     overlapping_edges = 0\n",
    "#     overlapping_length = 0\n",
    "#     total_edges = G_biketrack.number_of_edges()\n",
    "#     total_length = sum(data['length'] for u, v, data in G_biketrack.edges(data=True))\n",
    "    \n",
    "#     for u, v, data in G_biketrack.edges(data=True):\n",
    "#         if G.has_edge(u, v):\n",
    "#             overlapping_edges += 1\n",
    "#             overlapping_length += data['length']\n",
    "    \n",
    "#     if total_edges == 0:\n",
    "#         size_percent = 0.0\n",
    "#     else:\n",
    "#         size_percent = (overlapping_edges / total_edges) * 100\n",
    "    \n",
    "#     if total_length == 0:\n",
    "#         length_percent = 0.0\n",
    "#     else:\n",
    "#         length_percent = (overlapping_length / total_length) * 100\n",
    "    \n",
    "#     return size_percent, length_percent, overlapping_edges, overlapping_length\n",
    "\n",
    "\n",
    "# def compare_against_existing(graph_list1, graph_list2, reference_graph):\n",
    "#     \"\"\"\n",
    "#     Compare two lists of graphs against a common reference graph.\n",
    "#     Returns metrics for both lists compared to the reference.\n",
    "#     \"\"\"\n",
    "#     # Calculate metrics for both lists against the reference\n",
    "#     metrics_list1 = [calculate_overlap_percentages(g, reference_graph) for g in graph_list1]\n",
    "#     metrics_list2 = [calculate_overlap_percentages(g, reference_graph) for g in graph_list2]\n",
    "    \n",
    "#     return metrics_list1, metrics_list2\n",
    "\n",
    "# def plot_comparison(metrics_GTs, metrics_GTs_random):\n",
    "#     \"\"\"Plot comparison between GTs and GTs_random against G_biketrack\"\"\"\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    \n",
    "#     # Percentage plot\n",
    "#     ax1.plot([m[0] for m in metrics_GTs], 'b-', label='GTs Size Overlap (%)')\n",
    "#     ax1.plot([m[0] for m in metrics_GTs_random], 'r--', label='GTs_random Size Overlap (%)')\n",
    "#     ax1.plot([m[1] for m in metrics_GTs], 'g-', label='GTs Length Overlap (%)')\n",
    "#     ax1.plot([m[1] for m in metrics_GTs_random], 'm--', label='GTs_random Length Overlap (%)')\n",
    "#     ax1.set_title('Percentage Overlap with Existing Cycle Infrastructure (Including LTNs)')\n",
    "#     ax1.set_ylabel('Percentage')\n",
    "#     ax1.legend()\n",
    "#     ax1.grid(True)\n",
    "    \n",
    "#     # Edge count plot\n",
    "#     ax2.plot([m[2] for m in metrics_GTs], 'b-', label='GTs Overlapping Edges')\n",
    "#     ax2.plot([m[2] for m in metrics_GTs_random], 'r--', label='GTs_random Overlapping Edges')\n",
    "#     ax2.set_title('Edge Overlap Comparison')\n",
    "#     ax2.set_ylabel('Edge Count')\n",
    "#     ax2.legend()\n",
    "#     ax2.grid(True)\n",
    "    \n",
    "#     # Length plot\n",
    "#     ax3.plot([m[3] for m in metrics_GTs], 'g-', label='GTs Overlapping Length')\n",
    "#     ax3.plot([m[3] for m in metrics_GTs_random], 'm--', label='GTs_random Overlapping Length')\n",
    "#     ax3.set_title('Length Overlap Comparison')\n",
    "#     ax3.set_ylabel('Length Units')\n",
    "#     ax3.legend()\n",
    "#     ax3.grid(True)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack)\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)\n",
    "\n",
    "\n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'overlap_size_percent_GTs' not in analysis_results:\n",
    "    def calculate_overlap_percentages(G_ref, G):\n",
    "        overlapping_edges = 0\n",
    "        overlapping_length = 0\n",
    "        total_edges = G_ref.number_of_edges()\n",
    "        total_length = sum(data.get('length', 0) for _, _, data in G_ref.edges(data=True))\n",
    "\n",
    "        for u, v, data in G_ref.edges(data=True):\n",
    "            if G.has_edge(u, v):\n",
    "                overlapping_edges += 1\n",
    "                overlapping_length += data.get('length', 0)\n",
    "\n",
    "        size_percent = (overlapping_edges / total_edges * 100) if total_edges else 0\n",
    "        length_percent = (overlapping_length / total_length * 100) if total_length else 0\n",
    "\n",
    "        return size_percent, length_percent, overlapping_edges, overlapping_length\n",
    "\n",
    "    def get_metrics(graph_list, ref_graph):\n",
    "        return [calculate_overlap_percentages(ref_graph, g) for g in graph_list]\n",
    "\n",
    "    metrics_betweenness = get_metrics(GTs, G_biketrack)\n",
    "    metrics_random = get_metrics(GTs_random, G_biketrack)\n",
    "    metrics_demand = get_metrics(GTs_demand, G_biketrack)\n",
    "    metrics_betweenness_ltn_priority = get_metrics(GTs_betweenness_ltn_priority, G_biketrack)\n",
    "    metrics_demand_ltn_priority = get_metrics(GTs_demand_ltn_priority, G_biketrack)\n",
    "\n",
    "    overlap_metrics = {\n",
    "        # Betweenness\n",
    "        'overlap_size_percent_GTs': [m[0] for m in metrics_betweenness],\n",
    "        'overlap_length_percent_GTs': [m[1] for m in metrics_betweenness],\n",
    "        'overlap_edges_GTs': [m[2] for m in metrics_betweenness],\n",
    "        'overlap_length_GTs': [m[3] for m in metrics_betweenness],\n",
    "\n",
    "        # Random\n",
    "        'overlap_size_percent_random': [m[0] for m in metrics_random],\n",
    "        'overlap_length_percent_random': [m[1] for m in metrics_random],\n",
    "        'overlap_edges_random': [m[2] for m in metrics_random],\n",
    "        'overlap_length_random': [m[3] for m in metrics_random],\n",
    "\n",
    "        # Demand\n",
    "        'overlap_size_percent_demand': [m[0] for m in metrics_demand],\n",
    "        'overlap_length_percent_demand': [m[1] for m in metrics_demand],\n",
    "        'overlap_edges_demand': [m[2] for m in metrics_demand],\n",
    "        'overlap_length_demand': [m[3] for m in metrics_demand],\n",
    "\n",
    "        # Demand LTN Priority\n",
    "        'overlap_size_percent_demand_ltn_priority': [m[0] for m in metrics_demand_ltn_priority],\n",
    "        'overlap_length_percent_demand_ltn_priority': [m[1] for m in metrics_demand_ltn_priority],\n",
    "        'overlap_edges_demand_ltn_priority': [m[2] for m in metrics_demand_ltn_priority],\n",
    "        'overlap_length_demand_ltn_priority': [m[3] for m in metrics_demand_ltn_priority],\n",
    "\n",
    "        # Betweenness LTN Priority\n",
    "        'overlap_size_percent_betweenness_ltn_priority': [m[0] for m in metrics_betweenness_ltn_priority],\n",
    "        'overlap_length_percent_betweenness_ltn_priority': [m[1] for m in metrics_betweenness_ltn_priority],\n",
    "        'overlap_edges_betweenness_ltn_priority': [m[2] for m in metrics_betweenness_ltn_priority],\n",
    "        'overlap_length_betweenness_ltn_priority': [m[3] for m in metrics_betweenness_ltn_priority]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(overlap_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_comparison(metric_key_prefix, ylabel, title, filename):\n",
    "    \"\"\"\n",
    "    Plots a single metric across all strategies compared to existing infrastructure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(analysis_results[f'{metric_key_prefix}_GTs'], color='orange', linestyle='-', label='Betweenness')\n",
    "    plt.plot(analysis_results[f'{metric_key_prefix}_random'], color='blue', linestyle='--', label='Random')\n",
    "    plt.plot(analysis_results[f'{metric_key_prefix}_demand'], color='red', linestyle='-.', label='Demand')\n",
    "    plt.plot(analysis_results[f'{metric_key_prefix}_demand_ltn_priority'], color='green', linestyle=':', label='Demand LTN')\n",
    "    plt.plot(analysis_results[f'{metric_key_prefix}_betweenness_ltn_priority'], color='purple', linestyle='-', label='Betweenness LTN')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = PATH[\"plots\"] + f\"/{placeid}/{filename}\"\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Call for each metric\n",
    "plot_metric_comparison(\n",
    "    metric_key_prefix='overlap_size_percent',\n",
    "    ylabel='Overlap (%)',\n",
    "    title='Edge Overlap % with Existing Cycle Network',\n",
    "    filename='percentage_overlap_edges.png'\n",
    ")\n",
    "\n",
    "plot_metric_comparison(\n",
    "    metric_key_prefix='overlap_length_percent',\n",
    "    ylabel='Overlap (%)',\n",
    "    title='Length Overlap % with Existing Cycle Network',\n",
    "    filename='percentage_overlap_length.png'\n",
    ")\n",
    "\n",
    "# plot_metric_comparison(\n",
    "#     metric_key_prefix='overlap_edges',\n",
    "#     ylabel='Edge Count',\n",
    "#     title='Overlapping Edge Count with Existing Cycle Network',\n",
    "#     filename='overlapping_edges_count.png'\n",
    "# )\n",
    "\n",
    "# plot_metric_comparison(\n",
    "#     metric_key_prefix='overlap_length',\n",
    "#     ylabel='Length (m)',\n",
    "#     title='Overlapping Length with Existing Cycle Network',\n",
    "#     filename='overlapping_length_total.png'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## against a random baseline\n",
    "def plot_deviation_from_random(metric_key_prefix, ylabel, title, filename):\n",
    "    \"\"\"\n",
    "    Plots deviation from random growth for a given overlap metric.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    baseline = np.array(analysis_results[f'{metric_key_prefix}_random'])\n",
    "\n",
    "    def plot_diff(strategy_key, label, color, linestyle):\n",
    "        values = np.array(analysis_results[f'{metric_key_prefix}_{strategy_key}'])\n",
    "        diff = values - baseline\n",
    "        plt.plot(diff, label=label, color=color, linestyle=linestyle)\n",
    "\n",
    "    plot_diff('GTs', 'Betweenness – Random', 'orange', '-')\n",
    "    plot_diff('demand', 'Demand – Random', 'red', '-.')\n",
    "    plot_diff('demand_ltn_priority', 'Demand LTN – Random', 'green', ':')\n",
    "    plot_diff('betweenness_ltn_priority', 'Betweenness LTN – Random', 'purple', '-')\n",
    "\n",
    "    plt.axhline(0, color='grey', linestyle='--', linewidth=1, alpha=0.6)\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    output_path = PATH[\"plots\"] + f\"/{placeid}/{filename}\"\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_deviation_from_random(\n",
    "    metric_key_prefix='overlap_size_percent',\n",
    "    ylabel='Difference in Overlap (%)',\n",
    "    title='Edge Overlap: Improvement over Random (Baseline)',\n",
    "    filename='deviation_from_random_overlap_edges.png'\n",
    ")\n",
    "\n",
    "plot_deviation_from_random(\n",
    "    metric_key_prefix='overlap_length_percent',\n",
    "    ylabel='Difference in Overlap (%)',\n",
    "    title='Length Overlap: Improvement over Random (Baseline)',\n",
    "    filename='deviation_from_random_overlap_length.png'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack_no_ltn) # no differance?\n",
    "# plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to explore it\n",
    "\n",
    "# # work in meters\n",
    "# G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "# G_edges = G_edges.to_crs(epsg=3857)\n",
    "# G_biketrack_edges['geometry'] = G_biketrack_edges.geometry.buffer(1)\n",
    "# G_edges['geometry'] = G_edges.geometry.buffer(1)\n",
    "# joined = gpd.sjoin(G_biketrack_edges, G_edges, how=\"inner\", predicate=\"intersects\", lsuffix=\"_biketrack\", rsuffix=\"_edge\")\n",
    "\n",
    "# joined.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directness (Directness=Total Sum of Network Distances/Total Sum of Euclidean Distances​)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_dist = []\n",
    "# eucl_dist = []\n",
    "# directness = []\n",
    "\n",
    "# for G in GT_abstracts:\n",
    "#     total_net_dist = sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "#     total_eucl_dist = sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "#     net_dist.append(total_net_dist)\n",
    "#     eucl_dist.append(total_eucl_dist)\n",
    "#     if total_net_dist != 0:\n",
    "#         ratio = total_eucl_dist / total_net_dist\n",
    "#     else:\n",
    "#         ratio = None\n",
    "#     directness.append(ratio)\n",
    "\n",
    "\n",
    "# net_dist_random = []\n",
    "# eucl_dist_random = []\n",
    "# directness_random = []\n",
    "\n",
    "# for G in GT_abstracts_random:\n",
    "#     total_net_dist = sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "#     total_eucl_dist = sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "#     net_dist_random.append(total_net_dist)\n",
    "#     eucl_dist_random.append(total_eucl_dist)\n",
    "#     if total_net_dist != 0:\n",
    "#         ratio = total_eucl_dist / total_net_dist\n",
    "#     else:\n",
    "#         ratio = None\n",
    "#     directness_random.append(ratio)\n",
    "\n",
    "\n",
    "\n",
    "# # Plotting \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(directness, linestyle='-', color='blue', label='Betweeness')\n",
    "# plt.plot(directness_random, linestyle='--', color='orange', label='Random')\n",
    "# plt.xlabel('Graph Index')\n",
    "# plt.ylabel('Directness (Euclidean / Network Distance)')\n",
    "# plt.title('Total Network Directness')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Directness analysis \n",
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'directness_demand' not in analysis_results:\n",
    "    directness_metrics = {\n",
    "        # Betweenness\n",
    "        'directness_net': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'directness_eucl': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'directness': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "\n",
    "        # Random\n",
    "        'directness_net_random': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'directness_eucl_random': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'directness_random': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "\n",
    "        # Demand\n",
    "        'directness_net_demand': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'directness_eucl_demand': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'directness_demand': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "\n",
    "        # Demand LTN Priority\n",
    "        'directness_net_demand_ltn_priority': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'directness_eucl_demand_ltn_priority': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'directness_demand_ltn_priority': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "\n",
    "        # Betweenness LTN Priority\n",
    "        'directness_net_betweenness_ltn_priority': [\n",
    "            sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ],\n",
    "        'directness_eucl_betweenness_ltn_priority': [\n",
    "            sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True))\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ],\n",
    "        'directness_betweenness_ltn_priority': [\n",
    "            (sum(data.get('eucl_dist', 0) for _, _, data in G.edges(data=True)) / \n",
    "             sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)))\n",
    "            if sum(data.get('sp_true_distance', 0) for _, _, data in G.edges(data=True)) != 0 else None\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    analysis_results.update(directness_metrics)\n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    analysis_results['directness'],\n",
    "    linestyle='--', \n",
    "    color='orange', \n",
    "    label='Betweenness'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_random'],\n",
    "    linestyle='-', \n",
    "    color='blue', \n",
    "    label='Random'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_demand'],\n",
    "    linestyle='-.', \n",
    "    color='red', \n",
    "    label='Demand'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_demand_ltn_priority'],\n",
    "    linestyle=':', \n",
    "    color='green', \n",
    "    label='Demand LTN'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['directness_betweenness_ltn_priority'],\n",
    "    linestyle='-', \n",
    "    color='purple', \n",
    "    label='Betweenness LTN'\n",
    ")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Directness (Euclidean / Network Distance)')\n",
    "plt.title('Network Directness Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/directness.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcaulate directness of existing network to compare against..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## edit plotting\n",
    "# def calculate_efficiency(G):\n",
    "#     \"\"\"Calculate global network efficiency using formula E = 1/(N(N-1)) * Σ 1/d_ij\"\"\"\n",
    "#     # Convert to undirected graph\n",
    "#     undirected_G = nx.Graph(G)\n",
    "#     try:\n",
    "#         return nx.global_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         return 0  # Handle disconnected graphs\n",
    "\n",
    "# def plot_efficiency_comparison(GTs, GTs_random):\n",
    "#     \"\"\"Calculate and plot global efficiency for both graph lists\"\"\"\n",
    "#     # Calculate efficiencies\n",
    "#     eff_GTs = [calculate_efficiency(G) for G in GTs]\n",
    "#     eff_random = [calculate_efficiency(G) for G in GTs_random]\n",
    "    \n",
    "#     # Create plot\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(eff_GTs, 'b-', linewidth=2, label='GTs Efficiency')\n",
    "#     plt.plot(eff_random, 'r--', linewidth=2, label='GTs_random Efficiency')\n",
    "    \n",
    "#     plt.title('Global Network Efficiency Comparison\\n$E = \\\\frac{1}{N(N-1)}\\\\sum_{i\\\\neq j} \\\\frac{1}{d_{ij}}$')\n",
    "#     plt.ylabel('Global Efficiency')\n",
    "#     plt.xlabel('Graph Instance Index')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Usage example:\n",
    "# plot_efficiency_comparison(GTs, GTs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_efficiency(G, numnodepairs=500, normalized=True, weight='weight', debug=False):\n",
    "    \"\"\"Calculates global network efficiency for a graph G.\"\"\"\n",
    "    if G is None or len(G) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    nodes = list(G.nodes)\n",
    "    N = len(nodes)\n",
    "    \n",
    "    if N > numnodepairs:\n",
    "        sampled_nodes = random.sample(nodes, numnodepairs)\n",
    "    else:\n",
    "        sampled_nodes = nodes\n",
    "    S = len(sampled_nodes)\n",
    "    if S < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    total_efficiency = 0.0\n",
    "    considered_pairs = S * (S - 1)  \n",
    "    \n",
    "    for u in sampled_nodes:\n",
    "        try:\n",
    "            lengths = nx.single_source_dijkstra_path_length(G, u, weight=weight)\n",
    "            for v in sampled_nodes:\n",
    "                if u == v: continue\n",
    "                d = lengths.get(v, float('inf'))\n",
    "                if 0 < d < float('inf'):\n",
    "                    total_efficiency += 1 / d\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if considered_pairs == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Always use considered_pairs for unnormalized\n",
    "    EG = total_efficiency / considered_pairs  # average efficiency\n",
    "    \n",
    "    if not normalized:\n",
    "        return EG  # Directly return average efficiency of sampled pairs\n",
    "    \n",
    "    # Normalisation logic \n",
    "    for node in sampled_nodes:\n",
    "        if 'x' not in G.nodes[node] or 'y' not in G.nodes[node]:\n",
    "            raise KeyError(\"Nodes need 'x' and 'y' for normalization.\")\n",
    "    \n",
    "    ideal_total = 0.0\n",
    "    for u, v in itertools.permutations(sampled_nodes, 2):\n",
    "        x1, y1 = G.nodes[u]['x'], G.nodes[u]['y']\n",
    "        x2, y2 = G.nodes[v]['x'], G.nodes[v]['y']\n",
    "        distance = ((x1-x2)**2 + (y1-y2)**2)**0.5\n",
    "        if distance > 0:\n",
    "            ideal_total += 1 / distance\n",
    "    \n",
    "    if ideal_total == 0:\n",
    "        return 0.0\n",
    "    \n",
    "\n",
    "    ideal_avg = ideal_total / considered_pairs\n",
    "    normalized_efficiency = EG / ideal_avg\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Actual Avg: {EG}, Ideal Avg: {ideal_avg}, Normalized: {normalized_efficiency}\")\n",
    "    \n",
    "    return normalized_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_global_efficiency(G, numnodepairs=500, normalized=True, weight='length', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(analysis_res_pickle):\n",
    "    with open(analysis_res_pickle, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "else:\n",
    "    analysis_results = {}\n",
    "\n",
    "if rerun or 'efficiency_demand' not in analysis_results:\n",
    "    efficiency_metrics = {\n",
    "        'efficiency': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts\n",
    "        ],\n",
    "        'efficiency_random': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_random\n",
    "        ],\n",
    "        'efficiency_demand': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_demand\n",
    "        ],\n",
    "        'efficiency_demand_ltn_priority': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_demand_ltn_priority\n",
    "        ],\n",
    "        'efficiency_betweenness_ltn_priority': [\n",
    "            calculate_global_efficiency(G, numnodepairs=1000, normalized=True, weight='length')\n",
    "            for G in GT_abstracts_betweenness_ltn_priority\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    analysis_results.update(efficiency_metrics)  \n",
    "    with open(analysis_res_pickle, 'wb') as f:\n",
    "        pickle.dump(analysis_results, f)\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in analysis_results.items()}).to_csv(analysis_res_csv, index=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot efficiency from analysis_results\n",
    "plt.plot(\n",
    "    analysis_results['efficiency'],\n",
    "    linestyle='-', \n",
    "    color='orange',\n",
    "    label='Betweenness'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_random'],\n",
    "    linestyle='--', \n",
    "    color='blue',\n",
    "    label='Random'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_demand'],\n",
    "    linestyle='-.', \n",
    "    color='red',\n",
    "    label='Demand'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_demand_ltn_priority'],\n",
    "    linestyle=':', \n",
    "    color='green',\n",
    "    label='Demand LTN'\n",
    ")\n",
    "plt.plot(\n",
    "    analysis_results['efficiency_betweenness_ltn_priority'],\n",
    "    linestyle='-', \n",
    "    color='purple',\n",
    "    label='Betweenness LTN'\n",
    ")\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Global Efficiency', fontsize=12)\n",
    "plt.title('Global Network Efficiency Comparison', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = PATH[\"plots\"] + \"/\" + placeid + \"/global_eff.png\"\n",
    "plt.savefig(output_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot both lines\n",
    "plt.plot(x, eff_GTs, label='GTs',  linestyle='-', color='blue')\n",
    "plt.plot(x_random, eff_GTs_random, label='GTs Random', linestyle='--', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Graph Index', fontsize=12)\n",
    "plt.ylabel('Global Efficiency', fontsize=12)\n",
    "plt.title('Global Network Efficiency Comparison', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Customize ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_efficiencies(G):\n",
    "#     \"\"\"Calculate both global and local efficiencies\"\"\"\n",
    "#     # Convert to undirected graph\n",
    "#     undirected_G = nx.Graph(G)\n",
    "    \n",
    "#     try:\n",
    "#         global_eff = nx.global_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         global_eff = 0\n",
    "        \n",
    "#     try:\n",
    "#         local_eff = nx.local_efficiency(undirected_G)\n",
    "#     except nx.NetworkXError:\n",
    "#         local_eff = 0\n",
    "        \n",
    "#     return global_eff, local_eff\n",
    "\n",
    "# def plot_efficiency_comparison(GTs, GTs_random):\n",
    "#     \"\"\"Plot comparison of both efficiency metrics\"\"\"\n",
    "#     # Calculate efficiencies\n",
    "#     global_GTs, local_GTs = zip(*[calculate_efficiencies(G) for G in GTs])\n",
    "#     global_random, local_random = zip(*[calculate_efficiencies(G) for G in GTs_random])\n",
    "    \n",
    "#     # Create plots\n",
    "#     fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "#     # Global efficiency plot\n",
    "#     ax1.plot(global_GTs, 'b-', linewidth=2, label='GTs Global Eff')\n",
    "#     ax1.plot(global_random, 'r--', linewidth=2, label='GTs_random Global Eff')\n",
    "#     ax1.set_title('Global Network Efficiency Comparison')\n",
    "#     ax1.set_ylabel('Efficiency')\n",
    "#     ax1.legend()\n",
    "#     ax1.grid(True)\n",
    "#     ax1.set_ylim(0, 1)\n",
    "    \n",
    "#     # Local efficiency plot\n",
    "#     ax2.plot(local_GTs, 'g-', linewidth=2, label='GTs Local Eff')\n",
    "#     ax2.plot(local_random, 'm--', linewidth=2, label='GTs_random Local Eff')\n",
    "#     ax2.set_title('Local Network Efficiency Comparison')\n",
    "#     ax2.set_ylabel('Efficiency')\n",
    "#     ax2.legend()\n",
    "#     ax2.grid(True)\n",
    "#     ax2.set_ylim(0, 1)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Usage example:\n",
    "# plot_efficiency_comparison(GTs, GTs_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Pretty plots of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjust the width and height as needed\n",
    "\n",
    "\n",
    "\n",
    "G_biketrackcarall_edges = ox.graph_to_gdfs(G_biketrackcarall, nodes=False)\n",
    "G_biketrackcarall_edges = G_biketrackcarall_edges.to_crs(epsg=3857)  # Ensure CRS matches\n",
    "G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder = 0)  # Light grey with thin linewidth\n",
    "\n",
    "# Add bike track edges\n",
    "#G_biketrack = {}\n",
    "#G_biketrack[placeid] = csv_to_ox(PATH[\"data\"] + placeid + \"/\", placeid, 'biketrack')\n",
    "#G_biketrack[placeid].graph[\"crs\"] = 'epsg:4326'  # Needed for OSMNX's graph_to_gdfs in utils_graph.py\n",
    "#G_biketrack = copy.deepcopy(G_biketrack[placeid])\n",
    "G_biketrack_edges = ox.graph_to_gdfs(G_biketrack, nodes=False)\n",
    "G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder = 1)  # Light grey with thin linewidth\n",
    "\n",
    "\n",
    "# Plot the main graph and layers\n",
    "GT_nodes, GT_edges = ox.graph_to_gdfs(GTs[iteration_number])\n",
    "GT_edges = GT_edges.to_crs(epsg=3857)\n",
    "GT_edges.plot(ax=ax, color='orange')\n",
    "ltn_points.to_crs(epsg=3857).plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "tess_points.to_crs(epsg=3857).plot(ax=ax, color='green', markersize=5, zorder = 3)\n",
    "\n",
    "\n",
    "ltns = ltns.to_crs(epsg=3857)  # Ensure the CRS matches\n",
    "ltns.plot(ax=ax, color='blue', alpha=0.5, label=f\"Low Traffic Neighbourhoods\", zorder=2)\n",
    "\n",
    "\n",
    "# Remove x and y axis labels and ticks\n",
    "ax.axis('off')  # This removes the entire axis, including labels and ticks\n",
    "\n",
    "ax.set_title(f\"Iteration: {iteration_number + 1}\")\n",
    "#ax.legend(loc=\"upper left\")\n",
    "\n",
    "output_path = fr\"C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\Conferances etc\\GISRUK 2025\\Plots\\{iteration_number}_network_plot.png\"\n",
    "plt.savefig(output_path, dpi=600, bbox_inches='tight'\n",
    "            #, transparent=True\n",
    "            )\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif_path = r\"C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\networkGrowth\\bikenwgrowth_external\\videos\\newcastle\\investment_animation_pct.gif\"\n",
    "\n",
    "# # Set up a figure for animation\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# def update(idx):\n",
    "#     \"\"\"Update function for each frame in the animation.\"\"\"\n",
    "#     ax.clear()  # Clear previous frame\n",
    "#     G = GTs[idx]\n",
    "#     # Skip empty graphs\n",
    "#     if len(G.edges()) == 0:\n",
    "#         print(f\"Graph {idx + 1} has no edges, skipping plot.\")\n",
    "#         return\n",
    "    \n",
    "#     # Add G_weighted edges\n",
    "#     G_weighted_edges = ox.graph_to_gdfs(G_weighted, nodes=False)\n",
    "#     G_weighted_edges = G_weighted_edges.to_crs(epsg=3857)\n",
    "#     G_weighted_edges.plot(ax=ax, color='grey', linewidth=0.5, alpha=0.6, zorder=0)\n",
    "\n",
    "#     # Add bike track edges\n",
    "#     G_biketrack_nodes, G_biketrack_edges = ox.graph_to_gdfs(G_biketrack)\n",
    "#     G_biketrack_edges = G_biketrack_edges.to_crs(epsg=3857)\n",
    "#     G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=0.5, alpha=0.8, zorder=1)\n",
    "\n",
    "#     # Plot main graph\n",
    "#     GT_nodes, GT_edges = ox.graph_to_gdfs(G)\n",
    "#     GT_edges = GT_edges.to_crs(epsg=3857)\n",
    "#     GT_edges.plot(ax=ax, color='orange')\n",
    "\n",
    "#     # Plot additional layers\n",
    "#     ltn_gdf.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "#     tess_gdf.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "\n",
    "#     # Plot the neighbourhood\n",
    "#     placename = \"Newcastle Upon Tyne\"\n",
    "#     if placename in neighbourhoods:\n",
    "#         neighbourhood_gdf = neighbourhoods[placename].to_crs(epsg=3857)\n",
    "#         neighbourhood_gdf.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "#     # Remove axis and set title\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(f\"Meters of investment: {D/10}\")\n",
    "\n",
    "# # Create animation\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(GTs), repeat=False)\n",
    "\n",
    "# # Save the animation as a GIF using PillowWriter\n",
    "# ani.save(gif_path, writer=animation.PillowWriter(fps=6))\n",
    "\n",
    "# print(f\"GIF saved to: {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete once happy with cell below\n",
    "# neighbourhoods = load_neighbourhoods(os.path.join(PATH[\"data\"], placeid))\n",
    "# G_biketrackcarall_edges = (\n",
    "#     ox.graph_to_gdfs(G_biketrackcarall, nodes=False)\n",
    "#       .to_crs(epsg=3857)\n",
    "# )\n",
    "# G_biketrack_edges = (\n",
    "#     ox.graph_to_gdfs(G_biketrack, nodes=False)\n",
    "#       .to_crs(epsg=3857)\n",
    "# )\n",
    "\n",
    "# ltn_points_crs = ltn_points.to_crs(epsg=3857)\n",
    "# tess_points_crs = tess_points.to_crs(epsg=3857)\n",
    "# neighbourhoods = load_neighbourhoods(PATH[\"data\"] + placeid + \"/\")\n",
    "# ltns = neighbourhoods.get(\"ltns\", None)\n",
    "# ltns_gdf = None\n",
    "# if neighbourhoods:\n",
    "#     _, ltns_gdf = next(iter(neighbourhoods.items())) # get the first geodataframe in neighbourhoods. Should fix this to a more elegant solution\n",
    "#     ltns = ltns_gdf.to_crs(epsg=3857) \n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))  \n",
    "\n",
    "# def update(idx):\n",
    "#     \"\"\"Update function called for each animation frame.\"\"\"\n",
    "#     ax.clear()  # clear the axis for the new frame\n",
    "\n",
    "#     # Plot the static background layers first.\n",
    "#     G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder=0)\n",
    "#     G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder=1)\n",
    "\n",
    "#     # Get the current main graph from your list of graphs GTs.\n",
    "#     current_graph = GTs[idx]\n",
    "#     if len(current_graph.edges()) == 0:\n",
    "#         print(f\"Graph {idx + 1} has no edges, skipping plot.\")\n",
    "#         return\n",
    "\n",
    "#     # Convert the main graph to GeoDataFrames and reproject\n",
    "#     GT_nodes, GT_edges = ox.graph_to_gdfs(current_graph)\n",
    "#     GT_edges.to_crs(epsg=3857).plot(ax=ax, color='orange')\n",
    "    \n",
    "#     # Plot additional layers.\n",
    "#     ltn_points_crs.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "#     tess_points_crs.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "#     ltns.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(f\"Iterations completed: {idx + 1}%\", fontsize=14)\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=len(GT_abstracts), repeat=False)\n",
    "\n",
    "# # Construct the output file path flexibly\n",
    "# output_gif = os.path.join(PATH[\"videos\"], placeid + \"/\" f\"investment_animation{prune_measure}.gif\")\n",
    "# output_gif = os.path.join(PATH[\"videos\"], placeid + \"/\" f\"betweenness_greedyTri.gif\")\n",
    "# # Create the directory if it doesn't exist.\n",
    "# os.makedirs(os.path.dirname(output_gif), exist_ok=True)\n",
    "\n",
    "# # Save the animation as a GIF with PillowWriter.\n",
    "# ani.save(output_gif, writer=animation.PillowWriter(fps=6))\n",
    "\n",
    "# print(f\"GIF saved to: {output_gif}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new plotting function\n",
    "def plot_investment_animation(\n",
    "    graph_list,\n",
    "    output_path,\n",
    "    G_biketrackcarall,\n",
    "    G_biketrack,\n",
    "    ltn_points,\n",
    "    tess_points,\n",
    "    neighbourhoods,\n",
    "    fps=4,\n",
    "    title_prefix=\"Iteration number: \",\n",
    "    crs_epsg=3857,\n",
    "    figsize=(12, 8)\n",
    "):\n",
    "    \"\"\"Generate and save an animated GIF showing network growth over time.\"\"\"\n",
    "\n",
    "    G_biketrackcarall_edges = (\n",
    "        ox.graph_to_gdfs(G_biketrackcarall, nodes=False).to_crs(epsg=crs_epsg)\n",
    "    )\n",
    "    G_biketrack_edges = (\n",
    "        ox.graph_to_gdfs(G_biketrack, nodes=False).to_crs(epsg=crs_epsg)\n",
    "    )\n",
    "    ltn_points_crs = ltn_points.to_crs(epsg=crs_epsg)\n",
    "    tess_points_crs = tess_points.to_crs(epsg=crs_epsg)\n",
    "\n",
    "    # Get a neighbourhood GeoDataFrame from the dictionary\n",
    "    ltns = None\n",
    "    if neighbourhoods:\n",
    "        _, ltns_gdf = next(iter(neighbourhoods.items()))\n",
    "        ltns = ltns_gdf.to_crs(epsg=crs_epsg)\n",
    "\n",
    "    # Set up the figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    def update(idx):\n",
    "        ax.clear()\n",
    "        G = graph_list[idx]\n",
    "        if 'crs' not in G.graph:\n",
    "            G.graph['crs'] = f\"epsg:{crs_epsg}\"\n",
    "\n",
    "        # Static background layers\n",
    "        G_biketrackcarall_edges.plot(ax=ax, color='grey', linewidth=0.6, alpha=0.5, zorder=0)\n",
    "        G_biketrack_edges.plot(ax=ax, color='turquoise', linewidth=1.4, alpha=0.9, zorder=1)\n",
    "\n",
    "        # Skip empty graphs\n",
    "        if len(G.edges()) == 0:\n",
    "            print(f\"Graph {idx + 1} has no edges, skipping.\")\n",
    "            return\n",
    "\n",
    "        # Main graph\n",
    "        _, edges = ox.graph_to_gdfs(G)\n",
    "        edges.to_crs(epsg=crs_epsg).plot(ax=ax, color='orange')\n",
    "\n",
    "        # Point layers\n",
    "        ltn_points_crs.plot(ax=ax, color='red', markersize=10, zorder=4)\n",
    "        tess_points_crs.plot(ax=ax, color='green', markersize=5, zorder=3)\n",
    "\n",
    "        # LTN areas\n",
    "        if ltns is not None:\n",
    "            ltns.plot(ax=ax, color='blue', alpha=0.5, zorder=2)\n",
    "\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{title_prefix} - iterations completed: {idx + 1}%\", fontsize=14)\n",
    "\n",
    "    # Create animation\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(graph_list), repeat=False)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "\n",
    "    ani.save(output_path, writer=animation.PillowWriter(fps=fps), dpi=400)\n",
    "    print(f\"GIF saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run plotting function\n",
    "plot_investment_animation(\n",
    "    graph_list=GT_abstracts_demand,\n",
    "    output_path=os.path.join(PATH[\"videos\"], placeid, f\"demand_abstract_animation.gif\"),\n",
    "    G_biketrackcarall=G_biketrackcarall,\n",
    "    G_biketrack=G_biketrack,\n",
    "    ltn_points=ltn_points,\n",
    "    tess_points=tess_points,\n",
    "    neighbourhoods=load_neighbourhoods(os.path.join(PATH[\"data\"], placeid)),\n",
    "    title_prefix=\"Demand growth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfinshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_GTs, metrics_GTs_random = compare_against_existing(GTs, GTs_random, G_biketrack_no_ltn) # no differance?\n",
    "plot_comparison(metrics_GTs, metrics_GTs_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
